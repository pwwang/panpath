{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PanPath","text":"\ud83c\udf0d Universal sync/async local/cloud path library <p>A pathlib-compatible interface for Python that works seamlessly across local and cloud storage</p> <p> </p>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li> <p> Unified Interface</p> <p>Single API for local and cloud storage (S3, Google Cloud Storage, Azure Blob Storage)</p> </li> <li> <p> Sync &amp; Async</p> <p>Choose synchronous or asynchronous operations based on your needs</p> </li> <li> <p> Pathlib Compatible</p> <p>Drop-in replacement for <code>pathlib.Path</code> for local files</p> </li> <li> <p> Lazy Loading</p> <p>Cloud clients instantiated only when needed for better performance</p> </li> <li> <p> Cross-Storage Operations</p> <p>Copy/move files between different storage backends seamlessly</p> </li> <li> <p> Bulk Operations</p> <p>Efficient <code>rmtree</code>, <code>copy</code>, <code>copytree</code> for directories</p> </li> <li> <p> Testable</p> <p>Local mock infrastructure for testing without cloud resources</p> </li> <li> <p> Optional Dependencies</p> <p>Install only what you need - minimal core with optional cloud backends</p> </li> </ul>"},{"location":"#quick-example","title":"\ud83d\ude80 Quick Example","text":"SyncAsyncCross-Storage <pre><code>from panpath import PanPath\n\n# Local files (pathlib.Path compatible)\nlocal = PanPath(\"/path/to/file.txt\")\ncontent = local.read_text()\n\n# S3 (synchronous)\ns3_file = PanPath(\"s3://bucket/key/file.txt\")\ncontent = s3_file.read_text()\n\n# Google Cloud Storage\ngs_file = PanPath(\"gs://bucket/path/file.txt\")\ncontent = gs_file.read_text()\n\n# Azure Blob Storage\nazure_file = PanPath(\"az://container/path/file.txt\")\ncontent = azure_file.read_text()\n</code></pre> <pre><code>from panpath import PanPath\n\n# Same class, async methods with a_ prefix\ns3 = PanPath(\"s3://bucket/file.txt\")\ncontent = await s3.a_read_text()\n\n# Works for all storage types\nlocal = PanPath(\"/path/to/file.txt\")\ncontent = await local.a_read_text()\n</code></pre> <pre><code>from panpath import PanPath\n\n# Copy from S3 to GCS\ns3_file = PanPath(\"s3://my-bucket/data.csv\")\ns3_file.copy(\"gs://other-bucket/data.csv\")\n\n# Copy entire directory from cloud to local\ncloud_dir = PanPath(\"s3://data-lake/dataset/\")\ncloud_dir.copytree(\"/tmp/dataset/\")\n\n# Move between cloud providers\nazure_file = PanPath(\"az://container/file.txt\")\nazure_file.rename(\"s3://bucket/file.txt\")\n</code></pre>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":"<p>Install the core library:</p> <pre><code>pip install panpath\n</code></pre> <p>With cloud storage support:</p> S3Google Cloud StorageAzure Blob StorageAll Backends <pre><code>pip install panpath[s3]        # Sync\npip install panpath[async-s3]  # Async\n</code></pre> <pre><code>pip install panpath[gs]        # Sync\npip install panpath[async-gs]  # Async\n</code></pre> <pre><code>pip install panpath[azure]        # Sync\npip install panpath[async-azure]  # Async\n</code></pre> <pre><code>pip install panpath[all-sync]   # All sync backends\npip install panpath[all-async]  # All async backends\npip install panpath[all]        # Everything\n</code></pre>"},{"location":"#use-cases","title":"\ud83c\udfaf Use Cases","text":"<p>Local Development \u2192 Cloud Production: Write code using local paths during development, switch to cloud paths in production with minimal changes.</p> <p>Multi-Cloud Applications: Build applications that work with multiple cloud providers without vendor lock-in.</p> <p>Data Pipelines: Create ETL pipelines that seamlessly move data between local storage and cloud services.</p> <p>Async I/O: Leverage async/await for high-performance cloud operations in async frameworks like FastAPI, aiohttp, or asyncio scripts.</p> <p>Testing: Use local paths in tests, cloud paths in production - same code, different backends.</p>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":"<ul> <li> <p> Getting Started</p> <p>Installation, quick start, and basic concepts</p> </li> <li> <p> User Guide</p> <p>Comprehensive guides for all features</p> </li> <li> <p> Cloud Providers</p> <p>Provider-specific documentation and examples</p> </li> <li> <p> API Reference</p> <p>Complete API documentation with examples</p> </li> </ul>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Contributions are welcome! Please see our Contributing Guide for details.</p>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#acknowledgments","title":"\ud83d\ude4f Acknowledgments","text":"<p>PanPath is inspired by:</p> <ul> <li>pathlib - Python's standard library for filesystem paths</li> <li>cloudpathlib - Path-like interface for cloud storage</li> </ul> <p>Made with \u2764\ufe0f by the PanPath contributors</p> <p> GitHub \u2022     PyPI \u2022     Issues </p>"},{"location":"about/changelog/","title":"Changelog","text":""},{"location":"about/changelog/#047","title":"[0.4.7]","text":"<ul> <li>fix: update gcloud-aio-storage version to 9.5 in pyproject.toml (supporting storage.compose)</li> <li>fix: ensure unique temporary blob names and cleanup in upload methods for GSAsyncFileHandle and GSSyncFileHandle to avoid rate limit for object mutation operations</li> <li>fix: remove unnecessary type ignore comments for PanPath instantiation in cloud and local path implementations</li> </ul>"},{"location":"about/changelog/#046","title":"[0.4.6]","text":"<ul> <li>fix: update loop cleanup registration attributes for Azure, Google Cloud, and S3 clients</li> <li>feat: implement upload methods with append semantics for Azure, Google Cloud, and S3 clients; add upload warning threshold</li> </ul>"},{"location":"about/changelog/#045","title":"[0.4.5]","text":"<ul> <li>feat: add follow_symlinks parameter to a_stat methods for better symlink handling</li> </ul>"},{"location":"about/changelog/#044","title":"[0.4.4]","text":"<ul> <li>fix: update async file copying logic to use async for and correct path handling</li> </ul>"},{"location":"about/changelog/#043","title":"[0.4.3]","text":"<ul> <li>fix: correct variable name in fnmatch condition for blob retrieval in AsyncGSClient</li> </ul>"},{"location":"about/changelog/#042","title":"[0.4.2]","text":"<ul> <li>chore: update a_glob method to return AsyncGenerator for asynchronous path matching</li> <li>refactor: remove _return_panpath parameter from glob and walk methods in Azure, GS, and S3 clients</li> <li>fix: update return types to use AsyncGenerator and Iterator for async methods in path classes</li> <li>fix: remove redundant a_replace abstract method from PanPath class</li> <li>style: update method signatures to include additional parameters and return types across various clients</li> </ul>"},{"location":"about/changelog/#041","title":"[0.4.1]","text":"<ul> <li>chore: add missing_ok parameter to a_unlink method for optional error handling</li> <li>feat: update typing hints to use Iterator for glob and walk methods in GSClient and S3Client</li> </ul>"},{"location":"about/changelog/#040","title":"[0.4.0]","text":"<ul> <li>fix: correct async file read method in README example</li> <li>feat: refactor async client methods and enhance LocalPath functionality</li> </ul>"},{"location":"about/changelog/#030","title":"[0.3.0]","text":""},{"location":"about/changelog/#new-features","title":"\ud83d\ude80 New Features","text":""},{"location":"about/changelog/#async-file-handle-enhancements","title":"Async File Handle Enhancements","text":"<ul> <li><code>tell()</code> and <code>seek()</code> methods: Added <code>tell()</code> and <code>seek()</code> methods to async file handle classes for S3, GCS, and Azure clients, enabling better control over file position during async read/write operations</li> </ul>"},{"location":"about/changelog/#resource-management","title":"Resource Management","text":"<ul> <li>Async cleanup for GCS: Implemented async cleanup for active storage instances in <code>AsyncGSClient</code>, improving resource management and preventing resource leaks</li> </ul>"},{"location":"about/changelog/#refactoring-architecture-improvements","title":"\ud83d\udd27 Refactoring &amp; Architecture Improvements","text":""},{"location":"about/changelog/#client-architecture","title":"Client Architecture","text":"<ul> <li>Optimized async client architecture: Refactored cloud async clients (Azure, GCS, S3) for better code organization and maintainability</li> <li>Sync client refactoring: Refactored synchronous clients with improved structure and enhanced test coverage</li> <li>Base client classes: Introduced base <code>Client</code>, <code>SyncClient</code>, and <code>AsyncClient</code> classes for better code reuse and consistency across cloud providers</li> </ul>"},{"location":"about/changelog/#code-quality","title":"Code Quality","text":"<ul> <li>Enhanced error handling: Improved error handling and path parsing logic across all client classes</li> <li>Better code organization: Consolidated common methods in base classes, reducing code duplication</li> </ul>"},{"location":"about/changelog/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Cloud async clients: Fixed various issues in cloud async clients for more reliable async operations</li> <li>Warning suppression: Added warning suppression for <code>FutureWarning</code> in Google Cloud Storage import</li> </ul>"},{"location":"about/changelog/#testing-improvements","title":"\ud83e\uddea Testing Improvements","text":"<ul> <li>Increased test coverage: Significantly improved test coverage across all modules</li> <li>Comprehensive test suites: Added extensive test suites for all client classes:</li> <li><code>AzureBlobClient</code> tests covering initialization, path parsing, file operations, metadata, symlinks, and directory operations</li> <li><code>GSClient</code> tests with comprehensive coverage of GCS operations</li> <li><code>S3Client</code> tests with thorough validation of S3 operations</li> <li>New <code>test_cloudpath.py</code> with 1000+ lines of comprehensive tests</li> <li>Edge case coverage: Enhanced tests to cover edge cases and error scenarios for robust validation</li> </ul>"},{"location":"about/changelog/#statistics","title":"\ud83d\udcca Statistics","text":"<ul> <li>Test improvements: Added 2,000+ lines of comprehensive tests</li> <li>Code consolidation: Removed redundant test files, streamlining the test suite</li> <li>Coverage increase: Improved overall code coverage with better test organization</li> </ul>"},{"location":"about/changelog/#020-2025-12-18","title":"[0.2.0] - 2025-12-18","text":""},{"location":"about/changelog/#overview","title":"Overview","text":"<p>Version 0.2.0 represents a major refactoring and enhancement of PanPath, focusing on improved architecture, better async support, and enhanced cloud provider implementations. This release includes significant internal reorganization while maintaining API compatibility.</p>"},{"location":"about/changelog/#new-features_1","title":"\ud83d\ude80 New Features","text":""},{"location":"about/changelog/#enhanced-async-file-handle-support","title":"Enhanced Async File Handle Support","text":"<ul> <li>Async file handles for all cloud providers: Implemented native async file handle support for Azure, Google Cloud Storage, and S3 clients</li> <li>Dedicated storage instances: Enhanced <code>AsyncGSClient</code> to manage dedicated Storage instances for file handles, improving resource management and performance</li> </ul>"},{"location":"about/changelog/#optimized-path-initialization","title":"Optimized Path Initialization","text":"<ul> <li>Instance caching: PanPath now returns existing instances when initialized with the same path, reducing memory overhead and improving performance</li> <li>Python version compatibility: Enhanced <code>LocalPath</code> and <code>PanPath</code> initialization to better handle different Python versions</li> </ul>"},{"location":"about/changelog/#refactoring-architecture-improvements_1","title":"\ud83d\udd27 Refactoring &amp; Architecture Improvements","text":""},{"location":"about/changelog/#code-organization","title":"Code Organization","text":"<ul> <li>Base module restructuring: Renamed <code>base</code> module to <code>cloud</code> for better clarity and semantic meaning</li> <li>New path classes: Introduced dedicated path classes for cloud providers:</li> <li><code>AzurePath</code> (renamed from <code>AzureBlobPath</code> for consistency)</li> <li><code>GSPath</code> for Google Cloud Storage</li> <li><code>S3Path</code> for Amazon S3</li> <li>Base classes consolidation: Created <code>CloudPath</code> and <code>AsyncCloudPath</code> base classes to encapsulate common functionality for synchronous and asynchronous cloud path operations</li> </ul>"},{"location":"about/changelog/#import-structure-updates","title":"Import Structure Updates","text":"<ul> <li>Updated import paths from <code>panpath.base</code> to <code>panpath.cloud</code></li> <li>Refactored cloud path implementations (S3, GCS, Azure) to inherit from new base classes</li> <li>Consolidated imports across test files to streamline dependencies</li> </ul>"},{"location":"about/changelog/#registry-improvements","title":"Registry Improvements","text":"<ul> <li>Registered new path classes in the registry for better URI handling</li> <li>Enhanced path routing and resolution</li> </ul>"},{"location":"about/changelog/#documentation","title":"\ud83d\udcda Documentation","text":""},{"location":"about/changelog/#api-documentation","title":"API Documentation","text":"<ul> <li>mkapi integration: Adopted mkapi for automated API documentation generation</li> <li>Updated examples: Refreshed async file reading examples for consistency in PanPath usage</li> <li>Enhanced styling: Added custom CSS for improved documentation presentation</li> </ul>"},{"location":"about/changelog/#documentation-updates","title":"Documentation Updates","text":"<ul> <li>Updated documentation for new path classes and methods</li> <li>Improved clarity in async operations guide</li> <li>Enhanced provider-specific documentation (S3, GCS, Azure)</li> </ul>"},{"location":"about/changelog/#testing-improvements_1","title":"\ud83e\uddea Testing Improvements","text":""},{"location":"about/changelog/#test-suite-enhancements","title":"Test Suite Enhancements","text":"<ul> <li>Updated test cases to utilize PanPath for both sync and async operations</li> <li>Removed redundant tests for invalid modes and path equality checks</li> <li>Enhanced async method checks in tests for S3 and local paths</li> <li>Consolidated test dependencies and improved test organization</li> </ul>"},{"location":"about/changelog/#breaking-changes","title":"\ud83d\udd04 Breaking Changes","text":""},{"location":"about/changelog/#module-renames","title":"Module Renames","text":"<ul> <li>\u26a0\ufe0f Import path change: <code>panpath.base</code> \u2192 <code>panpath.cloud</code></li> <li>If you were directly importing from <code>panpath.base</code>, update to <code>panpath.cloud</code></li> <li>Example: <code>from panpath.cloud import CloudPath, AsyncCloudPath</code></li> </ul>"},{"location":"about/changelog/#class-renames","title":"Class Renames","text":"<ul> <li>\u26a0\ufe0f AzureBlobPath \u2192 AzurePath</li> <li>For consistency with other providers (S3Path, GSPath)</li> <li>Direct usage of class names should be updated</li> </ul>"},{"location":"about/changelog/#statistics_1","title":"\ud83d\udcca Statistics","text":"<ul> <li>61 files changed: 2,899 insertions, 3,717 deletions</li> <li>Net reduction: ~800 lines of code while adding significant functionality</li> <li>Improved code quality: Better separation of concerns and cleaner architecture</li> </ul>"},{"location":"about/changelog/#010-2025-12-17","title":"[0.1.0] - 2025-12-17","text":""},{"location":"about/changelog/#added","title":"Added","text":"<ul> <li>Core Features</li> <li>Unified <code>PanPath</code> interface for local and cloud storage</li> <li>Support for Amazon S3, Google Cloud Storage, and Azure Blob Storage</li> <li>Synchronous and asynchronous operation modes</li> <li>Pathlib-compatible interface for local files</li> <li> <p>Lazy client loading for better performance</p> </li> <li> <p>Path Operations</p> </li> <li>All standard pathlib operations (<code>read_text</code>, <code>write_text</code>, <code>exists</code>, etc.)</li> <li>Path manipulation (<code>parent</code>, <code>name</code>, <code>stem</code>, <code>suffix</code>, <code>with_*</code>)</li> <li>Pattern matching (<code>glob</code>, <code>rglob</code>, <code>match</code>)</li> <li> <p>Directory traversal (<code>iterdir</code>, <code>walk</code>)</p> </li> <li> <p>Bulk Operations</p> </li> <li><code>rmtree()</code> - Remove directory and all contents</li> <li><code>copy()</code> - Copy files with cross-storage support</li> <li><code>copytree()</code> - Copy entire directory trees</li> <li> <p><code>rename()</code> - Enhanced rename with cross-storage support</p> </li> <li> <p>Cloud Features</p> </li> <li>Server-side copy optimization (same-backend transfers)</li> <li>Cross-storage transfers (copy between different cloud providers)</li> <li>Automatic multipart upload for large files</li> <li> <p>Cloud-specific properties (<code>cloud_prefix</code>, <code>key</code>, <code>bucket</code>)</p> </li> <li> <p>Async Support</p> </li> <li>Full async/await support for all operations</li> <li><code>AsyncPanPath</code> for always-async usage</li> <li>Async context managers for file operations</li> <li> <p>Parallel async operations with <code>asyncio.gather</code></p> </li> <li> <p>Developer Experience</p> </li> <li>Type hints throughout</li> <li>Optional dependencies (install only what you need)</li> <li>Comprehensive test suite with 114+ passing tests</li> <li> <p>Cloudpathlib compatibility layer</p> </li> <li> <p>Documentation</p> </li> <li>Complete Material for MkDocs documentation</li> <li>Getting started guides</li> <li>User guide with examples</li> <li>Provider-specific documentation</li> <li>API reference</li> <li>Migration guides from pathlib and cloudpathlib</li> </ul>"},{"location":"about/changelog/#changed","title":"Changed","text":"<ul> <li>N/A (initial release)</li> </ul>"},{"location":"about/changelog/#deprecated","title":"Deprecated","text":"<ul> <li>N/A (initial release)</li> </ul>"},{"location":"about/changelog/#removed","title":"Removed","text":"<ul> <li>N/A (initial release)</li> </ul>"},{"location":"about/changelog/#fixed","title":"Fixed","text":"<ul> <li>N/A (initial release)</li> </ul>"},{"location":"about/changelog/#security","title":"Security","text":"<ul> <li>N/A (initial release)</li> </ul>"},{"location":"about/changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"about/changelog/#planned-features","title":"Planned Features","text":"<ul> <li>File caching support</li> <li>Progress callbacks for bulk operations</li> <li>Streaming uploads and downloads</li> <li>Additional cloud provider support</li> <li>Performance optimizations</li> <li>Enhanced error messages</li> </ul>"},{"location":"about/changelog/#release-notes","title":"Release Notes","text":""},{"location":"about/changelog/#version-010-initial-release","title":"Version 0.1.0 - Initial Release","text":"<p>This is the initial release of PanPath, providing a unified interface for working with local and cloud storage.</p> <p>Highlights:</p> <p>\u2728 Unified API - Same interface for local files, S3, GCS, and Azure \u26a1 Async Support - Full async/await for high-performance I/O \ud83d\udd04 Cross-Storage - Copy files between different cloud providers \ud83d\udce6 Optional Dependencies - Install only what you need \ud83c\udfaf Pathlib Compatible - Drop-in replacement for pathlib.Path</p> <p>Supported Operations:</p> <ul> <li>Reading and writing files (text and binary)</li> <li>Path manipulation and querying</li> <li>Directory operations (list, walk, glob)</li> <li>Bulk operations (copy, move, delete trees)</li> <li>Cross-storage transfers</li> <li>Async and sync modes</li> </ul> <p>Supported Backends:</p> <ul> <li>Local filesystem</li> <li>Amazon S3 (sync and async)</li> <li>Google Cloud Storage (sync and async)</li> <li>Azure Blob Storage (sync and async)</li> </ul> <p>Installation:</p> <pre><code>pip install panpath[all]\n</code></pre> <p>Quick Example:</p> <pre><code>from panpath import PanPath\n\n# Works the same for local and cloud\nlocal = PanPath(\"/tmp/file.txt\")\ns3 = PanPath(\"s3://bucket/file.txt\")\ngs = PanPath(\"gs://bucket/file.txt\")\n\n# Same operations\nfor path in [local, s3, gs]:\n    path.write_text(\"Hello, PanPath!\")\n    print(path.read_text())\n</code></pre>"},{"location":"about/changelog/#contributing","title":"Contributing","text":"<p>See CONTRIBUTING.md for information on how to contribute to PanPath.</p>"},{"location":"about/changelog/#links","title":"Links","text":"<ul> <li>PyPI</li> <li>GitHub Repository</li> <li>Documentation</li> <li>Issue Tracker</li> </ul>"},{"location":"about/cloudpathlib-compat/","title":"Cloudpathlib Compatibility","text":"<p>This document describes PanPath's compatibility with cloudpathlib and the tests adapted from their comprehensive test suite.</p>"},{"location":"about/cloudpathlib-compat/#overview","title":"Overview","text":"<p>PanPath provides a cloudpathlib-compatible interface for path operations across S3, GCS, and Azure Blob Storage. While the internal architecture differs (metaclass-based routing vs class hierarchy, explicit sync/async separation), the public API is designed to be compatible with cloudpathlib's interface.</p>"},{"location":"about/cloudpathlib-compat/#test-coverage","title":"Test Coverage","text":"<p>We've adapted key tests from cloudpathlib's test suite to verify compatibility:</p>"},{"location":"about/cloudpathlib-compat/#path-manipulation-testpathmanipulation","title":"\u2705 Path Manipulation (<code>TestPathManipulation</code>)","text":"<ul> <li>Properties: <code>name</code>, <code>stem</code>, <code>suffix</code>, <code>suffixes</code>, <code>parts</code></li> <li>Path operations: <code>with_suffix()</code>, <code>with_stem()</code>, <code>with_name()</code></li> <li>Joins: <code>/</code> operator, <code>joinpath()</code>, <code>parent</code>, <code>parents</code></li> <li>Cloud-specific: <code>cloud_prefix</code>, <code>key</code> properties</li> <li>Comparison: Equality, hashing, sorting</li> <li>Pattern matching: <code>match()</code> with glob patterns (including <code>**</code> recursive)</li> <li>URI operations: <code>as_uri()</code>, <code>absolute()</code>, <code>is_absolute()</code></li> </ul>"},{"location":"about/cloudpathlib-compat/#path-instantiation-testpathinstantiation","title":"\u2705 Path Instantiation (<code>TestPathInstantiation</code>)","text":"<ul> <li>Dispatch: <code>PanPath()</code> correctly routes to S3/GCS/Azure implementations</li> <li>Error handling: Invalid modes, unsupported schemes</li> <li>Idempotency: <code>PanPath(PanPath(...))</code> preserves type</li> <li>Local paths: Dispatches to <code>LocalPath</code></li> </ul>"},{"location":"about/cloudpathlib-compat/#azure-scheme-aliases-testazureschemealiases","title":"\u2705 Azure Scheme Aliases (<code>TestAzureSchemeAliases</code>)","text":"<ul> <li>Both <code>az://</code> and <code>azure://</code> schemes supported</li> <li>Original scheme preserved in string representation</li> </ul>"},{"location":"about/cloudpathlib-compat/#type-preservation-testtypepreservation","title":"\u2705 Type Preservation (<code>TestTypePreservation</code>)","text":"<ul> <li><code>parent</code> returns same type as original path</li> <li><code>joinpath</code> and <code>/</code> operator preserve type</li> <li><code>with_suffix()</code>, <code>with_name()</code>, <code>with_stem()</code> preserve type</li> </ul>"},{"location":"about/cloudpathlib-compat/#string-operations-teststringoperations","title":"\u2705 String Operations (<code>TestStringOperations</code>)","text":"<ul> <li>Proper URI format with double slashes: <code>s3://bucket/key</code></li> <li><code>__repr__</code> includes class name and path</li> <li><code>__fspath__</code> returns string representation</li> </ul>"},{"location":"about/cloudpathlib-compat/#cross-platform-testcrossplatform","title":"\u2705 Cross-Platform (<code>TestCrossPlatform</code>)","text":"<ul> <li>Tests verify operations work identically across S3, GCS, and Azure</li> </ul>"},{"location":"about/cloudpathlib-compat/#path-comparison-testpathcomparison","title":"\u2705 Path Comparison (<code>TestPathComparison</code>)","text":"<ul> <li>Different buckets/containers not equal</li> <li>Different providers not equal</li> <li>Sync vs async paths not equal</li> <li>Same paths are equal with consistent hashing</li> </ul>"},{"location":"about/cloudpathlib-compat/#architecture-differences","title":"Architecture Differences","text":""},{"location":"about/cloudpathlib-compat/#panpath-vs-cloudpathlib","title":"PanPath vs cloudpathlib","text":"Feature PanPath cloudpathlib Routing Metaclass (<code>PanPathMeta</code>) Class hierarchy Sync/Async Single class Not supported Caching Not implemented <code>FileCacheMode</code> support Client management Lazy client creation, registry-based Client instances with providers Local paths Explicit <code>LocalPath</code> No local path support"},{"location":"about/cloudpathlib-compat/#whats-compatible","title":"What's Compatible","text":"<p>\u2705 Path operations: All pathlib-like operations (joinpath, parent, with_suffix, etc.) \u2705 Cloud properties: <code>cloud_prefix</code>, <code>key</code> \u2705 File I/O: <code>read_text()</code>, <code>write_text()</code>, <code>read_bytes()</code>, <code>write_bytes()</code> \u2705 Path queries: <code>exists()</code>, <code>is_file()</code>, <code>is_dir()</code>, <code>stat()</code> \u2705 Directory operations: <code>iterdir()</code> (sync), <code>iterdir()</code> returns list (async) \u2705 Pattern matching: <code>match()</code> with glob patterns \u2705 URI operations: <code>as_uri()</code>, <code>__str__</code>, <code>__fspath__</code> \u2705 Equality and comparison: <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>hash()</code></p>"},{"location":"about/cloudpathlib-compat/#whats-different","title":"What's Different","text":"<p>\u274c Caching: PanPath doesn't implement file caching (no <code>FileCacheMode</code>) \u274c Test rigs: cloudpathlib uses <code>CloudProviderTestRig</code> pattern; PanPath uses simpler mocking \u274c Mock clients: cloudpathlib has filesystem-based SDK mocks; PanPath mocks at sys.modules level \u26a0\ufe0f Async iterdir: PanPath's async version returns a list, not an async generator \u26a0\ufe0f Client API: Different client initialization and configuration</p>"},{"location":"about/cloudpathlib-compat/#test-results","title":"Test Results","text":"<pre><code>tests/test_cloudpath_compat.py::TestPathManipulation          12/12 passed \u2705\ntests/test_cloudpath_compat.py::TestPathInstantiation         6/6 passed   \u2705\ntests/test_cloudpath_compat.py::TestAzureSchemeAliases        2/2 passed   \u2705\ntests/test_cloudpath_compat.py::TestTypePreservation          4/4 passed   \u2705\ntests/test_cloudpath_compat.py::TestStringOperations          3/3 passed   \u2705\ntests/test_cloudpath_compat.py::TestCrossPlatform             1/1 passed   \u2705\ntests/test_cloudpath_compat.py::TestPathComparison            3/3 passed   \u2705\n\nTotal: 31/31 tests passed \u2705\n</code></pre>"},{"location":"about/cloudpathlib-compat/#migration-from-cloudpathlib","title":"Migration from cloudpathlib","text":"<p>If you're migrating from cloudpathlib to PanPath:</p>"},{"location":"about/cloudpathlib-compat/#these-work-identically","title":"\u2705 These work identically:","text":"<pre><code># Path creation\npath = PanPath(\"s3://bucket/key.txt\")  # Same as CloudPath\n\n# Path operations\nparent = path.parent\nnew_path = path / \"subdir\" / \"file.txt\"\nrenamed = path.with_suffix(\".md\")\n\n# File I/O\ncontent = path.read_text()\npath.write_text(\"data\")\n\n# Properties\nbucket = path.cloud_prefix  # \"s3://bucket\"\nkey = path.key              # \"key.txt\"\n</code></pre>"},{"location":"about/cloudpathlib-compat/#these-need-changes","title":"\u26a0\ufe0f These need changes:","text":"<pre><code># Async iterdir returns list, not async generator\n# cloudpathlib: async for item in path.iterdir():\n# PanPath:\nitems = await path.a_iterdir()\nfor item in items:\n    ...\n\n# No caching support\n# cloudpathlib: path.fspath  # Returns local cached path\n# PanPath: Not supported - use read_bytes()/write_bytes() directly\n</code></pre>"},{"location":"about/cloudpathlib-compat/#implementation-notes","title":"Implementation Notes","text":""},{"location":"about/cloudpathlib-compat/#methods-added-for-compatibility","title":"Methods Added for Compatibility","text":"<p>To ensure cloudpathlib compatibility, we added these methods to <code>CloudPath</code> and <code>AsyncCloudPath</code>:</p> <ul> <li><code>absolute()</code> - Returns self (cloud paths are always absolute)</li> <li><code>is_absolute()</code> - Always returns True</li> <li><code>as_uri()</code> - Returns the string representation (already a URI)</li> <li><code>match(pattern)</code> - Glob pattern matching against the key portion</li> </ul>"},{"location":"about/cloudpathlib-compat/#match-pattern-implementation","title":"Match Pattern Implementation","text":"<p>The <code>match()</code> method was specifically adapted for cloud paths: - Matches against the key portion only (excluding scheme and bucket) - Supports <code>**</code> recursive patterns - Uses <code>PurePosixPath.match()</code> internally for correct glob behavior</p> <p>Example: <pre><code>path = PanPath(\"s3://bucket/dir/subdir/file.py\")\npath.match(\"**/*.py\")      # True - matches file.py anywhere\npath.match(\"**/subdir/*\")  # True - matches in subdir\npath.match(\"dir/*/file.py\") # True - matches with wildcard\n</code></pre></p>"},{"location":"about/cloudpathlib-compat/#coverage-impact","title":"Coverage Impact","text":"<p>Adding cloudpathlib compatibility tests increased: - Total tests: 70 \u2192 101 tests (+44%) - Code coverage: 52% \u2192 53% - <code>cloud.py</code> coverage: 72% \u2192 73%</p>"},{"location":"about/cloudpathlib-compat/#future-enhancements","title":"Future Enhancements","text":"<p>Potential areas for further cloudpathlib compatibility:</p> <ol> <li>Caching support - Implement <code>FileCacheMode</code> and local caching</li> <li>Glob operations - Add <code>glob()</code>, <code>rglob()</code> methods</li> <li>Walk operations - Add <code>walk()</code> method for directory traversal</li> <li>Copy/upload operations - Add <code>copy()</code>, <code>upload_from()</code> methods</li> <li>Async generators - Make <code>iterdir()</code> an async generator for consistency</li> </ol>"},{"location":"about/cloudpathlib-compat/#references","title":"References","text":"<ul> <li>cloudpathlib GitHub</li> <li>cloudpathlib Documentation</li> </ul>"},{"location":"about/license/","title":"License","text":""},{"location":"about/license/#mit-license","title":"MIT License","text":"<p>Copyright \u00a9 2025 panpath contributors</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"about/license/#third-party-licenses","title":"Third-Party Licenses","text":"<p>PanPath depends on several open-source libraries. Below are their licenses:</p>"},{"location":"about/license/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>typing-extensions - Python Software Foundation License</li> </ul>"},{"location":"about/license/#optional-cloud-dependencies","title":"Optional Cloud Dependencies","text":"<ul> <li>boto3 (S3 sync) - Apache License 2.0</li> <li>aioboto3 (S3 async) - Apache License 2.0</li> <li>google-cloud-storage (GCS sync) - Apache License 2.0</li> <li>gcloud-aio-storage (GCS async) - MIT License</li> <li>azure-storage-blob (Azure) - MIT License</li> <li>aiofiles (async file I/O) - Apache License 2.0</li> </ul>"},{"location":"about/license/#development-dependencies","title":"Development Dependencies","text":"<ul> <li>pytest - MIT License</li> <li>mypy - MIT License</li> <li>black - MIT License</li> <li>ruff - MIT License</li> </ul>"},{"location":"about/license/#documentation-dependencies","title":"Documentation Dependencies","text":"<ul> <li>mkdocs - BSD License</li> <li>mkdocs-material - MIT License</li> <li>mkdocstrings - ISC License</li> </ul>"},{"location":"about/license/#attribution","title":"Attribution","text":"<p>PanPath is inspired by:</p> <ul> <li>pathlib - Python's standard library for filesystem paths</li> <li>cloudpathlib - Path-like interface for cloud storage</li> </ul> <p>We are grateful to the maintainers and contributors of these projects.</p>"},{"location":"about/license/#contributing","title":"Contributing","text":"<p>By contributing to PanPath, you agree that your contributions will be licensed under the MIT License.</p> <p>See CONTRIBUTING.md for more information.</p>"},{"location":"about/license/#questions","title":"Questions?","text":"<p>If you have questions about licensing, please open an issue or contact the maintainers.</p>"},{"location":"advanced/configuration/","title":"Configuration","text":"<p>Advanced configuration options for PanPath.</p>"},{"location":"advanced/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"advanced/configuration/#aws-s3","title":"AWS S3","text":"<pre><code>export AWS_ACCESS_KEY_ID=your_key\nexport AWS_SECRET_ACCESS_KEY=your_secret\nexport AWS_DEFAULT_REGION=us-east-1\n</code></pre>"},{"location":"advanced/configuration/#google-cloud","title":"Google Cloud","text":"<pre><code>export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json\n</code></pre>"},{"location":"advanced/configuration/#azure","title":"Azure","text":"<pre><code>export AZURE_STORAGE_CONNECTION_STRING=your_connection_string\n</code></pre>"},{"location":"advanced/configuration/#custom-clients","title":"Custom Clients","text":"<pre><code>from panpath import PanPath\nfrom panpath.clients import get_s3_client\n\n# Configure S3 client\nget_s3_client(\n    aws_access_key_id=\"key\",\n    aws_secret_access_key=\"secret\",\n    region_name=\"us-west-2\"\n)\n\n# Use configured client\npath = PanPath(\"s3://bucket/file.txt\")\n</code></pre>"},{"location":"advanced/configuration/#see-also","title":"See Also","text":"<ul> <li>Provider Documentation - Provider-specific config</li> <li>Custom Clients - Advanced client management</li> </ul>"},{"location":"advanced/custom-clients/","title":"Custom Clients","text":"<p>Advanced client management and customization.</p>"},{"location":"advanced/custom-clients/#getting-clients","title":"Getting Clients","text":"<pre><code>from panpath.clients import get_s3_client, get_gs_client, get_azure_client\n\n# Get or create S3 client\ns3_client = get_s3_client(\n    aws_access_key_id=\"key\",\n    aws_secret_access_key=\"secret\"\n)\n\n# Get or create GCS client\ngs_client = get_gs_client()\n\n# Get or create Azure client\nazure_client = get_azure_client(\n    connection_string=\"connection_string\"\n)\n</code></pre>"},{"location":"advanced/custom-clients/#custom-endpoints","title":"Custom Endpoints","text":"<p>For S3-compatible services:</p> <pre><code>from panpath.clients import get_s3_client\n\n# MinIO\nget_s3_client(\n    endpoint_url=\"http://localhost:9000\",\n    aws_access_key_id=\"minioadmin\",\n    aws_secret_access_key=\"minioadmin\"\n)\n</code></pre>"},{"location":"advanced/custom-clients/#see-also","title":"See Also","text":"<ul> <li>Configuration - Basic configuration</li> <li>Provider Documentation - Provider specifics</li> </ul>"},{"location":"advanced/performance/","title":"Performance","text":"<p>Optimization tips and best practices for PanPath.</p>"},{"location":"advanced/performance/#use-async-for-concurrency","title":"Use Async for Concurrency","text":"<pre><code># Slow: Sequential\nfrom panpath import PanPath\n\nfor i in range(100):\n    path = PanPath(f\"s3://bucket/file{i}.txt\")\n    content = path.read_text()\n\n# Fast: Concurrent\nfrom panpath import PanPath\nimport asyncio\n\nasync def read_all():\n    paths = [PanPath(f\"s3://bucket/file{i}.txt\") for i in range(100)]\n    contents = await asyncio.gather(*[p.a_read_text() for p in paths])\n    return contents\n\nasyncio.run(read_all())\n</code></pre>"},{"location":"advanced/performance/#server-side-operations","title":"Server-Side Operations","text":"<p>Use server-side operations when possible:</p> <pre><code>from panpath import PanPath\n\n# Fast: Server-side copy (no download/upload)\nsrc = PanPath(\"s3://bucket/file.txt\")\nsrc.copy(\"s3://bucket/backup/file.txt\")\n\n# Slow: Download then upload\ncontent = src.read_bytes()\ndst = PanPath(\"s3://bucket/backup/file.txt\")\ndst.write_bytes(content)\n</code></pre>"},{"location":"advanced/performance/#bulk-operations","title":"Bulk Operations","text":"<pre><code>from panpath import PanPath\n\n# Efficient: Single copytree operation\nsrc_dir = PanPath(\"s3://bucket/data/\")\nsrc_dir.copytree(\"s3://bucket/backup/\")\n\n# Inefficient: Individual copies\nfor file in src_dir.rglob(\"*\"):\n    if file.is_file():\n        rel_path = file.relative_to(src_dir)\n        file.copy(PanPath(\"s3://bucket/backup/\") / rel_path)\n</code></pre>"},{"location":"advanced/performance/#see-also","title":"See Also","text":"<ul> <li>Async Operations - Async patterns</li> <li>Bulk Operations - Efficient operations</li> </ul>"},{"location":"advanced/testing/","title":"Testing","text":"<p>Testing applications that use PanPath.</p>"},{"location":"advanced/testing/#using-local-paths-for-tests","title":"Using Local Paths for Tests","text":"<p>The simplest approach is to use local paths during testing:</p> <pre><code>import pytest\nfrom panpath import PanPath\n\ndef test_file_processing():\n    # Use local path instead of cloud\n    path = PanPath(\"/tmp/test-file.txt\")\n    path.write_text(\"test content\")\n\n    # Your processing logic\n    result = process_file(path)\n\n    assert result == expected\n\ndef process_file(path: PanPath) -&gt; str:\n    \"\"\"Works with both local and cloud paths.\"\"\"\n    content = path.read_text()\n    return content.upper()\n</code></pre>"},{"location":"advanced/testing/#mocking-cloud-clients","title":"Mocking Cloud Clients","text":"<p>For more advanced testing:</p> <pre><code>from unittest.mock import Mock, patch\nfrom panpath import PanPath\n\n@patch('panpath.clients.get_s3_client')\ndef test_s3_operation(mock_get_client):\n    mock_client = Mock()\n    mock_get_client.return_value = mock_client\n\n    # Test your code\n    path = PanPath(\"s3://bucket/file.txt\")\n    # ...\n</code></pre>"},{"location":"advanced/testing/#see-also","title":"See Also","text":"<ul> <li>Contributing - Development setup</li> <li>Quick Start - Basic usage</li> </ul>"},{"location":"api/panpath.azure_async_client/","title":"panpath.azure_async_client","text":"module &lt;/&gt; <p>Async Azure Blob Storage client implementation.</p> Classes <ul> <li><code>AsyncAzureBlobClient</code> \u2014 Asynchronous Azure Blob Storage client implementation.&lt;/&gt;</li> <li><code>AzureAsyncFileHandle</code> \u2014 Async file handle for Azure with chunked streaming support.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.clients.AsyncClient panpath.clients.Client <p>Asynchronous Azure Blob Storage client implementation.</p> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncClient) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the client and cleanup resources.&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete Azure blob.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if Azure blob exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get blob metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if Azure path is a directory.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if Azure path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a symlink (has symlink metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (list) \u2014 List Azure blobs with prefix.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty blob with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Any) \u2014 Open Azure blob for reading/writing.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read Azure blob as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read Azure blob as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set blob metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (stat_result) \u2014 Get Azure blob metadata.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2014 Write bytes to Azure blob.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to Azure blob.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read Azure blob as text.</p> method &lt;/&gt; <p>Write text to Azure blob.</p> method &lt;/&gt; <p>Check if path is a symlink (has symlink metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (bool) <p>True if path is a symlink</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (str) <p>Symlink target path</p> method &lt;/&gt; <p>Close the client and cleanup resources.</p> method &lt;/&gt; <p>Check if Azure blob exists.</p> method &lt;/&gt; <p>Read Azure blob as bytes.</p> method &lt;/&gt; <p>Write bytes to Azure blob.</p> method &lt;/&gt; <p>Delete Azure blob.</p> method &lt;/&gt; <p>List Azure blobs with prefix.</p> method &lt;/&gt; <p>Check if Azure path is a directory.</p> method &lt;/&gt; <p>Check if Azure path is a file.</p> method &lt;/&gt; <p>Get Azure blob metadata.</p> method &lt;/&gt; <p>Open Azure blob for reading/writing.</p><p>Note: For better streaming support, use a_open() instead. This method returns a file-like object that supports the standard file API.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>mode</code> (str, optional) \u2014 File mode</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments (chunk_size, upload_warning_threshold,upload_interval supported) </li> </ul> method &lt;/&gt; <p>Create a directory marker (empty blob with trailing slash).</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path (az://container/path or azure://container/path)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed (ignored for Azure)</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Get blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> </ul> Returns (dict) <p>Dictionary of metadata key-value pairs</p> method &lt;/&gt; <p>Set blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>metadata</code> (dict) \u2014 Dictionary of metadata key-value pairs</li> </ul> method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path for the symlink</li> <li><code>target</code> (str) \u2014 Target path the symlink should point to</li> </ul> method &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base Azure path</li> <li><code>pattern</code> (str) \u2014 Glob pattern (e.g., \".txt\", \"**/.py\")</li> </ul> Yields <p>Matching paths as strings or PanPath objects</p> method &lt;/&gt; <p>Walk directory tree.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base Azure path</li> </ul> Yields <p>Tuples of (dirpath, dirnames, filenames)</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source Azure path</li> <li><code>target</code> (str) \u2014 Target Azure path</li> </ul> method &lt;/&gt; <p>Remove directory marker.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source Azure path</li> <li><code>target</code> (str) \u2014 Target Azure path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> method &lt;/&gt; <p>Copy directory tree to target recursively.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source Azure path</li> <li><code>target</code> (str) \u2014 Target Azure path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> class &lt;/&gt; Bases panpath.clients.AsyncFileHandle <p>Async file handle for Azure with chunked streaming support.</p><p>Uses Azure SDK's download_blob streaming API.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__aiter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__anext__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset the underlying stream to the beginning.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul> method &lt;/&gt; <p>Reset the underlying stream to the beginning.</p>"},{"location":"api/panpath.azure_async_client/#panpathazure_async_client","title":"panpath.azure_async_client","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclient","title":"<code>panpath.azure_async_client.</code><code>AsyncAzureBlobClient</code><code>(</code><code>connection_string=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncclientaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncClient","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncclientaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncclientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncclientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 stat_result","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientopen","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>mode=None</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientrename","title":"<code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientcopy","title":"<code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientasyncazureblobclientcopytree","title":"<code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientazureasyncfilehandle","title":"<code>panpath.azure_async_client.</code><code>AzureAsyncFileHandle</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleaiter","title":"<code>__aiter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleanext","title":"<code>__anext__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathclientsasyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.azure_async_client/#panpathazure_async_clientazureasyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/","title":"panpath.azure_client","text":"module &lt;/&gt; <p>Azure Blob Storage client implementation.</p> Classes <ul> <li><code>AzureBlobClient</code> \u2014 Synchronous Azure Blob Storage client implementation.&lt;/&gt;</li> <li><code>AzureSyncFileHandle</code> \u2014 Synchronous file handle for Azure Blob Storage.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.clients.SyncClient panpath.clients.Client <p>Synchronous Azure Blob Storage client implementation.</p> Methods <ul> <li><code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete Azure blob.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if Azure blob exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get blob metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> (Iterator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if Azure path is a directory (has blobs with prefix).&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if Azure path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a symlink (has symlink metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (list) \u2014 List Azure blobs with prefix.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty blob with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (SyncFileHandle) \u2014 Open Azure blob for reading/writing.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read Azure blob as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set blob metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (stat_result) \u2014 Get Azure blob metadata.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> (tuple) \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2014 Write bytes to Azure blob.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Check if path is a symlink (has symlink metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (bool) <p>True if path is a symlink</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (str) <p>Symlink target path</p> method &lt;/&gt; <p>Check if Azure blob exists.</p> method &lt;/&gt; <p>Read Azure blob as bytes.</p> method &lt;/&gt; <p>Write bytes to Azure blob.</p> method &lt;/&gt; <p>Delete Azure blob.</p> method &lt;/&gt; <p>List Azure blobs with prefix.</p> method &lt;/&gt; <p>Check if Azure path is a directory (has blobs with prefix).</p> method &lt;/&gt; <p>Check if Azure path is a file.</p> method &lt;/&gt; <p>Get Azure blob metadata.</p> method &lt;/&gt; <p>Open Azure blob for reading/writing.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>mode</code> (str, optional) \u2014 File mode</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments (chunk_size, upload_warning_threshold,upload_interval supported) </li> </ul> method &lt;/&gt; <p>Create a directory marker (empty blob with trailing slash).</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path (az://container/path or azure://container/path)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Get blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> </ul> Returns (dict) <p>Dictionary of metadata key-value pairs</p> method &lt;/&gt; <p>Set blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>metadata</code> (dict) \u2014 Dictionary of metadata key-value pairs</li> </ul> method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path for the symlink</li> <li><code>target</code> (str) \u2014 Target path the symlink should point to</li> </ul> generator &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base Azure path</li> <li><code>pattern</code> (str) \u2014 Glob pattern (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (Iterator) <p>List of matching CloudPath objects</p> generator &lt;/&gt; <p>Walk directory tree.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base Azure path</li> </ul> Yields (tuple) <p>Tuples of (dirpath, dirnames, filenames)</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>mode</code> (optional) \u2014 File mode (not supported for Azure)</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source Azure path</li> <li><code>target</code> (str) \u2014 Target Azure path</li> </ul> method &lt;/&gt; <p>Remove directory marker.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Azure path</li> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source Azure path</li> <li><code>target</code> (str) \u2014 Target Azure path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> method &lt;/&gt; <p>Copy directory tree to target recursively.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source Azure path</li> <li><code>target</code> (str) \u2014 Target Azure path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> class &lt;/&gt; Bases panpath.clients.SyncFileHandle <p>Synchronous file handle for Azure Blob Storage.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__enter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Enter context manager.&lt;/&gt;</li> <li><code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__iter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__next__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset the underlying stream to the beginning.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Enter context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul> method &lt;/&gt; <p>Reset the underlying stream to the beginning.</p>"},{"location":"api/panpath.azure_client/#panpathazure_client","title":"panpath.azure_client","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclient","title":"<code>panpath.azure_client.</code><code>AzureBlobClient</code><code>(</code><code>connection_string=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncclientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncclientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 stat_result","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientopen","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>mode=None</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientrename","title":"<code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientcopy","title":"<code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazureblobclientcopytree","title":"<code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazuresyncfilehandle","title":"<code>panpath.azure_client.</code><code>AzureSyncFileHandle</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandleenter","title":"<code>__enter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandleexit","title":"<code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandleiter","title":"<code>__iter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandlenext","title":"<code>__next__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathclientssyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.azure_client/#panpathazure_clientazuresyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/","title":"panpath.azure_path","text":"module &lt;/&gt; <p>Azure Blob Storage path implementation.</p> Classes <ul> <li><code>AzurePath</code> (CloudPath) \u2014 Azure Blob Storage path implementation (sync and async methods).&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.cloud.CloudPath panpath.base.PanPath pathlib.Path pathlib.PurePosixPath pathlib.PurePath <p>Azure Blob Storage path implementation (sync and async methods).</p> Attributes <ul> <li><code>anchor</code> \u2014 The concatenation of the drive and root, or ''.&lt;/&gt;</li> <li><code>async_client</code> (AsyncClient) \u2014 Get or create the async client for this path.&lt;/&gt;</li> <li><code>client</code> (SyncClient) \u2014 Get or create the sync client for this path.&lt;/&gt;</li> <li><code>cloud_prefix</code> (str) \u2014 Return the cloud prefix (e.g., 's3://bucket').&lt;/&gt;</li> <li><code>drive</code> \u2014 The drive prefix (letter or UNC path), if any.&lt;/&gt;</li> <li><code>key</code> (str) \u2014 Return the key/blob name without the cloud prefix.&lt;/&gt;</li> <li><code>name</code> \u2014 The final path component, if any.&lt;/&gt;</li> <li><code>parent</code> (CloudPath) \u2014 Return parent directory as same path type.&lt;/&gt;</li> <li><code>parents</code> \u2014 A sequence of this path's logical parents.&lt;/&gt;</li> <li><code>parts</code> \u2014 An object providing sequence-like access to thecomponents in the filesystem path. &lt;/&gt;</li> <li><code>root</code> \u2014 The root of the path, if any.&lt;/&gt;</li> <li><code>stem</code> \u2014 The final path component, minus its last suffix.&lt;/&gt;</li> <li><code>suffix</code> \u2014 The final component's last suffix, if any.This includes the leading period. For example: '.txt' &lt;/&gt;</li> <li><code>suffixes</code> \u2014 A list of the final component's suffixes, if any.These include the leading periods. For example: ['.tar', '.gz'] &lt;/&gt;</li> </ul> Methods <ul> <li><code>__bytes__</code><code>(</code><code>)</code> \u2014 Return the bytes representation of the path.  This is onlyrecommended to use under Unix. &lt;/&gt;</li> <li><code>__eq__</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check equality.&lt;/&gt;</li> <li><code>__hash__</code><code>(</code><code>)</code> (int) \u2014 Return hash of path.&lt;/&gt;</li> <li><code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> (CloudPath) \u2014 Create new cloud path instance.&lt;/&gt;</li> <li><code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Right join paths while preserving type and client.&lt;/&gt;</li> <li><code>__str__</code><code>(</code><code>)</code> (str) \u2014 Return properly formatted cloud URI with double slash.&lt;/&gt;</li> <li><code>__truediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>a_exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>a_glob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>a_is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>a_is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>a_is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>a_iterdir</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 List directory contents (async version returns list).&lt;/&gt;</li> <li><code>a_mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>a_open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (AsyncFileHandle) \u2014 Open file and return async file handle.&lt;/&gt;</li> <li><code>a_read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>a_read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>a_readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>a_rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>a_replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>a_resolve</code><code>(</code><code>)</code> (PanPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>a_rglob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>a_rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>a_rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>a_stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>a_touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>a_unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>a_walk</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>a_write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>a_write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to file.&lt;/&gt;</li> <li><code>absolute</code><code>(</code><code>)</code> (CloudPath) \u2014 Return absolute path - cloud paths are already absolute.&lt;/&gt;</li> <li><code>as_posix</code><code>(</code><code>)</code> \u2014 Return the string representation of the path with forward (/)slashes. &lt;/&gt;</li> <li><code>as_uri</code><code>(</code><code>)</code> (str) \u2014 Return the path as a URI (same as string representation).&lt;/&gt;</li> <li><code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks</code><code>)</code> \u2014 Change the permissions of the path, like os.chmod().&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>cwd</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the current working directory.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>expanduser</code><code>(</code><code>)</code> \u2014 Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser) &lt;/&gt;</li> <li><code>glob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>group</code><code>(</code><code>)</code> \u2014 Return the group name of the file gid.&lt;/&gt;</li> <li><code>hardlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Make this path a hard link pointing to the same file as target.&lt;/&gt;</li> <li><code>home</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')). &lt;/&gt;</li> <li><code>is_absolute</code><code>(</code><code>)</code> (bool) \u2014 Cloud paths are always absolute.&lt;/&gt;</li> <li><code>is_block_device</code><code>(</code><code>)</code> \u2014 Whether this path is a block device.&lt;/&gt;</li> <li><code>is_char_device</code><code>(</code><code>)</code> \u2014 Whether this path is a character device.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>is_fifo</code><code>(</code><code>)</code> \u2014 Whether this path is a FIFO.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>is_junction</code><code>(</code><code>)</code> \u2014 Whether this path is a junction.&lt;/&gt;</li> <li><code>is_mount</code><code>(</code><code>)</code> \u2014 Check if this path is a mount point&lt;/&gt;</li> <li><code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code> \u2014 Return True if the path is relative to another path or False.&lt;/&gt;</li> <li><code>is_reserved</code><code>(</code><code>)</code> \u2014 Return True if the path contains one of the special names reservedby the system, if any. &lt;/&gt;</li> <li><code>is_socket</code><code>(</code><code>)</code> \u2014 Whether this path is a socket.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>iterdir</code><code>(</code><code>)</code> (CloudPath) \u2014 Iterate over directory contents.&lt;/&gt;</li> <li><code>joinpath</code><code>(</code><code>*args</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>lchmod</code><code>(</code><code>mode</code><code>)</code> \u2014 Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's. &lt;/&gt;</li> <li><code>lstat</code><code>(</code><code>)</code> \u2014 Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's. &lt;/&gt;</li> <li><code>match</code><code>(</code><code>pattern</code><code>)</code> (bool) \u2014 Match path against glob pattern.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Union) \u2014 Open file for reading/writing.&lt;/&gt;</li> <li><code>owner</code><code>(</code><code>)</code> \u2014 Return the login name of the file owner.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up</code><code>)</code> \u2014 Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError. &lt;/&gt;</li> <li><code>rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>resolve</code><code>(</code><code>)</code> (CloudPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>rglob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>samefile</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check if this path refers to same file as other.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>)</code> (Iterator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>with_name</code><code>(</code><code>name</code><code>)</code> \u2014 Return a new path with the file name changed.&lt;/&gt;</li> <li><code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>. &lt;/&gt;</li> <li><code>with_stem</code><code>(</code><code>stem</code><code>)</code> \u2014 Return a new path with the stem changed.&lt;/&gt;</li> <li><code>with_suffix</code><code>(</code><code>suffix</code><code>)</code> \u2014 Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path. &lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>.</p> method &lt;/&gt; <p>Return the string representation of the path with forward (/)slashes.</p> method &lt;/&gt; <p>Return the bytes representation of the path.  This is onlyrecommended to use under Unix.</p> method &lt;/&gt; <p>Return a new path with the file name changed.</p> method &lt;/&gt; <p>Return a new path with the stem changed.</p> method &lt;/&gt; <p>Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path.</p> method &lt;/&gt; <p>Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError.</p> <p>The walk_up parameter controls whether <code>..</code> may be used to resolve the path.</p> method &lt;/&gt; <p>Return True if the path is relative to another path or False.</p> method &lt;/&gt; <p>Return True if the path contains one of the special names reservedby the system, if any.</p> method &lt;/&gt; <p>Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's.</p> method &lt;/&gt; <p>Check if this path is a mount point</p> method &lt;/&gt; <p>Whether this path is a junction.</p> method &lt;/&gt; <p>Whether this path is a block device.</p> method &lt;/&gt; <p>Whether this path is a character device.</p> method &lt;/&gt; <p>Whether this path is a FIFO.</p> method &lt;/&gt; <p>Whether this path is a socket.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the current working directory.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')).</p> method &lt;/&gt; <p>Return the login name of the file owner.</p> method &lt;/&gt; <p>Return the group name of the file gid.</p> method &lt;/&gt; <p>Change the permissions of the path, like os.chmod().</p> method &lt;/&gt; <p>Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's.</p> method &lt;/&gt; <p>Make this path a hard link pointing to the same file as target.</p><p>Note the order of arguments (self, target) is the reverse of os.link's.</p> method &lt;/&gt; <p>Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser)</p> staticmethod &lt;/&gt; <p>Create new cloud path instance.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Right join paths while preserving type and client.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Return properly formatted cloud URI with double slash.</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write bytes to file.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Delete file.</p> generator &lt;/&gt; <p>Iterate over directory contents.</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Open file for reading/writing.</p> method &lt;/&gt; <p>Check equality.</p> method &lt;/&gt; <p>Return hash of path.</p> method &lt;/&gt; <p>Return absolute path - cloud paths are already absolute.</p> method &lt;/&gt; <p>Cloud paths are always absolute.</p> method &lt;/&gt; <p>Return the path as a URI (same as string representation).</p> method &lt;/&gt; <p>Match path against glob pattern.</p><p>Override to work correctly with cloud URIs by matching against the key portion of the path (excluding scheme and bucket).</p> generator &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (Iterator) <p>List of matching paths</p> generator &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (Iterator) <p>List of matching paths (recursive)</p> generator &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (Iterator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (CloudPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Check if this path refers to same file as other.</p> Parameters <ul> <li><code>other</code> (Union) \u2014 Path to compare</li> </ul> Returns (bool) <p>True if paths are the same</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> Parameters <ul> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Write bytes to file.</p> Parameters <ul> <li><code>data</code> (bytes) \u2014 Bytes to write to the file.</li> </ul> method &lt;/&gt; <p>Write text to file.</p> Parameters <ul> <li><code>data</code> (str) \u2014 Text to write to the file.</li> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Delete file.</p> Parameters <ul> <li><code>missing_ok</code> (bool, optional) \u2014 If True, does not raise an error if the file does not exist.</li> </ul> method &lt;/&gt; <p>List directory contents (async version returns list).</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths</p> method &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths (recursive)</p> method &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (AsyncGenerator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 File mode (permissions) to set if creating the file.</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (PanPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> <li><code>target_is_directory</code> (bool, optional) \u2014 Ignored (for compatibility with pathlib)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (PanPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Open file and return async file handle.</p> Parameters <ul> <li><code>mode</code> (str, optional) \u2014 File mode (e.g., 'r', 'w', 'rb', 'wb')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments passed to the async client</li> </ul> Returns (AsyncFileHandle) <p>Async file handle from the async client</p>"},{"location":"api/panpath.azure_path/#panpathazure_path","title":"panpath.azure_path","text":""},{"location":"api/panpath.azure_path/#panpathazure_pathazurepath","title":"<code>panpath.azure_path.</code><code>AzurePath</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathwith_segments","title":"<code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathas_posix","title":"<code>as_posix</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathbytes","title":"<code>__bytes__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathwith_name","title":"<code>with_name</code><code>(</code><code>name</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathwith_stem","title":"<code>with_stem</code><code>(</code><code>stem</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathwith_suffix","title":"<code>with_suffix</code><code>(</code><code>suffix</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathrelative_to","title":"<code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathis_relative_to","title":"<code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpurepathis_reserved","title":"<code>is_reserved</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathlstat","title":"<code>lstat</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathis_mount","title":"<code>is_mount</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathis_junction","title":"<code>is_junction</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathis_block_device","title":"<code>is_block_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathis_char_device","title":"<code>is_char_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathis_fifo","title":"<code>is_fifo</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathis_socket","title":"<code>is_socket</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathcwd","title":"<code>cwd</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathhome","title":"<code>home</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathowner","title":"<code>owner</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathgroup","title":"<code>group</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathchmod","title":"<code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathlchmod","title":"<code>lchmod</code><code>(</code><code>mode</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathhardlink_to","title":"<code>hardlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#pathlibpathexpanduser","title":"<code>expanduser</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathnew","title":"<code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathtruediv","title":"<code>__truediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathrtruediv","title":"<code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathjoinpath","title":"<code>joinpath</code><code>(</code><code>*args</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathstr","title":"<code>__str__</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathexists","title":"<code>exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathread_bytes","title":"<code>read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathread_text","title":"<code>read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathwrite_text","title":"<code>write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathunlink","title":"<code>unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathiterdir","title":"<code>iterdir</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathis_dir","title":"<code>is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathis_file","title":"<code>is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathstat","title":"<code>stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathmkdir","title":"<code>mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathopen","title":"<code>open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatheq","title":"<code>__eq__</code><code>(</code><code>other</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathhash","title":"<code>__hash__</code><code>(</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathabsolute","title":"<code>absolute</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathis_absolute","title":"<code>is_absolute</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathas_uri","title":"<code>as_uri</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathmatch","title":"<code>match</code><code>(</code><code>pattern</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathglob","title":"<code>glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathrglob","title":"<code>rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathwalk","title":"<code>walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathtouch","title":"<code>touch</code><code>(</code><code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathrename","title":"<code>rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathreplace","title":"<code>replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathrmdir","title":"<code>rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathresolve","title":"<code>resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathsamefile","title":"<code>samefile</code><code>(</code><code>other</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathis_symlink","title":"<code>is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathreadlink","title":"<code>readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathsymlink_to","title":"<code>symlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathrmtree","title":"<code>rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathcopy","title":"<code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpathcopytree","title":"<code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_exists","title":"<code>a_exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_read_bytes","title":"<code>a_read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_read_text","title":"<code>a_read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_write_bytes","title":"<code>a_write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_write_text","title":"<code>a_write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_unlink","title":"<code>a_unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_iterdir","title":"<code>a_iterdir</code><code>(</code><code>)</code> \u2192 AsyncGenerator","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_is_dir","title":"<code>a_is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_is_file","title":"<code>a_is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_stat","title":"<code>a_stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_mkdir","title":"<code>a_mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_glob","title":"<code>a_glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_rglob","title":"<code>a_rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_walk","title":"<code>a_walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_touch","title":"<code>a_touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_rename","title":"<code>a_rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_replace","title":"<code>a_replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_resolve","title":"<code>a_resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_rmdir","title":"<code>a_rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_is_symlink","title":"<code>a_is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_readlink","title":"<code>a_readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_symlink_to","title":"<code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_rmtree","title":"<code>a_rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_copy","title":"<code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_copytree","title":"<code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.azure_path/#panpathcloudcloudpatha_open","title":"<code>a_open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.base/","title":"panpath.base","text":"module &lt;/&gt; <p>Base class for all PanPath path implementations.</p> Classes <ul> <li><code>PanPath</code> (PanPath) \u2014 Universal path base class and factory.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases pathlib.Path pathlib.PurePath <p>Universal path base class and factory.</p><p>This class inherits from pathlib.Path and serves dual purposes: 1. Base class for all path types in the panpath package 2. Factory for creating appropriate path instances via new</p> <p>As a base class, it's inherited by: <ul><li>- LocalPath (local filesystem paths with sync and async methods)</li><li>- CloudPath (cloud storage paths with sync and async methods)</li><li>- All cloud-specific subclasses (GSPath, S3Path, AzurePath, etc.)</li></ul><p>As a factory, calling PanPath(...) returns the appropriate concrete implementationbased on the URI scheme.</p> <p>Use <code>isinstance(obj, PanPath)</code> to check if an object is a path created by this package.</p> Attributes <ul> <li><code>anchor</code> \u2014 The concatenation of the drive and root, or ''.&lt;/&gt;</li> <li><code>drive</code> \u2014 The drive prefix (letter or UNC path), if any.&lt;/&gt;</li> <li><code>name</code> \u2014 The final path component, if any.&lt;/&gt;</li> <li><code>parent</code> \u2014 The logical parent of the path.&lt;/&gt;</li> <li><code>parents</code> \u2014 A sequence of this path's logical parents.&lt;/&gt;</li> <li><code>parts</code> \u2014 An object providing sequence-like access to thecomponents in the filesystem path. &lt;/&gt;</li> <li><code>root</code> \u2014 The root of the path, if any.&lt;/&gt;</li> <li><code>stem</code> \u2014 The final path component, minus its last suffix.&lt;/&gt;</li> <li><code>suffix</code> \u2014 The final component's last suffix, if any.This includes the leading period. For example: '.txt' &lt;/&gt;</li> <li><code>suffixes</code> \u2014 A list of the final component's suffixes, if any.These include the leading periods. For example: ['.tar', '.gz'] &lt;/&gt;</li> </ul> Examples <pre><code>&gt;&gt;&gt; # Local path&gt;&gt;&gt; path = PanPath(\"/local/file.txt\")\n&gt;&gt;&gt; isinstance(path, PanPath)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # S3 path\n&gt;&gt;&gt; path = PanPath(\"s3://bucket/key.txt\")\n&gt;&gt;&gt; isinstance(path, PanPath)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Async method with a_ prefix\n&gt;&gt;&gt; content = await path.a_read_text()\n</code></pre> Methods <ul> <li><code>__bytes__</code><code>(</code><code>)</code> \u2014 Return the bytes representation of the path.  This is onlyrecommended to use under Unix. &lt;/&gt;</li> <li><code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> (PanPath) \u2014 Create and return the appropriate path instance.&lt;/&gt;</li> <li><code>__str__</code><code>(</code><code>)</code> \u2014 Return the string representation of the path, suitable forpassing to system calls. &lt;/&gt;</li> <li><code>a_copy</code><code>(</code><code>target</code><code>)</code> (PanPath) \u2014 Asynchronously copy this path to the target path.&lt;/&gt;</li> <li><code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Asynchronously copy the directory and all its contents recursively to the target path.&lt;/&gt;</li> <li><code>a_exists</code><code>(</code><code>)</code> (bool) \u2014 Asynchronously check if the path exists.&lt;/&gt;</li> <li><code>a_glob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Asynchronously yield paths matching a glob pattern.&lt;/&gt;</li> <li><code>a_is_dir</code><code>(</code><code>)</code> (bool) \u2014 Asynchronously check if the path is a directory.&lt;/&gt;</li> <li><code>a_is_file</code><code>(</code><code>)</code> (bool) \u2014 Asynchronously check if the path is a file.&lt;/&gt;</li> <li><code>a_is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Asynchronously check if the path is a symbolic link.&lt;/&gt;</li> <li><code>a_iterdir</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 Asynchronously iterate over directory contents.&lt;/&gt;</li> <li><code>a_mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Asynchronously create a directory at this path.&lt;/&gt;</li> <li><code>a_open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (AsyncFileHandle) \u2014 Asynchronously open the file and return an async file handle.&lt;/&gt;</li> <li><code>a_read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Asynchronously read the file's bytes.&lt;/&gt;</li> <li><code>a_read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Asynchronously read the file's text content.&lt;/&gt;</li> <li><code>a_readlink</code><code>(</code><code>)</code> (PanPath) \u2014 Asynchronously read the target of the symbolic link.&lt;/&gt;</li> <li><code>a_rename</code><code>(</code><code>target</code><code>)</code> (PanPath) \u2014 Asynchronously rename this path to the target path.&lt;/&gt;</li> <li><code>a_replace</code><code>(</code><code>target</code><code>)</code> (PanPath) \u2014 Asynchronously replace this path with the target path.&lt;/&gt;</li> <li><code>a_resolve</code><code>(</code><code>)</code> (PanPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>a_rglob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Asynchronously yield paths matching a recursive glob pattern.&lt;/&gt;</li> <li><code>a_rmdir</code><code>(</code><code>)</code> \u2014 Asynchronously remove the directory and its contents recursively.&lt;/&gt;</li> <li><code>a_rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Asynchronously remove the directory and all its contents recursively.&lt;/&gt;</li> <li><code>a_stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (stat_result) \u2014 Asynchronously get the file or directory's status information.&lt;/&gt;</li> <li><code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Asynchronously create a symbolic link pointing to the target path.&lt;/&gt;</li> <li><code>a_touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Asynchronously create the file if it does not exist.&lt;/&gt;</li> <li><code>a_unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Asynchronously remove (delete) the file or empty directory.&lt;/&gt;</li> <li><code>a_walk</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 Asynchronously walk the directory tree.&lt;/&gt;</li> <li><code>a_write_bytes</code><code>(</code><code>data</code><code>)</code> (Optional) \u2014 Asynchronously write bytes to the file.&lt;/&gt;</li> <li><code>a_write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Asynchronously write text to the file.&lt;/&gt;</li> <li><code>absolute</code><code>(</code><code>)</code> \u2014 Return an absolute version of this path by prepending the currentworking directory. No normalization or symlink resolution is performed. &lt;/&gt;</li> <li><code>as_posix</code><code>(</code><code>)</code> \u2014 Return the string representation of the path with forward (/)slashes. &lt;/&gt;</li> <li><code>as_uri</code><code>(</code><code>)</code> \u2014 Return the path as a 'file' URI.&lt;/&gt;</li> <li><code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks</code><code>)</code> \u2014 Change the permissions of the path, like os.chmod().&lt;/&gt;</li> <li><code>cwd</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the current working directory.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>follow_symlinks</code><code>)</code> \u2014 Whether this path exists.&lt;/&gt;</li> <li><code>expanduser</code><code>(</code><code>)</code> \u2014 Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser) &lt;/&gt;</li> <li><code>glob</code><code>(</code><code>pattern</code>, <code>case_sensitive</code><code>)</code> \u2014 Iterate over this subtree and yield all existing files (of anykind, including directories) matching the given relative pattern. &lt;/&gt;</li> <li><code>group</code><code>(</code><code>)</code> \u2014 Return the group name of the file gid.&lt;/&gt;</li> <li><code>hardlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Make this path a hard link pointing to the same file as target.&lt;/&gt;</li> <li><code>home</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')). &lt;/&gt;</li> <li><code>is_absolute</code><code>(</code><code>)</code> \u2014 True if the path is absolute (has both a root and, if applicable,a drive). &lt;/&gt;</li> <li><code>is_block_device</code><code>(</code><code>)</code> \u2014 Whether this path is a block device.&lt;/&gt;</li> <li><code>is_char_device</code><code>(</code><code>)</code> \u2014 Whether this path is a character device.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>)</code> \u2014 Whether this path is a directory.&lt;/&gt;</li> <li><code>is_fifo</code><code>(</code><code>)</code> \u2014 Whether this path is a FIFO.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>)</code> \u2014 Whether this path is a regular file (also True for symlinks pointingto regular files). &lt;/&gt;</li> <li><code>is_junction</code><code>(</code><code>)</code> \u2014 Whether this path is a junction.&lt;/&gt;</li> <li><code>is_mount</code><code>(</code><code>)</code> \u2014 Check if this path is a mount point&lt;/&gt;</li> <li><code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code> \u2014 Return True if the path is relative to another path or False.&lt;/&gt;</li> <li><code>is_reserved</code><code>(</code><code>)</code> \u2014 Return True if the path contains one of the special names reservedby the system, if any. &lt;/&gt;</li> <li><code>is_socket</code><code>(</code><code>)</code> \u2014 Whether this path is a socket.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>)</code> \u2014 Whether this path is a symbolic link.&lt;/&gt;</li> <li><code>iterdir</code><code>(</code><code>)</code> \u2014 Yield path objects of the directory contents.&lt;/&gt;</li> <li><code>joinpath</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Combine this path with one or several arguments, and return anew path representing either a subpath (if all arguments are relative paths) or a totally different path (if one of the arguments is anchored). &lt;/&gt;</li> <li><code>lchmod</code><code>(</code><code>mode</code><code>)</code> \u2014 Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's. &lt;/&gt;</li> <li><code>lstat</code><code>(</code><code>)</code> \u2014 Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's. &lt;/&gt;</li> <li><code>match</code><code>(</code><code>path_pattern</code>, <code>case_sensitive</code><code>)</code> \u2014 Return True if this path matches the given pattern.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a new directory at this given path.&lt;/&gt;</li> <li><code>open</code><code>(</code><code>mode</code>, <code>buffering</code>, <code>encoding</code>, <code>errors</code>, <code>newline</code><code>)</code> \u2014 Open the file pointed to by this path and return a file object, asthe built-in open() function does. &lt;/&gt;</li> <li><code>owner</code><code>(</code><code>)</code> \u2014 Return the login name of the file owner.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>)</code> \u2014 Open the file in bytes mode, read it, and close the file.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>encoding</code>, <code>errors</code><code>)</code> \u2014 Open the file in text mode, read it, and close the file.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>)</code> \u2014 Return the path to which the symbolic link points.&lt;/&gt;</li> <li><code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up</code><code>)</code> \u2014 Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError. &lt;/&gt;</li> <li><code>rename</code><code>(</code><code>target</code><code>)</code> \u2014 Rename this path to the target path.&lt;/&gt;</li> <li><code>replace</code><code>(</code><code>target</code><code>)</code> \u2014 Rename this path to the target path, overwriting if that path exists.&lt;/&gt;</li> <li><code>resolve</code><code>(</code><code>strict</code><code>)</code> \u2014 Make the path absolute, resolving all symlinks on the way and alsonormalizing it. &lt;/&gt;</li> <li><code>rglob</code><code>(</code><code>pattern</code>, <code>case_sensitive</code><code>)</code> \u2014 Recursively yield all existing files (of any kind, includingdirectories) matching the given relative pattern, anywhere in this subtree. &lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>)</code> \u2014 Remove this directory.  The directory must be empty.&lt;/&gt;</li> <li><code>samefile</code><code>(</code><code>other_path</code><code>)</code> \u2014 Return whether other_path is the same or not as this file(as returned by os.path.samefile()). &lt;/&gt;</li> <li><code>stat</code><code>(</code><code>follow_symlinks</code><code>)</code> \u2014 Return the result of the stat() system call on this path, likeos.stat() does. &lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Make this path a symlink pointing to the target path.Note the order of arguments (link, target) is the reverse of os.symlink. &lt;/&gt;</li> <li><code>touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create this file with the given access mode, if it doesn't exist.&lt;/&gt;</li> <li><code>unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Remove this file or link.If the path is a directory, use rmdir() instead. &lt;/&gt;</li> <li><code>walk</code><code>(</code><code>)</code> \u2014 Walk the directory tree.&lt;/&gt;</li> <li><code>with_name</code><code>(</code><code>name</code><code>)</code> \u2014 Return a new path with the file name changed.&lt;/&gt;</li> <li><code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>. &lt;/&gt;</li> <li><code>with_stem</code><code>(</code><code>stem</code><code>)</code> \u2014 Return a new path with the stem changed.&lt;/&gt;</li> <li><code>with_suffix</code><code>(</code><code>suffix</code><code>)</code> \u2014 Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path. &lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Open the file in bytes mode, write to it, and close the file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>data</code>, <code>encoding</code>, <code>errors</code>, <code>newline</code><code>)</code> \u2014 Open the file in text mode, write to it, and close the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>.</p> method &lt;/&gt; <p>Return the string representation of the path, suitable forpassing to system calls.</p> method &lt;/&gt; <p>Return the string representation of the path with forward (/)slashes.</p> method &lt;/&gt; <p>Return the bytes representation of the path.  This is onlyrecommended to use under Unix.</p> method &lt;/&gt; <p>Return the path as a 'file' URI.</p> method &lt;/&gt; <p>Return a new path with the file name changed.</p> method &lt;/&gt; <p>Return a new path with the stem changed.</p> method &lt;/&gt; <p>Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path.</p> method &lt;/&gt; <p>Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError.</p> <p>The walk_up parameter controls whether <code>..</code> may be used to resolve the path.</p> method &lt;/&gt; <p>Return True if the path is relative to another path or False.</p> method &lt;/&gt; <p>Combine this path with one or several arguments, and return anew path representing either a subpath (if all arguments are relative paths) or a totally different path (if one of the arguments is anchored).</p> method &lt;/&gt; <p>True if the path is absolute (has both a root and, if applicable,a drive).</p> method &lt;/&gt; <p>Return True if the path contains one of the special names reservedby the system, if any.</p> method &lt;/&gt; <p>Return True if this path matches the given pattern.</p> method &lt;/&gt; <p>Return the result of the stat() system call on this path, likeos.stat() does.</p> method &lt;/&gt; <p>Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's.</p> method &lt;/&gt; <p>Whether this path exists.</p><p>This method normally follows symlinks; to check whether a symlink exists, add the argument follow_symlinks=False.</p> method &lt;/&gt; <p>Whether this path is a directory.</p> method &lt;/&gt; <p>Whether this path is a regular file (also True for symlinks pointingto regular files).</p> method &lt;/&gt; <p>Check if this path is a mount point</p> method &lt;/&gt; <p>Whether this path is a symbolic link.</p> method &lt;/&gt; <p>Whether this path is a junction.</p> method &lt;/&gt; <p>Whether this path is a block device.</p> method &lt;/&gt; <p>Whether this path is a character device.</p> method &lt;/&gt; <p>Whether this path is a FIFO.</p> method &lt;/&gt; <p>Whether this path is a socket.</p> method &lt;/&gt; <p>Return whether other_path is the same or not as this file(as returned by os.path.samefile()).</p> method &lt;/&gt; <p>Open the file pointed to by this path and return a file object, asthe built-in open() function does.</p> method &lt;/&gt; <p>Open the file in bytes mode, read it, and close the file.</p> method &lt;/&gt; <p>Open the file in text mode, read it, and close the file.</p> method &lt;/&gt; <p>Open the file in bytes mode, write to it, and close the file.</p> method &lt;/&gt; <p>Open the file in text mode, write to it, and close the file.</p> generator &lt;/&gt; <p>Yield path objects of the directory contents.</p><p>The children are yielded in arbitrary order, and the special entries '.' and '..' are not included.</p> generator &lt;/&gt; <p>Iterate over this subtree and yield all existing files (of anykind, including directories) matching the given relative pattern.</p> generator &lt;/&gt; <p>Recursively yield all existing files (of any kind, includingdirectories) matching the given relative pattern, anywhere in this subtree.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the current working directory.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')).</p> method &lt;/&gt; <p>Return an absolute version of this path by prepending the currentworking directory. No normalization or symlink resolution is performed.</p> <p>Use resolve() to get the canonical path to a file.</p> method &lt;/&gt; <p>Make the path absolute, resolving all symlinks on the way and alsonormalizing it.</p> method &lt;/&gt; <p>Return the login name of the file owner.</p> method &lt;/&gt; <p>Return the group name of the file gid.</p> method &lt;/&gt; <p>Return the path to which the symbolic link points.</p> method &lt;/&gt; <p>Create this file with the given access mode, if it doesn't exist.</p> method &lt;/&gt; <p>Create a new directory at this given path.</p> method &lt;/&gt; <p>Change the permissions of the path, like os.chmod().</p> method &lt;/&gt; <p>Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's.</p> method &lt;/&gt; <p>Remove this file or link.If the path is a directory, use rmdir() instead.</p> method &lt;/&gt; <p>Remove this directory.  The directory must be empty.</p> method &lt;/&gt; <p>Rename this path to the target path.</p><p>The target path may be absolute or relative. Relative paths are interpreted relative to the current working directory, not the directory of the Path object.</p> <p>Returns the new Path instance pointing to the target path.</p> method &lt;/&gt; <p>Rename this path to the target path, overwriting if that path exists.</p><p>The target path may be absolute or relative. Relative paths are interpreted relative to the current working directory, not the directory of the Path object.</p> <p>Returns the new Path instance pointing to the target path.</p> method &lt;/&gt; <p>Make this path a symlink pointing to the target path.Note the order of arguments (link, target) is the reverse of os.symlink.</p> method &lt;/&gt; <p>Make this path a hard link pointing to the same file as target.</p><p>Note the order of arguments (self, target) is the reverse of os.link's.</p> method &lt;/&gt; <p>Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser)</p> staticmethod &lt;/&gt; <p>Create and return the appropriate path instance.</p><p>If called on a subclass, returns instance of that subclass. If called on PanPath itself, routes to the appropriate concrete class.</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (PanPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Asynchronously check if the path exists.</p> Returns (bool) <p>True if the path exists, False otherwise.</p> method &lt;/&gt; <p>Asynchronously read the file's bytes.</p> Returns (bytes) <p>File content as bytes.</p> method &lt;/&gt; <p>Asynchronously read the file's text content.</p> Parameters <ul> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> Returns (str) <p>File content as string.</p> method &lt;/&gt; <p>Asynchronously write bytes to the file.</p> Parameters <ul> <li><code>data</code> (bytes) \u2014 Bytes to write to the file.</li> </ul> Returns (Optional) <p>Number of bytes written. For some cloud paths, may return None.</p> method &lt;/&gt; <p>Asynchronously write text to the file.</p> Parameters <ul> <li><code>data</code> (str) \u2014 Text to write to the file.</li> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> Returns (int) <p>Number of characters written.</p> method &lt;/&gt; <p>Asynchronously remove (delete) the file or empty directory.</p> Parameters <ul> <li><code>missing_ok</code> (bool, optional) \u2014 If True, does not raise an error if the file does not exist.</li> </ul> method &lt;/&gt; <p>Asynchronously iterate over directory contents.</p> Yields (AsyncGenerator) <p>PanPath instances for each item in the directory.</p> method &lt;/&gt; <p>Asynchronously check if the path is a directory.</p> Returns (bool) <p>True if the path is a directory, False otherwise.</p> method &lt;/&gt; <p>Asynchronously check if the path is a file.</p> Returns (bool) <p>True if the path is a file, False otherwise.</p> method &lt;/&gt; <p>Asynchronously get the file or directory's status information.</p> Returns (stat_result) <p>An object containing file status information (platform-dependent).</p> method &lt;/&gt; <p>Asynchronously create a directory at this path.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Directory mode (permissions) to set.</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed.</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, does not raise an error if the directory already exists.</li> </ul> method &lt;/&gt; <p>Asynchronously yield paths matching a glob pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Glob pattern to match.</li> </ul> Returns (AsyncGenerator) <p>List of PanPath instances matching the pattern.</p> method &lt;/&gt; <p>Asynchronously yield paths matching a recursive glob pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Recursive glob pattern to match.</li> </ul> Returns (AsyncGenerator) <p>List of PanPath instances matching the pattern.</p> method &lt;/&gt; <p>Asynchronously walk the directory tree.</p> Yields (AsyncGenerator) <p>Tuples of (current_path, dirnames, filenames) at each level.</p> method &lt;/&gt; <p>Asynchronously create the file if it does not exist.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 File mode (permissions) to set if creating the file.</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raises an error if the file already exists.</li> </ul> method &lt;/&gt; <p>Asynchronously rename this path to the target path.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path to rename to.</li> </ul> Returns (PanPath) <p>The renamed PanPath instance.</p> method &lt;/&gt; <p>Asynchronously replace this path with the target path.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path to replace with.</li> </ul> Returns (PanPath) <p>The replaced PanPath instance.</p> method &lt;/&gt; <p>Asynchronously remove the directory and its contents recursively.</p> method &lt;/&gt; <p>Asynchronously check if the path is a symbolic link.</p><p>For local path, this checks if the path is a symlink. For cloud paths, this will check if the object has a metdata flag indicating it's a symlink. Note that it is not a real symlink like in local filesystems. But for example, gcsfuse supports symlink-like behavior via metadata.</p> Returns (bool) <p>True if the path is a symlink, False otherwise.</p> method &lt;/&gt; <p>Asynchronously read the target of the symbolic link.</p><p>For local path, this reads the symlink target. For cloud paths, this reads the metadata flag indicating the symlink target.</p> Returns (PanPath) <p>The target PanPath of the symlink.</p> method &lt;/&gt; <p>Asynchronously create a symbolic link pointing to the target path.</p><p>For local path, this creates a real symlink. For cloud paths, this sets a metadata flag indicating the symlink target.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 The target PanPath the symlink points to.</li> <li><code>target_is_directory</code> (bool, optional) \u2014 Whether the target is a directory (ignored for cloud paths).</li> </ul> method &lt;/&gt; <p>Asynchronously remove the directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, ignores errors during removal.</li> <li><code>onerror</code> (Any, optional) \u2014 Optional function to call on errors.</li> </ul> method &lt;/&gt; <p>Asynchronously copy this path to the target path.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination PanPath to copy to.</li> </ul> Returns (PanPath) <p>The copied PanPath instance.</p> method &lt;/&gt; <p>Asynchronously copy the directory and all its contents recursively to the target path.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination PanPath to copy to.</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If True, copies the contents of symlinks.</li> </ul> Returns (PanPath) <p>The copied PanPath instance.</p> method &lt;/&gt; <p>Asynchronously open the file and return an async file handle.</p> Parameters <ul> <li><code>mode</code> (str, optional) \u2014 Mode to open the file (e.g., 'r', 'rb', 'w', 'wb').</li> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8').</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments to pass to the underlying open method.</li> </ul> Returns (AsyncFileHandle) <p>An async file handle.</p> method &lt;/&gt; <p>Walk the directory tree.</p> Yields <p>Tuples of (current_path, dirnames, filenames) at each level.</p>"},{"location":"api/panpath.base/#panpathbase","title":"panpath.base","text":""},{"location":"api/panpath.base/#panpathbasepanpath","title":"<code>panpath.base.</code><code>PanPath</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 PanPath","text":""},{"location":"api/panpath.base/#pathlibpurepathwith_segments","title":"<code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathstr","title":"<code>__str__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathas_posix","title":"<code>as_posix</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathbytes","title":"<code>__bytes__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathas_uri","title":"<code>as_uri</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathwith_name","title":"<code>with_name</code><code>(</code><code>name</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathwith_stem","title":"<code>with_stem</code><code>(</code><code>stem</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathwith_suffix","title":"<code>with_suffix</code><code>(</code><code>suffix</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathrelative_to","title":"<code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathis_relative_to","title":"<code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathjoinpath","title":"<code>joinpath</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathis_absolute","title":"<code>is_absolute</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathis_reserved","title":"<code>is_reserved</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpurepathmatch","title":"<code>match</code><code>(</code><code>path_pattern</code>, <code>case_sensitive=None</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathstat","title":"<code>stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathlstat","title":"<code>lstat</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathexists","title":"<code>exists</code><code>(</code><code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_dir","title":"<code>is_dir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_file","title":"<code>is_file</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_mount","title":"<code>is_mount</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_symlink","title":"<code>is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_junction","title":"<code>is_junction</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_block_device","title":"<code>is_block_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_char_device","title":"<code>is_char_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_fifo","title":"<code>is_fifo</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathis_socket","title":"<code>is_socket</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathsamefile","title":"<code>samefile</code><code>(</code><code>other_path</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathopen","title":"<code>open</code><code>(</code><code>mode='r'</code>, <code>buffering=-1</code>, <code>encoding=None</code>, <code>errors=None</code>, <code>newline=None</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathread_bytes","title":"<code>read_bytes</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathread_text","title":"<code>read_text</code><code>(</code><code>encoding=None</code>, <code>errors=None</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathwrite_text","title":"<code>write_text</code><code>(</code><code>data</code>, <code>encoding=None</code>, <code>errors=None</code>, <code>newline=None</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathiterdir","title":"<code>iterdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathglob","title":"<code>glob</code><code>(</code><code>pattern</code>, <code>case_sensitive=None</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathrglob","title":"<code>rglob</code><code>(</code><code>pattern</code>, <code>case_sensitive=None</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathcwd","title":"<code>cwd</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathhome","title":"<code>home</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathabsolute","title":"<code>absolute</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathresolve","title":"<code>resolve</code><code>(</code><code>strict=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathowner","title":"<code>owner</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathgroup","title":"<code>group</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathreadlink","title":"<code>readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathtouch","title":"<code>touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathmkdir","title":"<code>mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathchmod","title":"<code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathlchmod","title":"<code>lchmod</code><code>(</code><code>mode</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathunlink","title":"<code>unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathrmdir","title":"<code>rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathrename","title":"<code>rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathreplace","title":"<code>replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathsymlink_to","title":"<code>symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathhardlink_to","title":"<code>hardlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.base/#pathlibpathexpanduser","title":"<code>expanduser</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpathnew","title":"<code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 PanPath","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_resolve","title":"<code>a_resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_exists","title":"<code>a_exists</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_read_bytes","title":"<code>a_read_bytes</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_read_text","title":"<code>a_read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_write_bytes","title":"<code>a_write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_write_text","title":"<code>a_write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_unlink","title":"<code>a_unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_iterdir","title":"<code>a_iterdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_is_dir","title":"<code>a_is_dir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_is_file","title":"<code>a_is_file</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_stat","title":"<code>a_stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_mkdir","title":"<code>a_mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_glob","title":"<code>a_glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_rglob","title":"<code>a_rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_walk","title":"<code>a_walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_touch","title":"<code>a_touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_rename","title":"<code>a_rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_replace","title":"<code>a_replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_rmdir","title":"<code>a_rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_is_symlink","title":"<code>a_is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_readlink","title":"<code>a_readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_symlink_to","title":"<code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_rmtree","title":"<code>a_rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_copy","title":"<code>a_copy</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_copytree","title":"<code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpatha_open","title":"<code>a_open</code><code>(</code><code>mode='r'</code>, <code>encoding='utf-8'</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.base/#panpathbasepanpathwalk","title":"<code>walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/","title":"panpath.clients","text":"module &lt;/&gt; <p>Base client classes for sync and async cloud storage operations.</p> Classes <ul> <li><code>Client</code><code>(</code><code>)</code> \u2014 Base class for cloud storage clients.&lt;/&gt;</li> <li><code>SyncClient</code><code>(</code><code>)</code> \u2014 Base class for synchronous cloud storage clients.&lt;/&gt;</li> <li><code>AsyncClient</code><code>(</code><code>)</code> \u2014 Base class for asynchronous cloud storage clients.&lt;/&gt;</li> <li><code>AsyncFileHandle</code><code>(</code><code>client_factory</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode</code>, <code>encoding</code>, <code>chunk_size</code>, <code>upload_warning_threshold</code>, <code>upload_interval</code><code>)</code> \u2014 Base class for async file handles.&lt;/&gt;</li> <li><code>SyncFileHandle</code><code>(</code><code>client</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode</code>, <code>encoding</code>, <code>chunk_size</code>, <code>upload_warning_threshold</code>, <code>upload_interval</code><code>)</code> \u2014 Base class for sync file handles.&lt;/&gt;</li> </ul> abstract class &lt;/&gt; <p>Base class for cloud storage clients.</p> Methods <ul> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Union) \u2014 Open file and return sync/async file handle.&lt;/&gt;</li> </ul> abstract method &lt;/&gt; <p>Open file and return sync/async file handle.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud storage path</li> <li><code>mode</code> (str, optional) \u2014 File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments for specific implementations</li> </ul> Returns (Union) <p>SyncFileHandle/AsyncFileHandle instance</p> abstract class &lt;/&gt; Bases panpath.clients.Client <p>Base class for synchronous cloud storage clients.</p> Methods <ul> <li><code>copy</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file from src to dst.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree from src to dst recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get object metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> (Iterator) \u2014 Find all paths matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a symlink (has symlink metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (Iterator) \u2014 List directory contents.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty blob with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Union) \u2014 Open file and return sync/async file handle.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>src</code>, <code>dst</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set object metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file or update metadata.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> (Iterator) \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> abstract method &lt;/&gt; <p>Open file and return sync/async file handle.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud storage path</li> <li><code>mode</code> (str, optional) \u2014 File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments for specific implementations</li> </ul> Returns (Union) <p>SyncFileHandle/AsyncFileHandle instance</p> abstract method &lt;/&gt; <p>Check if path exists.</p> abstract method &lt;/&gt; <p>Read file as bytes.</p> abstract method &lt;/&gt; <p>Write bytes to file.</p> abstract method &lt;/&gt; <p>Delete file.</p> abstract method &lt;/&gt; <p>List directory contents.</p> abstract method &lt;/&gt; <p>Check if path is a directory.</p> abstract method &lt;/&gt; <p>Check if path is a file.</p> abstract method &lt;/&gt; <p>Get file stats.</p> abstract method &lt;/&gt; <p>Create a directory marker (empty blob with trailing slash).</p> abstract method &lt;/&gt; <p>Find all paths matching pattern.</p> abstract method &lt;/&gt; <p>Walk directory tree.</p> abstract method &lt;/&gt; <p>Create empty file or update metadata.</p> abstract method &lt;/&gt; <p>Rename/move file.</p> abstract method &lt;/&gt; <p>Remove directory marker.</p> abstract method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> abstract method &lt;/&gt; <p>Get object metadata.</p> abstract method &lt;/&gt; <p>Set object metadata.</p> abstract method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> abstract method &lt;/&gt; <p>Copy file from src to dst.</p> abstract method &lt;/&gt; <p>Copy directory tree from src to dst recursively.</p> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Check if path is a symlink (has symlink metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (bool) <p>True if path is a symlink</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (str) <p>Symlink target path</p> abstract class &lt;/&gt; Bases panpath.clients.Client <p>Base class for asynchronous cloud storage clients.</p> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncClient) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close any open connections/resources.&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file from src to dst.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree from src to dst recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get object metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Find all paths matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a symlink (has symlink metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (list) \u2014 List directory contents.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty blob with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Union) \u2014 Open file and return sync/async file handle.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read Azure blob as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>src</code>, <code>dst</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set object metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file or update metadata.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> (AsyncGenerator) \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> (int) \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to Azure blob.&lt;/&gt;</li> </ul> abstract method &lt;/&gt; <p>Open file and return sync/async file handle.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud storage path</li> <li><code>mode</code> (str, optional) \u2014 File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments for specific implementations</li> </ul> Returns (Union) <p>SyncFileHandle/AsyncFileHandle instance</p> abstract method &lt;/&gt; <p>Close any open connections/resources.</p> abstract method &lt;/&gt; <p>Check if path exists.</p> abstract method &lt;/&gt; <p>Read file as bytes.</p> abstract method &lt;/&gt; <p>Write bytes to file.</p> abstract method &lt;/&gt; <p>Delete file.</p> abstract method &lt;/&gt; <p>List directory contents.</p> abstract method &lt;/&gt; <p>Check if path is a directory.</p> abstract method &lt;/&gt; <p>Check if path is a file.</p> abstract method &lt;/&gt; <p>Get file stats.</p> abstract method &lt;/&gt; <p>Create a directory marker (empty blob with trailing slash).</p> abstract method &lt;/&gt; <p>Find all paths matching pattern.</p> abstract method &lt;/&gt; <p>Walk directory tree.</p> abstract method &lt;/&gt; <p>Create empty file or update metadata.</p> abstract method &lt;/&gt; <p>Rename/move file.</p> abstract method &lt;/&gt; <p>Remove directory marker.</p> abstract method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> abstract method &lt;/&gt; <p>Get object metadata.</p> abstract method &lt;/&gt; <p>Set object metadata.</p> abstract method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> abstract method &lt;/&gt; <p>Copy file from src to dst.</p> abstract method &lt;/&gt; <p>Copy directory tree from src to dst recursively.</p> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read Azure blob as text.</p> method &lt;/&gt; <p>Write text to Azure blob.</p> method &lt;/&gt; <p>Check if path is a symlink (has symlink metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (bool) <p>True if path is a symlink</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (str) <p>Symlink target path</p> abstract class &lt;/&gt; <p>Base class for async file handles.</p><p>This abstract base class defines the interface for async file operations on cloud storage. Each cloud provider implements its own version using the provider's specific streaming capabilities.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__aiter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__anext__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset the underlying stream to the beginning.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Reset the underlying stream to the beginning.</p> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul> abstract class &lt;/&gt; <p>Base class for sync file handles.</p><p>This abstract base class defines the interface for sync file operations on cloud storage. Each cloud provider implements its own version using the provider's specific streaming capabilities.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__enter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Enter context manager.&lt;/&gt;</li> <li><code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__iter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__next__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset the underlying stream to the beginning.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Reset the underlying stream to the beginning.</p> method &lt;/&gt; <p>Enter context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul>"},{"location":"api/panpath.clients/#panpathclients","title":"panpath.clients","text":""},{"location":"api/panpath.clients/#panpathclientsclient","title":"<code>panpath.clients.</code><code>Client</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsclientopen","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclient","title":"<code>panpath.clients.</code><code>SyncClient</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsclientopen_1","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 Iterator","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> \u2192 Iterator","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code> \u2192 Iterator","text":""},{"location":"api/panpath.clients/#panpathclientssyncclienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientrename","title":"<code>rename</code><code>(</code><code>src</code>, <code>dst</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code> \u2192 dict","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientcopy","title":"<code>copy</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientcopytree","title":"<code>copytree</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncclientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclient","title":"<code>panpath.clients.</code><code>AsyncClient</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsclientopen_2","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> \u2192 AsyncGenerator","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code> \u2192 AsyncGenerator","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientrename","title":"<code>rename</code><code>(</code><code>src</code>, <code>dst</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code> \u2192 dict","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientcopy","title":"<code>copy</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientcopytree","title":"<code>copytree</code><code>(</code><code>src</code>, <code>dst</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncClient","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncclientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandle","title":"<code>panpath.clients.</code><code>AsyncFileHandle</code><code>(</code><code>client_factory</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>chunk_size=4096</code>, <code>upload_warning_threshold=100</code>, <code>upload_interval=1.0</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleaiter","title":"<code>__aiter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleanext","title":"<code>__anext__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientsasyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandle","title":"<code>panpath.clients.</code><code>SyncFileHandle</code><code>(</code><code>client</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>chunk_size=4096</code>, <code>upload_warning_threshold=100</code>, <code>upload_interval=1.0</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandleenter","title":"<code>__enter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandleexit","title":"<code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandleiter","title":"<code>__iter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandlenext","title":"<code>__next__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.clients/#panpathclientssyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.cloud/","title":"panpath.cloud","text":"module &lt;/&gt; <p>Base classes for cloud path implementations.</p> Classes <ul> <li><code>CloudPath</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> (CloudPath) \u2014 Base class for cloud path implementations.&lt;/&gt;</li> </ul> abstract class &lt;/&gt; Bases panpath.base.PanPath pathlib.Path pathlib.PurePosixPath pathlib.PurePath <p>Base class for cloud path implementations.</p><p>Inherits from PanPath and PurePosixPath for path operations. Includes both sync and async methods (async methods prefixed with a_).</p> Attributes <ul> <li><code>anchor</code> \u2014 The concatenation of the drive and root, or ''.&lt;/&gt;</li> <li><code>async_client</code> (AsyncClient) \u2014 Get or create the async client for this path.&lt;/&gt;</li> <li><code>client</code> (SyncClient) \u2014 Get or create the sync client for this path.&lt;/&gt;</li> <li><code>cloud_prefix</code> (str) \u2014 Return the cloud prefix (e.g., 's3://bucket').&lt;/&gt;</li> <li><code>drive</code> \u2014 The drive prefix (letter or UNC path), if any.&lt;/&gt;</li> <li><code>key</code> (str) \u2014 Return the key/blob name without the cloud prefix.&lt;/&gt;</li> <li><code>name</code> \u2014 The final path component, if any.&lt;/&gt;</li> <li><code>parent</code> (CloudPath) \u2014 Return parent directory as same path type.&lt;/&gt;</li> <li><code>parents</code> \u2014 A sequence of this path's logical parents.&lt;/&gt;</li> <li><code>parts</code> \u2014 An object providing sequence-like access to thecomponents in the filesystem path. &lt;/&gt;</li> <li><code>root</code> \u2014 The root of the path, if any.&lt;/&gt;</li> <li><code>stem</code> \u2014 The final path component, minus its last suffix.&lt;/&gt;</li> <li><code>suffix</code> \u2014 The final component's last suffix, if any.This includes the leading period. For example: '.txt' &lt;/&gt;</li> <li><code>suffixes</code> \u2014 A list of the final component's suffixes, if any.These include the leading periods. For example: ['.tar', '.gz'] &lt;/&gt;</li> </ul> Methods <ul> <li><code>__bytes__</code><code>(</code><code>)</code> \u2014 Return the bytes representation of the path.  This is onlyrecommended to use under Unix. &lt;/&gt;</li> <li><code>__eq__</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check equality.&lt;/&gt;</li> <li><code>__hash__</code><code>(</code><code>)</code> (int) \u2014 Return hash of path.&lt;/&gt;</li> <li><code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> (CloudPath) \u2014 Create new cloud path instance.&lt;/&gt;</li> <li><code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Right join paths while preserving type and client.&lt;/&gt;</li> <li><code>__str__</code><code>(</code><code>)</code> (str) \u2014 Return properly formatted cloud URI with double slash.&lt;/&gt;</li> <li><code>__truediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>a_exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>a_glob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>a_is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>a_is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>a_is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>a_iterdir</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 List directory contents (async version returns list).&lt;/&gt;</li> <li><code>a_mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>a_open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (AsyncFileHandle) \u2014 Open file and return async file handle.&lt;/&gt;</li> <li><code>a_read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>a_read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>a_readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>a_rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>a_replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>a_resolve</code><code>(</code><code>)</code> (PanPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>a_rglob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>a_rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>a_rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>a_stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>a_touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>a_unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>a_walk</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>a_write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>a_write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to file.&lt;/&gt;</li> <li><code>absolute</code><code>(</code><code>)</code> (CloudPath) \u2014 Return absolute path - cloud paths are already absolute.&lt;/&gt;</li> <li><code>as_posix</code><code>(</code><code>)</code> \u2014 Return the string representation of the path with forward (/)slashes. &lt;/&gt;</li> <li><code>as_uri</code><code>(</code><code>)</code> (str) \u2014 Return the path as a URI (same as string representation).&lt;/&gt;</li> <li><code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks</code><code>)</code> \u2014 Change the permissions of the path, like os.chmod().&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>cwd</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the current working directory.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>expanduser</code><code>(</code><code>)</code> \u2014 Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser) &lt;/&gt;</li> <li><code>glob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>group</code><code>(</code><code>)</code> \u2014 Return the group name of the file gid.&lt;/&gt;</li> <li><code>hardlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Make this path a hard link pointing to the same file as target.&lt;/&gt;</li> <li><code>home</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')). &lt;/&gt;</li> <li><code>is_absolute</code><code>(</code><code>)</code> (bool) \u2014 Cloud paths are always absolute.&lt;/&gt;</li> <li><code>is_block_device</code><code>(</code><code>)</code> \u2014 Whether this path is a block device.&lt;/&gt;</li> <li><code>is_char_device</code><code>(</code><code>)</code> \u2014 Whether this path is a character device.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>is_fifo</code><code>(</code><code>)</code> \u2014 Whether this path is a FIFO.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>is_junction</code><code>(</code><code>)</code> \u2014 Whether this path is a junction.&lt;/&gt;</li> <li><code>is_mount</code><code>(</code><code>)</code> \u2014 Check if this path is a mount point&lt;/&gt;</li> <li><code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code> \u2014 Return True if the path is relative to another path or False.&lt;/&gt;</li> <li><code>is_reserved</code><code>(</code><code>)</code> \u2014 Return True if the path contains one of the special names reservedby the system, if any. &lt;/&gt;</li> <li><code>is_socket</code><code>(</code><code>)</code> \u2014 Whether this path is a socket.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>iterdir</code><code>(</code><code>)</code> (CloudPath) \u2014 Iterate over directory contents.&lt;/&gt;</li> <li><code>joinpath</code><code>(</code><code>*args</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>lchmod</code><code>(</code><code>mode</code><code>)</code> \u2014 Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's. &lt;/&gt;</li> <li><code>lstat</code><code>(</code><code>)</code> \u2014 Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's. &lt;/&gt;</li> <li><code>match</code><code>(</code><code>pattern</code><code>)</code> (bool) \u2014 Match path against glob pattern.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Union) \u2014 Open file for reading/writing.&lt;/&gt;</li> <li><code>owner</code><code>(</code><code>)</code> \u2014 Return the login name of the file owner.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up</code><code>)</code> \u2014 Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError. &lt;/&gt;</li> <li><code>rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>resolve</code><code>(</code><code>)</code> (CloudPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>rglob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>samefile</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check if this path refers to same file as other.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>)</code> (Iterator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>with_name</code><code>(</code><code>name</code><code>)</code> \u2014 Return a new path with the file name changed.&lt;/&gt;</li> <li><code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>. &lt;/&gt;</li> <li><code>with_stem</code><code>(</code><code>stem</code><code>)</code> \u2014 Return a new path with the stem changed.&lt;/&gt;</li> <li><code>with_suffix</code><code>(</code><code>suffix</code><code>)</code> \u2014 Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path. &lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>.</p> method &lt;/&gt; <p>Return the string representation of the path with forward (/)slashes.</p> method &lt;/&gt; <p>Return the bytes representation of the path.  This is onlyrecommended to use under Unix.</p> method &lt;/&gt; <p>Return a new path with the file name changed.</p> method &lt;/&gt; <p>Return a new path with the stem changed.</p> method &lt;/&gt; <p>Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path.</p> method &lt;/&gt; <p>Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError.</p> <p>The walk_up parameter controls whether <code>..</code> may be used to resolve the path.</p> method &lt;/&gt; <p>Return True if the path is relative to another path or False.</p> method &lt;/&gt; <p>Return True if the path contains one of the special names reservedby the system, if any.</p> method &lt;/&gt; <p>Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's.</p> method &lt;/&gt; <p>Check if this path is a mount point</p> method &lt;/&gt; <p>Whether this path is a junction.</p> method &lt;/&gt; <p>Whether this path is a block device.</p> method &lt;/&gt; <p>Whether this path is a character device.</p> method &lt;/&gt; <p>Whether this path is a FIFO.</p> method &lt;/&gt; <p>Whether this path is a socket.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the current working directory.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')).</p> method &lt;/&gt; <p>Return the login name of the file owner.</p> method &lt;/&gt; <p>Return the group name of the file gid.</p> method &lt;/&gt; <p>Change the permissions of the path, like os.chmod().</p> method &lt;/&gt; <p>Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's.</p> method &lt;/&gt; <p>Make this path a hard link pointing to the same file as target.</p><p>Note the order of arguments (self, target) is the reverse of os.link's.</p> method &lt;/&gt; <p>Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser)</p> staticmethod &lt;/&gt; <p>Create new cloud path instance.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Right join paths while preserving type and client.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Return properly formatted cloud URI with double slash.</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write bytes to file.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Delete file.</p> generator &lt;/&gt; <p>Iterate over directory contents.</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Open file for reading/writing.</p> method &lt;/&gt; <p>Check equality.</p> method &lt;/&gt; <p>Return hash of path.</p> method &lt;/&gt; <p>Return absolute path - cloud paths are already absolute.</p> method &lt;/&gt; <p>Cloud paths are always absolute.</p> method &lt;/&gt; <p>Return the path as a URI (same as string representation).</p> method &lt;/&gt; <p>Match path against glob pattern.</p><p>Override to work correctly with cloud URIs by matching against the key portion of the path (excluding scheme and bucket).</p> generator &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (Iterator) <p>List of matching paths</p> generator &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (Iterator) <p>List of matching paths (recursive)</p> generator &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (Iterator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (CloudPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Check if this path refers to same file as other.</p> Parameters <ul> <li><code>other</code> (Union) \u2014 Path to compare</li> </ul> Returns (bool) <p>True if paths are the same</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write bytes to file.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Delete file.</p> method &lt;/&gt; <p>List directory contents (async version returns list).</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths</p> method &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths (recursive)</p> method &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (AsyncGenerator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (PanPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> <li><code>target_is_directory</code> (bool, optional) \u2014 Ignored (for compatibility with pathlib)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (PanPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Open file and return async file handle.</p> Parameters <ul> <li><code>mode</code> (str, optional) \u2014 File mode (e.g., 'r', 'w', 'rb', 'wb')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments passed to the async client</li> </ul> Returns (AsyncFileHandle) <p>Async file handle from the async client</p>"},{"location":"api/panpath.cloud/#panpathcloud","title":"panpath.cloud","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpath","title":"<code>panpath.cloud.</code><code>CloudPath</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.cloud/#pathlibpurepathwith_segments","title":"<code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathas_posix","title":"<code>as_posix</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathbytes","title":"<code>__bytes__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathwith_name","title":"<code>with_name</code><code>(</code><code>name</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathwith_stem","title":"<code>with_stem</code><code>(</code><code>stem</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathwith_suffix","title":"<code>with_suffix</code><code>(</code><code>suffix</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathrelative_to","title":"<code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up=False</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathis_relative_to","title":"<code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpurepathis_reserved","title":"<code>is_reserved</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathlstat","title":"<code>lstat</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathis_mount","title":"<code>is_mount</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathis_junction","title":"<code>is_junction</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathis_block_device","title":"<code>is_block_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathis_char_device","title":"<code>is_char_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathis_fifo","title":"<code>is_fifo</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathis_socket","title":"<code>is_socket</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathcwd","title":"<code>cwd</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathhome","title":"<code>home</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathowner","title":"<code>owner</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathgroup","title":"<code>group</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathchmod","title":"<code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathlchmod","title":"<code>lchmod</code><code>(</code><code>mode</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathhardlink_to","title":"<code>hardlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#pathlibpathexpanduser","title":"<code>expanduser</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathnew","title":"<code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathtruediv","title":"<code>__truediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathrtruediv","title":"<code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathjoinpath","title":"<code>joinpath</code><code>(</code><code>*args</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathstr","title":"<code>__str__</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathexists","title":"<code>exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathread_bytes","title":"<code>read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathread_text","title":"<code>read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathwrite_text","title":"<code>write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathunlink","title":"<code>unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathiterdir","title":"<code>iterdir</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathis_dir","title":"<code>is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathis_file","title":"<code>is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathstat","title":"<code>stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathmkdir","title":"<code>mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathopen","title":"<code>open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatheq","title":"<code>__eq__</code><code>(</code><code>other</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathhash","title":"<code>__hash__</code><code>(</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathabsolute","title":"<code>absolute</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathis_absolute","title":"<code>is_absolute</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathas_uri","title":"<code>as_uri</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathmatch","title":"<code>match</code><code>(</code><code>pattern</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathglob","title":"<code>glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathrglob","title":"<code>rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathwalk","title":"<code>walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathtouch","title":"<code>touch</code><code>(</code><code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathrename","title":"<code>rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathreplace","title":"<code>replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathrmdir","title":"<code>rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathresolve","title":"<code>resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathsamefile","title":"<code>samefile</code><code>(</code><code>other</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathis_symlink","title":"<code>is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathreadlink","title":"<code>readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathsymlink_to","title":"<code>symlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathrmtree","title":"<code>rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathcopy","title":"<code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpathcopytree","title":"<code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_exists","title":"<code>a_exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_read_bytes","title":"<code>a_read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_read_text","title":"<code>a_read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_write_bytes","title":"<code>a_write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_write_text","title":"<code>a_write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_unlink","title":"<code>a_unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_iterdir","title":"<code>a_iterdir</code><code>(</code><code>)</code> \u2192 AsyncGenerator","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_is_dir","title":"<code>a_is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_is_file","title":"<code>a_is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_stat","title":"<code>a_stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_mkdir","title":"<code>a_mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_glob","title":"<code>a_glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_rglob","title":"<code>a_rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_walk","title":"<code>a_walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_touch","title":"<code>a_touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_rename","title":"<code>a_rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_replace","title":"<code>a_replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_resolve","title":"<code>a_resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_rmdir","title":"<code>a_rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_is_symlink","title":"<code>a_is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_readlink","title":"<code>a_readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_symlink_to","title":"<code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_rmtree","title":"<code>a_rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_copy","title":"<code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_copytree","title":"<code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.cloud/#panpathcloudcloudpatha_open","title":"<code>a_open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.exceptions/","title":"panpath.exceptions","text":"module &lt;/&gt; <p>Exception classes for panpath.</p> Classes <ul> <li><code>PanPathError</code> \u2014 Base exception for panpath errors.&lt;/&gt;</li> <li><code>MissingDependencyError</code> \u2014 Raised when a required dependency is not installed.&lt;/&gt;</li> <li><code>CloudPathError</code> \u2014 Base exception for cloud path errors.&lt;/&gt;</li> <li><code>NoStatError</code> \u2014 Raised when stat information cannot be retrieved.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases Exception BaseException <p>Base exception for panpath errors.</p> class &lt;/&gt; Bases panpath.exceptions.PanPathError ImportError Exception BaseException <p>Raised when a required dependency is not installed.</p> class &lt;/&gt; Bases panpath.exceptions.PanPathError Exception BaseException <p>Base exception for cloud path errors.</p> class &lt;/&gt; Bases panpath.exceptions.CloudPathError panpath.exceptions.PanPathError Exception BaseException <p>Raised when stat information cannot be retrieved.</p>"},{"location":"api/panpath.exceptions/#panpathexceptions","title":"panpath.exceptions","text":""},{"location":"api/panpath.exceptions/#panpathexceptionspanpatherror","title":"<code>panpath.exceptions.</code><code>PanPathError</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.exceptions/#panpathexceptionsmissingdependencyerror","title":"<code>panpath.exceptions.</code><code>MissingDependencyError</code><code>(</code><code>backend</code>, <code>package</code>, <code>extra</code><code>)</code>","text":""},{"location":"api/panpath.exceptions/#panpathexceptionscloudpatherror","title":"<code>panpath.exceptions.</code><code>CloudPathError</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.exceptions/#panpathexceptionsnostaterror","title":"<code>panpath.exceptions.</code><code>NoStatError</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/","title":"panpath.gs_async_client","text":"module &lt;/&gt; <p>Async Google Cloud Storage client implementation.</p> Classes <ul> <li><code>AsyncGSClient</code> \u2014 Asynchronous Google Cloud Storage client implementation.&lt;/&gt;</li> <li><code>GSAsyncFileHandle</code> \u2014 Async file handle for GCS with chunked streaming support.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.clients.AsyncClient panpath.clients.Client <p>Asynchronous Google Cloud Storage client implementation.</p> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncClient) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the storage client and cleanup resources.&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete GCS blob.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if GCS blob exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get blob metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if GCS path is a directory.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if GCS path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if path is a symlink (has symlink metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (list) \u2014 List GCS blobs with prefix.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty blob with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (gsasyncfilehandle) \u2014 Open GCS blob and return async file handle with streaming support.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read GCS blob as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read Azure blob as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set blob metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (stat_result) \u2014 Get GCS blob metadata.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2014 Write bytes to GCS blob.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to Azure blob.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read Azure blob as text.</p> method &lt;/&gt; <p>Write text to Azure blob.</p> method &lt;/&gt; <p>Check if path is a symlink (has symlink metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 Cloud path</li> </ul> Returns (bool) <p>True if path is a symlink</p> method &lt;/&gt; <p>Close the storage client and cleanup resources.</p> method &lt;/&gt; <p>Check if GCS blob exists.</p> method &lt;/&gt; <p>Read GCS blob as bytes.</p> method &lt;/&gt; <p>Write bytes to GCS blob.</p> method &lt;/&gt; <p>Delete GCS blob.</p> method &lt;/&gt; <p>List GCS blobs with prefix.</p> method &lt;/&gt; <p>Check if GCS path is a directory.</p> method &lt;/&gt; <p>Check if GCS path is a file.</p> method &lt;/&gt; <p>Get GCS blob metadata.</p> method &lt;/&gt; <p>Open GCS blob and return async file handle with streaming support.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path (gs://bucket/blob)</li> <li><code>mode</code> (str, optional) \u2014 File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments (chunk_size, upload_warning_threshold,upload_interval supported) </li> </ul> Returns (gsasyncfilehandle) <p>GSAsyncFileHandle with streaming support</p> method &lt;/&gt; <p>Create a directory marker (empty blob with trailing slash).</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path (gs://bucket/path)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Get blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> </ul> Returns (dict) <p>Dictionary of metadata key-value pairs</p> method &lt;/&gt; <p>Set blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> <li><code>metadata</code> (dict) \u2014 Dictionary of metadata key-value pairs</li> </ul> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> </ul> Returns (str) <p>Symlink target path</p> method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path for the symlink</li> <li><code>target</code> (str) \u2014 Target path the symlink should point to</li> </ul> method &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base GCS path</li> <li><code>pattern</code> (str) \u2014 Glob pattern (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching PanPath objects or strings</p> method &lt;/&gt; <p>Walk directory tree.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base GCS path</li> </ul> Yields <p>Tuples of (dirpath, dirnames, filenames)</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> <li><code>mode</code> (optional) \u2014 Mode setting (not supported for GCS, will raise ValueError if provided)</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source GCS path</li> <li><code>target</code> (str) \u2014 Target GCS path</li> </ul> method &lt;/&gt; <p>Remove directory marker.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source GCS path</li> <li><code>target</code> (str) \u2014 Target GCS path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> method &lt;/&gt; <p>Copy directory tree to target recursively.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source GCS path</li> <li><code>target</code> (str) \u2014 Target GCS path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> class &lt;/&gt; Bases panpath.clients.AsyncFileHandle <p>Async file handle for GCS with chunked streaming support.</p><p>Uses range requests for reading to avoid loading entire blobs.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__aiter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__anext__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset the underlying stream to the beginning.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Reset the underlying stream to the beginning.</p> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul>"},{"location":"api/panpath.gs_async_client/#panpathgs_async_client","title":"panpath.gs_async_client","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclient","title":"<code>panpath.gs_async_client.</code><code>AsyncGSClient</code><code>(</code><code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncclientaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncClient","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncclientaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncclientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 stat_result","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientopen","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>mode=None</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientrename","title":"<code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientcopy","title":"<code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientasyncgsclientcopytree","title":"<code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathgs_async_clientgsasyncfilehandle","title":"<code>panpath.gs_async_client.</code><code>GSAsyncFileHandle</code><code>(</code><code>client_factory</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>chunk_size=4096</code>, <code>upload_warning_threshold=100</code>, <code>upload_interval=1.0</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleaiter","title":"<code>__aiter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleanext","title":"<code>__anext__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_async_client/#panpathclientsasyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/","title":"panpath.gs_client","text":"module &lt;/&gt; <p>Google Cloud Storage client implementation.</p> Classes <ul> <li><code>GSClient</code> \u2014 Synchronous Google Cloud Storage client implementation.&lt;/&gt;</li> <li><code>GSSyncFileHandle</code> \u2014 Sync file handle for GCS with chunked streaming support.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.clients.SyncClient panpath.clients.Client <p>Synchronous Google Cloud Storage client implementation.</p> Methods <ul> <li><code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete GCS blob.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if GCS blob exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get blob metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> (Iterator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if GCS path is a directory (has blobs with prefix).&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if GCS path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if blob is a symlink (has symlink_target metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (list) \u2014 List GCS blobs with prefix.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty blob with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Any) \u2014 Open GCS blob for reading/writing with streaming support.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read GCS blob as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set blob metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (Any) \u2014 Get GCS blob metadata.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> (Iterator) \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2014 Write bytes to GCS blob.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Check if GCS blob exists.</p> method &lt;/&gt; <p>Read GCS blob as bytes.</p> method &lt;/&gt; <p>Write bytes to GCS blob.</p> method &lt;/&gt; <p>Delete GCS blob.</p> method &lt;/&gt; <p>List GCS blobs with prefix.</p> method &lt;/&gt; <p>Check if GCS path is a directory (has blobs with prefix).</p> method &lt;/&gt; <p>Check if GCS path is a file.</p> method &lt;/&gt; <p>Get GCS blob metadata.</p> method &lt;/&gt; <p>Open GCS blob for reading/writing with streaming support.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path (gs://bucket/blob)</li> <li><code>mode</code> (str, optional) \u2014 File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments (chunk_size, upload_warning_threshold,upload_interval supported) </li> </ul> Returns (Any) <p>GSSyncFileHandle with streaming support</p> method &lt;/&gt; <p>Create a directory marker (empty blob with trailing slash).</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path (gs://bucket/path)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed (ignored for GCS)</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Get blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> </ul> Returns (dict) <p>Dictionary of metadata key-value pairs</p> method &lt;/&gt; <p>Set blob metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> <li><code>metadata</code> (dict) \u2014 Dictionary of metadata key-value pairs</li> </ul> method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path for the symlink</li> <li><code>target</code> (str) \u2014 Target path the symlink should point to</li> </ul> method &lt;/&gt; <p>Check if blob is a symlink (has symlink_target metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> </ul> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> </ul> Returns (str) <p>Symlink target path</p> generator &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base GCS path</li> <li><code>pattern</code> (str) \u2014 Glob pattern (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (Iterator) <p>List of matching paths (as PanPath objects or strings)</p> generator &lt;/&gt; <p>Walk directory tree.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base GCS path</li> </ul> Returns (Iterator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source GCS path</li> <li><code>target</code> (str) \u2014 Target GCS path</li> </ul> method &lt;/&gt; <p>Remove directory marker.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>path</code> (str) \u2014 GCS path</li> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source GCS path</li> <li><code>target</code> (str) \u2014 Target GCS path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> method &lt;/&gt; <p>Copy directory tree to target recursively.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source GCS path</li> <li><code>target</code> (str) \u2014 Target GCS path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> class &lt;/&gt; Bases panpath.clients.SyncFileHandle <p>Sync file handle for GCS with chunked streaming support.</p><p>Uses google-cloud-storage's streaming API for efficient reading of large files.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__del__</code><code>(</code><code>)</code> \u2014 Destructor to ensure stream is closed.&lt;/&gt;</li> <li><code>__enter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Enter context manager.&lt;/&gt;</li> <li><code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__iter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__next__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset streaming reader/writer.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Enter context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul> method &lt;/&gt; <p>Reset streaming reader/writer.</p> method &lt;/&gt; <p>Destructor to ensure stream is closed.</p>"},{"location":"api/panpath.gs_client/#panpathgs_client","title":"panpath.gs_client","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclient","title":"<code>panpath.gs_client.</code><code>GSClient</code><code>(</code><code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientopen","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientrename","title":"<code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientcopy","title":"<code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgsclientcopytree","title":"<code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgssyncfilehandle","title":"<code>panpath.gs_client.</code><code>GSSyncFileHandle</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandleenter","title":"<code>__enter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandleexit","title":"<code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandleiter","title":"<code>__iter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandlenext","title":"<code>__next__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathclientssyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgssyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_client/#panpathgs_clientgssyncfilehandledel","title":"<code>__del__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/","title":"panpath.gs_path","text":"module &lt;/&gt; <p>Google Cloud Storage path implementation.</p> Classes <ul> <li><code>GSPath</code> (CloudPath) \u2014 Google Cloud Storage path implementation (sync and async methods).&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.cloud.CloudPath panpath.base.PanPath pathlib.Path pathlib.PurePosixPath pathlib.PurePath <p>Google Cloud Storage path implementation (sync and async methods).</p> Attributes <ul> <li><code>anchor</code> \u2014 The concatenation of the drive and root, or ''.&lt;/&gt;</li> <li><code>async_client</code> (AsyncClient) \u2014 Get or create the async client for this path.&lt;/&gt;</li> <li><code>client</code> (SyncClient) \u2014 Get or create the sync client for this path.&lt;/&gt;</li> <li><code>cloud_prefix</code> (str) \u2014 Return the cloud prefix (e.g., 's3://bucket').&lt;/&gt;</li> <li><code>drive</code> \u2014 The drive prefix (letter or UNC path), if any.&lt;/&gt;</li> <li><code>key</code> (str) \u2014 Return the key/blob name without the cloud prefix.&lt;/&gt;</li> <li><code>name</code> \u2014 The final path component, if any.&lt;/&gt;</li> <li><code>parent</code> (CloudPath) \u2014 Return parent directory as same path type.&lt;/&gt;</li> <li><code>parents</code> \u2014 A sequence of this path's logical parents.&lt;/&gt;</li> <li><code>parts</code> \u2014 An object providing sequence-like access to thecomponents in the filesystem path. &lt;/&gt;</li> <li><code>root</code> \u2014 The root of the path, if any.&lt;/&gt;</li> <li><code>stem</code> \u2014 The final path component, minus its last suffix.&lt;/&gt;</li> <li><code>suffix</code> \u2014 The final component's last suffix, if any.This includes the leading period. For example: '.txt' &lt;/&gt;</li> <li><code>suffixes</code> \u2014 A list of the final component's suffixes, if any.These include the leading periods. For example: ['.tar', '.gz'] &lt;/&gt;</li> </ul> Methods <ul> <li><code>__bytes__</code><code>(</code><code>)</code> \u2014 Return the bytes representation of the path.  This is onlyrecommended to use under Unix. &lt;/&gt;</li> <li><code>__eq__</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check equality.&lt;/&gt;</li> <li><code>__hash__</code><code>(</code><code>)</code> (int) \u2014 Return hash of path.&lt;/&gt;</li> <li><code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> (CloudPath) \u2014 Create new cloud path instance.&lt;/&gt;</li> <li><code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Right join paths while preserving type and client.&lt;/&gt;</li> <li><code>__str__</code><code>(</code><code>)</code> (str) \u2014 Return properly formatted cloud URI with double slash.&lt;/&gt;</li> <li><code>__truediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>a_exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>a_glob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>a_is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>a_is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>a_is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>a_iterdir</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 List directory contents (async version returns list).&lt;/&gt;</li> <li><code>a_mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>a_open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (AsyncFileHandle) \u2014 Open file and return async file handle.&lt;/&gt;</li> <li><code>a_read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>a_read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>a_readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>a_rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>a_replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>a_resolve</code><code>(</code><code>)</code> (PanPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>a_rglob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>a_rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>a_rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>a_stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>a_touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>a_unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>a_walk</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>a_write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>a_write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to file.&lt;/&gt;</li> <li><code>absolute</code><code>(</code><code>)</code> (CloudPath) \u2014 Return absolute path - cloud paths are already absolute.&lt;/&gt;</li> <li><code>as_posix</code><code>(</code><code>)</code> \u2014 Return the string representation of the path with forward (/)slashes. &lt;/&gt;</li> <li><code>as_uri</code><code>(</code><code>)</code> (str) \u2014 Return the path as a URI (same as string representation).&lt;/&gt;</li> <li><code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks</code><code>)</code> \u2014 Change the permissions of the path, like os.chmod().&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>cwd</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the current working directory.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>expanduser</code><code>(</code><code>)</code> \u2014 Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser) &lt;/&gt;</li> <li><code>glob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>group</code><code>(</code><code>)</code> \u2014 Return the group name of the file gid.&lt;/&gt;</li> <li><code>hardlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Make this path a hard link pointing to the same file as target.&lt;/&gt;</li> <li><code>home</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')). &lt;/&gt;</li> <li><code>is_absolute</code><code>(</code><code>)</code> (bool) \u2014 Cloud paths are always absolute.&lt;/&gt;</li> <li><code>is_block_device</code><code>(</code><code>)</code> \u2014 Whether this path is a block device.&lt;/&gt;</li> <li><code>is_char_device</code><code>(</code><code>)</code> \u2014 Whether this path is a character device.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>is_fifo</code><code>(</code><code>)</code> \u2014 Whether this path is a FIFO.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>is_junction</code><code>(</code><code>)</code> \u2014 Whether this path is a junction.&lt;/&gt;</li> <li><code>is_mount</code><code>(</code><code>)</code> \u2014 Check if this path is a mount point&lt;/&gt;</li> <li><code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code> \u2014 Return True if the path is relative to another path or False.&lt;/&gt;</li> <li><code>is_reserved</code><code>(</code><code>)</code> \u2014 Return True if the path contains one of the special names reservedby the system, if any. &lt;/&gt;</li> <li><code>is_socket</code><code>(</code><code>)</code> \u2014 Whether this path is a socket.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>iterdir</code><code>(</code><code>)</code> (CloudPath) \u2014 Iterate over directory contents.&lt;/&gt;</li> <li><code>joinpath</code><code>(</code><code>*args</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>lchmod</code><code>(</code><code>mode</code><code>)</code> \u2014 Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's. &lt;/&gt;</li> <li><code>lstat</code><code>(</code><code>)</code> \u2014 Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's. &lt;/&gt;</li> <li><code>match</code><code>(</code><code>pattern</code><code>)</code> (bool) \u2014 Match path against glob pattern.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Union) \u2014 Open file for reading/writing.&lt;/&gt;</li> <li><code>owner</code><code>(</code><code>)</code> \u2014 Return the login name of the file owner.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up</code><code>)</code> \u2014 Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError. &lt;/&gt;</li> <li><code>rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>resolve</code><code>(</code><code>)</code> (CloudPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>rglob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>samefile</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check if this path refers to same file as other.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>)</code> (Iterator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>with_name</code><code>(</code><code>name</code><code>)</code> \u2014 Return a new path with the file name changed.&lt;/&gt;</li> <li><code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>. &lt;/&gt;</li> <li><code>with_stem</code><code>(</code><code>stem</code><code>)</code> \u2014 Return a new path with the stem changed.&lt;/&gt;</li> <li><code>with_suffix</code><code>(</code><code>suffix</code><code>)</code> \u2014 Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path. &lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>.</p> method &lt;/&gt; <p>Return the string representation of the path with forward (/)slashes.</p> method &lt;/&gt; <p>Return the bytes representation of the path.  This is onlyrecommended to use under Unix.</p> method &lt;/&gt; <p>Return a new path with the file name changed.</p> method &lt;/&gt; <p>Return a new path with the stem changed.</p> method &lt;/&gt; <p>Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path.</p> method &lt;/&gt; <p>Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError.</p> <p>The walk_up parameter controls whether <code>..</code> may be used to resolve the path.</p> method &lt;/&gt; <p>Return True if the path is relative to another path or False.</p> method &lt;/&gt; <p>Return True if the path contains one of the special names reservedby the system, if any.</p> method &lt;/&gt; <p>Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's.</p> method &lt;/&gt; <p>Check if this path is a mount point</p> method &lt;/&gt; <p>Whether this path is a junction.</p> method &lt;/&gt; <p>Whether this path is a block device.</p> method &lt;/&gt; <p>Whether this path is a character device.</p> method &lt;/&gt; <p>Whether this path is a FIFO.</p> method &lt;/&gt; <p>Whether this path is a socket.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the current working directory.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')).</p> method &lt;/&gt; <p>Return the login name of the file owner.</p> method &lt;/&gt; <p>Return the group name of the file gid.</p> method &lt;/&gt; <p>Change the permissions of the path, like os.chmod().</p> method &lt;/&gt; <p>Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's.</p> method &lt;/&gt; <p>Make this path a hard link pointing to the same file as target.</p><p>Note the order of arguments (self, target) is the reverse of os.link's.</p> method &lt;/&gt; <p>Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser)</p> staticmethod &lt;/&gt; <p>Create new cloud path instance.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Right join paths while preserving type and client.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Return properly formatted cloud URI with double slash.</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write bytes to file.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Delete file.</p> generator &lt;/&gt; <p>Iterate over directory contents.</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Open file for reading/writing.</p> method &lt;/&gt; <p>Check equality.</p> method &lt;/&gt; <p>Return hash of path.</p> method &lt;/&gt; <p>Return absolute path - cloud paths are already absolute.</p> method &lt;/&gt; <p>Cloud paths are always absolute.</p> method &lt;/&gt; <p>Return the path as a URI (same as string representation).</p> method &lt;/&gt; <p>Match path against glob pattern.</p><p>Override to work correctly with cloud URIs by matching against the key portion of the path (excluding scheme and bucket).</p> generator &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (Iterator) <p>List of matching paths</p> generator &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (Iterator) <p>List of matching paths (recursive)</p> generator &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (Iterator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (CloudPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Check if this path refers to same file as other.</p> Parameters <ul> <li><code>other</code> (Union) \u2014 Path to compare</li> </ul> Returns (bool) <p>True if paths are the same</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> Parameters <ul> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Write bytes to file.</p> Parameters <ul> <li><code>data</code> (bytes) \u2014 Bytes to write to the file.</li> </ul> method &lt;/&gt; <p>Write text to file.</p> Parameters <ul> <li><code>data</code> (str) \u2014 Text to write to the file.</li> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Delete file.</p> Parameters <ul> <li><code>missing_ok</code> (bool, optional) \u2014 If True, does not raise an error if the file does not exist.</li> </ul> method &lt;/&gt; <p>List directory contents (async version returns list).</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths</p> method &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths (recursive)</p> method &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (AsyncGenerator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 File mode (permissions) to set if creating the file.</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (PanPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> <li><code>target_is_directory</code> (bool, optional) \u2014 Ignored (for compatibility with pathlib)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (PanPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Open file and return async file handle.</p> Parameters <ul> <li><code>mode</code> (str, optional) \u2014 File mode (e.g., 'r', 'w', 'rb', 'wb')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments passed to the async client</li> </ul> Returns (AsyncFileHandle) <p>Async file handle from the async client</p>"},{"location":"api/panpath.gs_path/#panpathgs_path","title":"panpath.gs_path","text":""},{"location":"api/panpath.gs_path/#panpathgs_pathgspath","title":"<code>panpath.gs_path.</code><code>GSPath</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathwith_segments","title":"<code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathas_posix","title":"<code>as_posix</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathbytes","title":"<code>__bytes__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathwith_name","title":"<code>with_name</code><code>(</code><code>name</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathwith_stem","title":"<code>with_stem</code><code>(</code><code>stem</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathwith_suffix","title":"<code>with_suffix</code><code>(</code><code>suffix</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathrelative_to","title":"<code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathis_relative_to","title":"<code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpurepathis_reserved","title":"<code>is_reserved</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathlstat","title":"<code>lstat</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathis_mount","title":"<code>is_mount</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathis_junction","title":"<code>is_junction</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathis_block_device","title":"<code>is_block_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathis_char_device","title":"<code>is_char_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathis_fifo","title":"<code>is_fifo</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathis_socket","title":"<code>is_socket</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathcwd","title":"<code>cwd</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathhome","title":"<code>home</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathowner","title":"<code>owner</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathgroup","title":"<code>group</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathchmod","title":"<code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathlchmod","title":"<code>lchmod</code><code>(</code><code>mode</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathhardlink_to","title":"<code>hardlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#pathlibpathexpanduser","title":"<code>expanduser</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathnew","title":"<code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathtruediv","title":"<code>__truediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathrtruediv","title":"<code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathjoinpath","title":"<code>joinpath</code><code>(</code><code>*args</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathstr","title":"<code>__str__</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathexists","title":"<code>exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathread_bytes","title":"<code>read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathread_text","title":"<code>read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathwrite_text","title":"<code>write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathunlink","title":"<code>unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathiterdir","title":"<code>iterdir</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathis_dir","title":"<code>is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathis_file","title":"<code>is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathstat","title":"<code>stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathmkdir","title":"<code>mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathopen","title":"<code>open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatheq","title":"<code>__eq__</code><code>(</code><code>other</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathhash","title":"<code>__hash__</code><code>(</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathabsolute","title":"<code>absolute</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathis_absolute","title":"<code>is_absolute</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathas_uri","title":"<code>as_uri</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathmatch","title":"<code>match</code><code>(</code><code>pattern</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathglob","title":"<code>glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathrglob","title":"<code>rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathwalk","title":"<code>walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathtouch","title":"<code>touch</code><code>(</code><code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathrename","title":"<code>rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathreplace","title":"<code>replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathrmdir","title":"<code>rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathresolve","title":"<code>resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathsamefile","title":"<code>samefile</code><code>(</code><code>other</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathis_symlink","title":"<code>is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathreadlink","title":"<code>readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathsymlink_to","title":"<code>symlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathrmtree","title":"<code>rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathcopy","title":"<code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpathcopytree","title":"<code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_exists","title":"<code>a_exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_read_bytes","title":"<code>a_read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_read_text","title":"<code>a_read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_write_bytes","title":"<code>a_write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_write_text","title":"<code>a_write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_unlink","title":"<code>a_unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_iterdir","title":"<code>a_iterdir</code><code>(</code><code>)</code> \u2192 AsyncGenerator","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_is_dir","title":"<code>a_is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_is_file","title":"<code>a_is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_stat","title":"<code>a_stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_mkdir","title":"<code>a_mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_glob","title":"<code>a_glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_rglob","title":"<code>a_rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_walk","title":"<code>a_walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_touch","title":"<code>a_touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_rename","title":"<code>a_rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_replace","title":"<code>a_replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_resolve","title":"<code>a_resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_rmdir","title":"<code>a_rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_is_symlink","title":"<code>a_is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_readlink","title":"<code>a_readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_symlink_to","title":"<code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_rmtree","title":"<code>a_rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_copy","title":"<code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_copytree","title":"<code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.gs_path/#panpathcloudcloudpatha_open","title":"<code>a_open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.local_path/","title":"panpath.local_path","text":"module &lt;/&gt; <p>Local filesystem path implementation.</p> Classes <ul> <li><code>LocalPath</code> \u2014 Local filesystem path (drop-in replacement for pathlib.Path).&lt;/&gt;</li> </ul> class &lt;/&gt; Bases pathlib.PosixPath panpath.base.PanPath pathlib.Path pathlib.PurePosixPath pathlib.PurePath <p>Local filesystem path (drop-in replacement for pathlib.Path).</p><p>Inherits from the platform-specific concrete path class (PosixPath/WindowsPath) and PanPath for full compatibility. The concrete class must come first in MRO to ensure proper flavour attribute inheritance in Python 3.10. Includes both sync methods (from Path) and async methods with a prefix.</p> Attributes <ul> <li><code>anchor</code> \u2014 The concatenation of the drive and root, or ''.&lt;/&gt;</li> <li><code>drive</code> \u2014 The drive prefix (letter or UNC path), if any.&lt;/&gt;</li> <li><code>name</code> \u2014 The final path component, if any.&lt;/&gt;</li> <li><code>parent</code> \u2014 The logical parent of the path.&lt;/&gt;</li> <li><code>parents</code> \u2014 A sequence of this path's logical parents.&lt;/&gt;</li> <li><code>parts</code> \u2014 An object providing sequence-like access to thecomponents in the filesystem path. &lt;/&gt;</li> <li><code>root</code> \u2014 The root of the path, if any.&lt;/&gt;</li> <li><code>stem</code> \u2014 The final path component, minus its last suffix.&lt;/&gt;</li> <li><code>suffix</code> \u2014 The final component's last suffix, if any.This includes the leading period. For example: '.txt' &lt;/&gt;</li> <li><code>suffixes</code> \u2014 A list of the final component's suffixes, if any.These include the leading periods. For example: ['.tar', '.gz'] &lt;/&gt;</li> </ul> Methods <ul> <li><code>__bytes__</code><code>(</code><code>)</code> \u2014 Return the bytes representation of the path.  This is onlyrecommended to use under Unix. &lt;/&gt;</li> <li><code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> (PanPath) \u2014 Create and return the appropriate path instance.&lt;/&gt;</li> <li><code>__str__</code><code>(</code><code>)</code> \u2014 Return the string representation of the path, suitable forpassing to system calls. &lt;/&gt;</li> <li><code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Recursively copy the directory and all its contents to the target path.&lt;/&gt;</li> <li><code>a_exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists (async).&lt;/&gt;</li> <li><code>a_glob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Asynchronously yield paths matching the glob pattern.&lt;/&gt;</li> <li><code>a_is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory (async).&lt;/&gt;</li> <li><code>a_is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file (async).&lt;/&gt;</li> <li><code>a_is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a symlink (async).&lt;/&gt;</li> <li><code>a_iterdir</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 List directory contents (async).&lt;/&gt;</li> <li><code>a_mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create directory (async).&lt;/&gt;</li> <li><code>a_open</code><code>(</code><code>mode</code>, <code>buffering</code>, <code>encoding</code>, <code>errors</code>, <code>newline</code><code>)</code> (Any) \u2014 Open file and return async file handle.&lt;/&gt;</li> <li><code>a_read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes (async).&lt;/&gt;</li> <li><code>a_read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text (async).&lt;/&gt;</li> <li><code>a_readlink</code><code>(</code><code>)</code> (LocalPath) \u2014 Asynchronously read the target of a symbolic link.&lt;/&gt;</li> <li><code>a_rename</code><code>(</code><code>target</code><code>)</code> (PanPath) \u2014 Rename the file or directory to target.&lt;/&gt;</li> <li><code>a_replace</code><code>(</code><code>target</code><code>)</code> (PanPath) \u2014 Rename the file or directory to target, overwriting if target exists.&lt;/&gt;</li> <li><code>a_resolve</code><code>(</code><code>)</code> (PanPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>a_rglob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Recursively yield all existing files matching the given pattern.&lt;/&gt;</li> <li><code>a_rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory (async).&lt;/&gt;</li> <li><code>a_rmtree</code><code>(</code><code>)</code> \u2014 Recursively remove directory and its contents (async).&lt;/&gt;</li> <li><code>a_stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (stat_result) \u2014 Get file stats (async).&lt;/&gt;</li> <li><code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Asynchronously create a symbolic link pointing to target.&lt;/&gt;</li> <li><code>a_touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create the file if it does not exist or update the modification time (async).&lt;/&gt;</li> <li><code>a_unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file (async).&lt;/&gt;</li> <li><code>a_walk</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 Asynchronously walk the directory tree.&lt;/&gt;</li> <li><code>a_write_bytes</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write bytes to file (async).&lt;/&gt;</li> <li><code>a_write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to file (async).&lt;/&gt;</li> <li><code>absolute</code><code>(</code><code>)</code> \u2014 Return an absolute version of this path by prepending the currentworking directory. No normalization or symlink resolution is performed. &lt;/&gt;</li> <li><code>as_posix</code><code>(</code><code>)</code> \u2014 Return the string representation of the path with forward (/)slashes. &lt;/&gt;</li> <li><code>as_uri</code><code>(</code><code>)</code> \u2014 Return the path as a 'file' URI.&lt;/&gt;</li> <li><code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks</code><code>)</code> \u2014 Change the permissions of the path, like os.chmod().&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Recursively copy the directory and all its contents to the target path.&lt;/&gt;</li> <li><code>cwd</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the current working directory.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>follow_symlinks</code><code>)</code> \u2014 Whether this path exists.&lt;/&gt;</li> <li><code>expanduser</code><code>(</code><code>)</code> \u2014 Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser) &lt;/&gt;</li> <li><code>glob</code><code>(</code><code>pattern</code>, <code>case_sensitive</code><code>)</code> \u2014 Iterate over this subtree and yield all existing files (of anykind, including directories) matching the given relative pattern. &lt;/&gt;</li> <li><code>group</code><code>(</code><code>)</code> \u2014 Return the group name of the file gid.&lt;/&gt;</li> <li><code>hardlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Make this path a hard link pointing to the same file as target.&lt;/&gt;</li> <li><code>home</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')). &lt;/&gt;</li> <li><code>is_absolute</code><code>(</code><code>)</code> \u2014 True if the path is absolute (has both a root and, if applicable,a drive). &lt;/&gt;</li> <li><code>is_block_device</code><code>(</code><code>)</code> \u2014 Whether this path is a block device.&lt;/&gt;</li> <li><code>is_char_device</code><code>(</code><code>)</code> \u2014 Whether this path is a character device.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>)</code> \u2014 Whether this path is a directory.&lt;/&gt;</li> <li><code>is_fifo</code><code>(</code><code>)</code> \u2014 Whether this path is a FIFO.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>)</code> \u2014 Whether this path is a regular file (also True for symlinks pointingto regular files). &lt;/&gt;</li> <li><code>is_junction</code><code>(</code><code>)</code> \u2014 Whether this path is a junction.&lt;/&gt;</li> <li><code>is_mount</code><code>(</code><code>)</code> \u2014 Check if this path is a mount point&lt;/&gt;</li> <li><code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code> \u2014 Return True if the path is relative to another path or False.&lt;/&gt;</li> <li><code>is_reserved</code><code>(</code><code>)</code> \u2014 Return True if the path contains one of the special names reservedby the system, if any. &lt;/&gt;</li> <li><code>is_socket</code><code>(</code><code>)</code> \u2014 Whether this path is a socket.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>)</code> \u2014 Whether this path is a symbolic link.&lt;/&gt;</li> <li><code>iterdir</code><code>(</code><code>)</code> \u2014 Yield path objects of the directory contents.&lt;/&gt;</li> <li><code>joinpath</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Combine this path with one or several arguments, and return anew path representing either a subpath (if all arguments are relative paths) or a totally different path (if one of the arguments is anchored). &lt;/&gt;</li> <li><code>lchmod</code><code>(</code><code>mode</code><code>)</code> \u2014 Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's. &lt;/&gt;</li> <li><code>lstat</code><code>(</code><code>)</code> \u2014 Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's. &lt;/&gt;</li> <li><code>match</code><code>(</code><code>path_pattern</code>, <code>case_sensitive</code><code>)</code> \u2014 Return True if this path matches the given pattern.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a new directory at this given path.&lt;/&gt;</li> <li><code>open</code><code>(</code><code>mode</code>, <code>buffering</code>, <code>encoding</code>, <code>errors</code>, <code>newline</code><code>)</code> \u2014 Open the file pointed to by this path and return a file object, asthe built-in open() function does. &lt;/&gt;</li> <li><code>owner</code><code>(</code><code>)</code> \u2014 Return the login name of the file owner.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>)</code> \u2014 Open the file in bytes mode, read it, and close the file.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>encoding</code>, <code>errors</code><code>)</code> \u2014 Open the file in text mode, read it, and close the file.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>)</code> \u2014 Return the path to which the symbolic link points.&lt;/&gt;</li> <li><code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up</code><code>)</code> \u2014 Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError. &lt;/&gt;</li> <li><code>rename</code><code>(</code><code>target</code><code>)</code> (PanPath) \u2014 Rename the file or directory to target.&lt;/&gt;</li> <li><code>replace</code><code>(</code><code>target</code><code>)</code> \u2014 Rename this path to the target path, overwriting if that path exists.&lt;/&gt;</li> <li><code>resolve</code><code>(</code><code>strict</code><code>)</code> \u2014 Make the path absolute, resolving all symlinks on the way and alsonormalizing it. &lt;/&gt;</li> <li><code>rglob</code><code>(</code><code>pattern</code>, <code>case_sensitive</code><code>)</code> \u2014 Recursively yield all existing files (of any kind, includingdirectories) matching the given relative pattern, anywhere in this subtree. &lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>)</code> \u2014 Recursively remove directory and its contents.&lt;/&gt;</li> <li><code>samefile</code><code>(</code><code>other_path</code><code>)</code> \u2014 Return whether other_path is the same or not as this file(as returned by os.path.samefile()). &lt;/&gt;</li> <li><code>stat</code><code>(</code><code>follow_symlinks</code><code>)</code> \u2014 Return the result of the stat() system call on this path, likeos.stat() does. &lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Make this path a symlink pointing to the target path.Note the order of arguments (link, target) is the reverse of os.symlink. &lt;/&gt;</li> <li><code>touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create this file with the given access mode, if it doesn't exist.&lt;/&gt;</li> <li><code>unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Remove this file or link.If the path is a directory, use rmdir() instead. &lt;/&gt;</li> <li><code>walk</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> (List) \u2014 Walk the directory tree.&lt;/&gt;</li> <li><code>with_name</code><code>(</code><code>name</code><code>)</code> \u2014 Return a new path with the file name changed.&lt;/&gt;</li> <li><code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>. &lt;/&gt;</li> <li><code>with_stem</code><code>(</code><code>stem</code><code>)</code> \u2014 Return a new path with the stem changed.&lt;/&gt;</li> <li><code>with_suffix</code><code>(</code><code>suffix</code><code>)</code> \u2014 Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path. &lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Open the file in bytes mode, write to it, and close the file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>data</code>, <code>encoding</code>, <code>errors</code>, <code>newline</code><code>)</code> \u2014 Open the file in text mode, write to it, and close the file.&lt;/&gt;</li> </ul> staticmethod &lt;/&gt; <p>Create and return the appropriate path instance.</p><p>If called on a subclass, returns instance of that subclass. If called on PanPath itself, routes to the appropriate concrete class.</p> method &lt;/&gt; <p>Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>.</p> method &lt;/&gt; <p>Return the string representation of the path, suitable forpassing to system calls.</p> method &lt;/&gt; <p>Return the string representation of the path with forward (/)slashes.</p> method &lt;/&gt; <p>Return the bytes representation of the path.  This is onlyrecommended to use under Unix.</p> method &lt;/&gt; <p>Return the path as a 'file' URI.</p> method &lt;/&gt; <p>Return a new path with the file name changed.</p> method &lt;/&gt; <p>Return a new path with the stem changed.</p> method &lt;/&gt; <p>Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path.</p> method &lt;/&gt; <p>Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError.</p> <p>The walk_up parameter controls whether <code>..</code> may be used to resolve the path.</p> method &lt;/&gt; <p>Return True if the path is relative to another path or False.</p> method &lt;/&gt; <p>Combine this path with one or several arguments, and return anew path representing either a subpath (if all arguments are relative paths) or a totally different path (if one of the arguments is anchored).</p> method &lt;/&gt; <p>True if the path is absolute (has both a root and, if applicable,a drive).</p> method &lt;/&gt; <p>Return True if the path contains one of the special names reservedby the system, if any.</p> method &lt;/&gt; <p>Return True if this path matches the given pattern.</p> method &lt;/&gt; <p>Return the result of the stat() system call on this path, likeos.stat() does.</p> method &lt;/&gt; <p>Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's.</p> method &lt;/&gt; <p>Whether this path exists.</p><p>This method normally follows symlinks; to check whether a symlink exists, add the argument follow_symlinks=False.</p> method &lt;/&gt; <p>Whether this path is a directory.</p> method &lt;/&gt; <p>Whether this path is a regular file (also True for symlinks pointingto regular files).</p> method &lt;/&gt; <p>Check if this path is a mount point</p> method &lt;/&gt; <p>Whether this path is a symbolic link.</p> method &lt;/&gt; <p>Whether this path is a junction.</p> method &lt;/&gt; <p>Whether this path is a block device.</p> method &lt;/&gt; <p>Whether this path is a character device.</p> method &lt;/&gt; <p>Whether this path is a FIFO.</p> method &lt;/&gt; <p>Whether this path is a socket.</p> method &lt;/&gt; <p>Return whether other_path is the same or not as this file(as returned by os.path.samefile()).</p> method &lt;/&gt; <p>Open the file pointed to by this path and return a file object, asthe built-in open() function does.</p> method &lt;/&gt; <p>Open the file in bytes mode, read it, and close the file.</p> method &lt;/&gt; <p>Open the file in text mode, read it, and close the file.</p> method &lt;/&gt; <p>Open the file in bytes mode, write to it, and close the file.</p> method &lt;/&gt; <p>Open the file in text mode, write to it, and close the file.</p> generator &lt;/&gt; <p>Yield path objects of the directory contents.</p><p>The children are yielded in arbitrary order, and the special entries '.' and '..' are not included.</p> generator &lt;/&gt; <p>Iterate over this subtree and yield all existing files (of anykind, including directories) matching the given relative pattern.</p> generator &lt;/&gt; <p>Recursively yield all existing files (of any kind, includingdirectories) matching the given relative pattern, anywhere in this subtree.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the current working directory.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')).</p> method &lt;/&gt; <p>Return an absolute version of this path by prepending the currentworking directory. No normalization or symlink resolution is performed.</p> <p>Use resolve() to get the canonical path to a file.</p> method &lt;/&gt; <p>Make the path absolute, resolving all symlinks on the way and alsonormalizing it.</p> method &lt;/&gt; <p>Return the login name of the file owner.</p> method &lt;/&gt; <p>Return the group name of the file gid.</p> method &lt;/&gt; <p>Return the path to which the symbolic link points.</p> method &lt;/&gt; <p>Create this file with the given access mode, if it doesn't exist.</p> method &lt;/&gt; <p>Create a new directory at this given path.</p> method &lt;/&gt; <p>Change the permissions of the path, like os.chmod().</p> method &lt;/&gt; <p>Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's.</p> method &lt;/&gt; <p>Remove this file or link.If the path is a directory, use rmdir() instead.</p> method &lt;/&gt; <p>Rename this path to the target path, overwriting if that path exists.</p><p>The target path may be absolute or relative. Relative paths are interpreted relative to the current working directory, not the directory of the Path object.</p> <p>Returns the new Path instance pointing to the target path.</p> method &lt;/&gt; <p>Make this path a symlink pointing to the target path.Note the order of arguments (link, target) is the reverse of os.symlink.</p> method &lt;/&gt; <p>Make this path a hard link pointing to the same file as target.</p><p>Note the order of arguments (self, target) is the reverse of os.link's.</p> method &lt;/&gt; <p>Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser)</p> method &lt;/&gt; <p>Create the file if it does not exist or update the modification time (async).</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 File mode (permissions) to set if creating the file.</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raises an error if the file already exists.</li> </ul> method &lt;/&gt; <p>Rename the file or directory to target.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path</li> </ul> Returns (PanPath) <p>New path instance</p> method &lt;/&gt; <p>Rename the file or directory to target, overwriting if target exists.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path</li> </ul> Returns (PanPath) <p>New path instance</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (PanPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (PanPath) <p>Target path instance</p> method &lt;/&gt; <p>Recursively copy the directory and all its contents to the target path.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination PanPath to copy to.</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If True, copies the contents of symlinks.</li> </ul> Returns (PanPath) <p>The copied PanPath instance.</p> method &lt;/&gt; <p>Asynchronously walk the directory tree.</p> Returns (AsyncGenerator) <p>A list of tuples (dirpath, dirnames, filenames)</p> method &lt;/&gt; <p>Asynchronously read the target of a symbolic link.</p> Returns (LocalPath) <p>The path to which the symbolic link points.</p> method &lt;/&gt; <p>Asynchronously create a symbolic link pointing to target.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 The target path the symbolic link points to.</li> <li><code>target_is_directory</code> (bool, optional) \u2014 Whether the target is a directory.</li> </ul> method &lt;/&gt; <p>Asynchronously yield paths matching the glob pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Glob pattern (relative)</li> </ul> Yields (AsyncGenerator) <p>Matching LocalPath instances</p> method &lt;/&gt; <p>Recursively yield all existing files matching the given pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Glob pattern (relative)</li> </ul> Yields (AsyncGenerator) <p>Matching LocalPath instances</p> method &lt;/&gt; <p>Check if path exists (async).</p> method &lt;/&gt; <p>Check if path is a file (async).</p> method &lt;/&gt; <p>Check if path is a directory (async).</p> method &lt;/&gt; <p>Read file as bytes (async).</p> method &lt;/&gt; <p>Read file as text (async).</p> Parameters <ul> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Write bytes to file (async).</p> Parameters <ul> <li><code>data</code> (bytes) \u2014 Bytes to write to the file.</li> </ul> method &lt;/&gt; <p>Write text to file (async).</p> Parameters <ul> <li><code>data</code> (str) \u2014 Text to write to the file.</li> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Check if path is a symlink (async).</p> method &lt;/&gt; <p>Delete file (async).</p> Parameters <ul> <li><code>missing_ok</code> (bool, optional) \u2014 If True, does not raise an error if the file does not exist.</li> </ul> method &lt;/&gt; <p>Create directory (async).</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Directory mode (permissions) to set.</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed.</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, does not raise an error if the directory already exists.</li> </ul> method &lt;/&gt; <p>Remove empty directory (async).</p> method &lt;/&gt; <p>Recursively remove directory and its contents (async).</p> method &lt;/&gt; <p>List directory contents (async).</p> method &lt;/&gt; <p>Get file stats (async).</p> method &lt;/&gt; <p>Open file and return async file handle.</p> Parameters <ul> <li><code>mode</code> (str, optional) \u2014 Mode to open the file (e.g., 'r', 'rb', 'w', 'wb').</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding to use (default: 'utf-8').</li> </ul> Returns (Any) <p>Async file handle from aiofiles</p> method &lt;/&gt; <p>Rename the file or directory to target.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path</li> </ul> Returns (PanPath) <p>New path instance</p> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If True, follow symbolic links</li> </ul> Returns (PanPath) <p>Target path instance</p> method &lt;/&gt; <p>Recursively copy the directory and all its contents to the target path.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination PanPath to copy to.</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If True, copies the contents of symlinks.</li> </ul> Returns (PanPath) <p>The copied PanPath instance.</p> method &lt;/&gt; <p>Remove empty directory.</p> method &lt;/&gt; <p>Recursively remove directory and its contents.</p> method &lt;/&gt; <p>Walk the directory tree.</p> Returns (List) <p>A list of tuples (dirpath, dirnames, filenames)</p>"},{"location":"api/panpath.local_path/#panpathlocal_path","title":"panpath.local_path","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpath","title":"<code>panpath.local_path.</code><code>LocalPath</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathbasepanpathnew","title":"<code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 PanPath","text":""},{"location":"api/panpath.local_path/#pathlibpurepathwith_segments","title":"<code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathstr","title":"<code>__str__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathas_posix","title":"<code>as_posix</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathbytes","title":"<code>__bytes__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathas_uri","title":"<code>as_uri</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathwith_name","title":"<code>with_name</code><code>(</code><code>name</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathwith_stem","title":"<code>with_stem</code><code>(</code><code>stem</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathwith_suffix","title":"<code>with_suffix</code><code>(</code><code>suffix</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathrelative_to","title":"<code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathis_relative_to","title":"<code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathjoinpath","title":"<code>joinpath</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathis_absolute","title":"<code>is_absolute</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathis_reserved","title":"<code>is_reserved</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpurepathmatch","title":"<code>match</code><code>(</code><code>path_pattern</code>, <code>case_sensitive=None</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathstat","title":"<code>stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathlstat","title":"<code>lstat</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathexists","title":"<code>exists</code><code>(</code><code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_dir","title":"<code>is_dir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_file","title":"<code>is_file</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_mount","title":"<code>is_mount</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_symlink","title":"<code>is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_junction","title":"<code>is_junction</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_block_device","title":"<code>is_block_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_char_device","title":"<code>is_char_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_fifo","title":"<code>is_fifo</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathis_socket","title":"<code>is_socket</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathsamefile","title":"<code>samefile</code><code>(</code><code>other_path</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathopen","title":"<code>open</code><code>(</code><code>mode='r'</code>, <code>buffering=-1</code>, <code>encoding=None</code>, <code>errors=None</code>, <code>newline=None</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathread_bytes","title":"<code>read_bytes</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathread_text","title":"<code>read_text</code><code>(</code><code>encoding=None</code>, <code>errors=None</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathwrite_text","title":"<code>write_text</code><code>(</code><code>data</code>, <code>encoding=None</code>, <code>errors=None</code>, <code>newline=None</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathiterdir","title":"<code>iterdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathglob","title":"<code>glob</code><code>(</code><code>pattern</code>, <code>case_sensitive=None</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathrglob","title":"<code>rglob</code><code>(</code><code>pattern</code>, <code>case_sensitive=None</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathcwd","title":"<code>cwd</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathhome","title":"<code>home</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathabsolute","title":"<code>absolute</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathresolve","title":"<code>resolve</code><code>(</code><code>strict=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathowner","title":"<code>owner</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathgroup","title":"<code>group</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathreadlink","title":"<code>readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathtouch","title":"<code>touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathmkdir","title":"<code>mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathchmod","title":"<code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathlchmod","title":"<code>lchmod</code><code>(</code><code>mode</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathunlink","title":"<code>unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathreplace","title":"<code>replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathsymlink_to","title":"<code>symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathhardlink_to","title":"<code>hardlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#pathlibpathexpanduser","title":"<code>expanduser</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_touch","title":"<code>a_touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_rename","title":"<code>a_rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_replace","title":"<code>a_replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_resolve","title":"<code>a_resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_copy","title":"<code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_copytree","title":"<code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_walk","title":"<code>a_walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_readlink","title":"<code>a_readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_symlink_to","title":"<code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_glob","title":"<code>a_glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_rglob","title":"<code>a_rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_exists","title":"<code>a_exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_is_file","title":"<code>a_is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_is_dir","title":"<code>a_is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_read_bytes","title":"<code>a_read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_read_text","title":"<code>a_read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_write_bytes","title":"<code>a_write_bytes</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_write_text","title":"<code>a_write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_is_symlink","title":"<code>a_is_symlink</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_unlink","title":"<code>a_unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_mkdir","title":"<code>a_mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_rmdir","title":"<code>a_rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_rmtree","title":"<code>a_rmtree</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_iterdir","title":"<code>a_iterdir</code><code>(</code><code>)</code> \u2192 AsyncGenerator","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_stat","title":"<code>a_stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 stat_result","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpatha_open","title":"<code>a_open</code><code>(</code><code>mode='r'</code>, <code>buffering=-1</code>, <code>encoding=None</code>, <code>errors=None</code>, <code>newline=None</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpathrename","title":"<code>rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpathcopy","title":"<code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpathcopytree","title":"<code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpathrmdir","title":"<code>rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpathrmtree","title":"<code>rmtree</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.local_path/#panpathlocal_pathlocalpathwalk","title":"<code>walk</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath/","title":"panpath","text":"package &lt;/&gt; <p>PanPath - Universal sync/async local/cloud path library.</p> Examples <pre><code>&gt;&gt;&gt; from panpath import PanPath&gt;&gt;&gt;\n&gt;&gt;&gt; # Local path (sync methods)\n&gt;&gt;&gt; path = PanPath(\"/path/to/file.txt\")\n&gt;&gt;&gt; content = path.read_text()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Local path (async methods with a_ prefix)\n&gt;&gt;&gt; content = await path.a_read_text()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # S3 path (sync methods)\n&gt;&gt;&gt; s3_path = PanPath(\"s3://bucket/key.txt\")\n&gt;&gt;&gt; content = s3_path.read_text()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # S3 path (async methods with a_ prefix)\n&gt;&gt;&gt; content = await s3_path.a_read_text()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check if object is a PanPath instance\n&gt;&gt;&gt; isinstance(path, PanPath)  # True for any path created by this package\n</code></pre> module &lt;/&gt; <p>Async Azure Blob Storage client implementation.</p> Classes <ul> <li><code>AsyncAzureBlobClient</code> \u2014 Asynchronous Azure Blob Storage client implementation.&lt;/&gt;</li> <li><code>AzureAsyncFileHandle</code> \u2014 Async file handle for Azure with chunked streaming support.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Base classes for cloud path implementations.</p> Classes <ul> <li><code>CloudPath</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> (CloudPath) \u2014 Base class for cloud path implementations.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Async Google Cloud Storage client implementation.</p> Classes <ul> <li><code>AsyncGSClient</code> \u2014 Asynchronous Google Cloud Storage client implementation.&lt;/&gt;</li> <li><code>GSAsyncFileHandle</code> \u2014 Async file handle for GCS with chunked streaming support.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Local filesystem path implementation.</p> Classes <ul> <li><code>LocalPath</code> \u2014 Local filesystem path (drop-in replacement for pathlib.Path).&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Google Cloud Storage client implementation.</p> Classes <ul> <li><code>GSClient</code> \u2014 Synchronous Google Cloud Storage client implementation.&lt;/&gt;</li> <li><code>GSSyncFileHandle</code> \u2014 Sync file handle for GCS with chunked streaming support.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Google Cloud Storage path implementation.</p> Classes <ul> <li><code>GSPath</code> (CloudPath) \u2014 Google Cloud Storage path implementation (sync and async methods).&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Azure Blob Storage path implementation.</p> Classes <ul> <li><code>AzurePath</code> (CloudPath) \u2014 Azure Blob Storage path implementation (sync and async methods).&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Exception classes for panpath.</p> Classes <ul> <li><code>PanPathError</code> \u2014 Base exception for panpath errors.&lt;/&gt;</li> <li><code>MissingDependencyError</code> \u2014 Raised when a required dependency is not installed.&lt;/&gt;</li> <li><code>CloudPathError</code> \u2014 Base exception for cloud path errors.&lt;/&gt;</li> <li><code>NoStatError</code> \u2014 Raised when stat information cannot be retrieved.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>S3 path implementation.</p> Classes <ul> <li><code>S3Path</code> (CloudPath) \u2014 S3 path implementation (sync and async methods).&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Azure Blob Storage client implementation.</p> Classes <ul> <li><code>AzureBlobClient</code> \u2014 Synchronous Azure Blob Storage client implementation.&lt;/&gt;</li> <li><code>AzureSyncFileHandle</code> \u2014 Synchronous file handle for Azure Blob Storage.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Base client classes for sync and async cloud storage operations.</p> Classes <ul> <li><code>Client</code><code>(</code><code>)</code> \u2014 Base class for cloud storage clients.&lt;/&gt;</li> <li><code>SyncClient</code><code>(</code><code>)</code> \u2014 Base class for synchronous cloud storage clients.&lt;/&gt;</li> <li><code>AsyncClient</code><code>(</code><code>)</code> \u2014 Base class for asynchronous cloud storage clients.&lt;/&gt;</li> <li><code>AsyncFileHandle</code><code>(</code><code>client_factory</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode</code>, <code>encoding</code>, <code>chunk_size</code>, <code>upload_warning_threshold</code>, <code>upload_interval</code><code>)</code> \u2014 Base class for async file handles.&lt;/&gt;</li> <li><code>SyncFileHandle</code><code>(</code><code>client</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode</code>, <code>encoding</code>, <code>chunk_size</code>, <code>upload_warning_threshold</code>, <code>upload_interval</code><code>)</code> \u2014 Base class for sync file handles.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Async S3 client implementation.</p> Classes <ul> <li><code>AsyncS3Client</code> \u2014 Asynchronous S3 client implementation using aioboto3.&lt;/&gt;</li> <li><code>S3AsyncFileHandle</code> \u2014 Async file handle for S3 with streaming support.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>S3 client implementation.</p> Classes <ul> <li><code>S3Client</code> \u2014 Synchronous S3 client implementation using boto3.&lt;/&gt;</li> <li><code>S3SyncFileHandle</code> \u2014 Sync file handle for S3 with chunked streaming support.&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Registry for path class implementations.</p> Functions <ul> <li><code>clear_registry</code><code>(</code><code>)</code> \u2014 Clear the registry (mainly for testing).&lt;/&gt;</li> <li><code>get_path_class</code><code>(</code><code>scheme</code><code>)</code> (Type) \u2014 Get the path class for a URI scheme.&lt;/&gt;</li> <li><code>get_registered_schemes</code><code>(</code><code>)</code> (list) \u2014 Get all registered URI schemes.&lt;/&gt;</li> <li><code>register_path_class</code><code>(</code><code>scheme</code>, <code>path_class</code><code>)</code> \u2014 Register a path class implementation for a URI scheme.&lt;/&gt;</li> <li><code>restore_registry</code><code>(</code><code>snapshot</code><code>)</code> \u2014 Restore the registry from a snapshot (for testing).&lt;/&gt;</li> <li><code>swap_implementation</code><code>(</code><code>scheme</code>, <code>path_class</code><code>)</code> (Type) \u2014 Swap implementation for a scheme (for testing with local mocks).&lt;/&gt;</li> </ul> module &lt;/&gt; <p>Base class for all PanPath path implementations.</p> Classes <ul> <li><code>PanPath</code> (PanPath) \u2014 Universal path base class and factory.&lt;/&gt;</li> </ul>"},{"location":"api/panpath/#panpath","title":"panpath","text":""},{"location":"api/panpath/#panpathazure_async_client","title":"panpath.azure_async_client","text":""},{"location":"api/panpath/#panpathcloud","title":"panpath.cloud","text":""},{"location":"api/panpath/#panpathgs_async_client","title":"panpath.gs_async_client","text":""},{"location":"api/panpath/#panpathlocal_path","title":"panpath.local_path","text":""},{"location":"api/panpath/#panpathgs_client","title":"panpath.gs_client","text":""},{"location":"api/panpath/#panpathgs_path","title":"panpath.gs_path","text":""},{"location":"api/panpath/#panpathazure_path","title":"panpath.azure_path","text":""},{"location":"api/panpath/#panpathexceptions","title":"panpath.exceptions","text":""},{"location":"api/panpath/#panpaths3_path","title":"panpath.s3_path","text":""},{"location":"api/panpath/#panpathazure_client","title":"panpath.azure_client","text":""},{"location":"api/panpath/#panpathclients","title":"panpath.clients","text":""},{"location":"api/panpath/#panpaths3_async_client","title":"panpath.s3_async_client","text":""},{"location":"api/panpath/#panpaths3_client","title":"panpath.s3_client","text":""},{"location":"api/panpath/#panpathregistry","title":"panpath.registry","text":""},{"location":"api/panpath/#panpathbase","title":"panpath.base","text":""},{"location":"api/panpath.registry/","title":"panpath.registry","text":"module &lt;/&gt; <p>Registry for path class implementations.</p> Functions <ul> <li><code>clear_registry</code><code>(</code><code>)</code> \u2014 Clear the registry (mainly for testing).&lt;/&gt;</li> <li><code>get_path_class</code><code>(</code><code>scheme</code><code>)</code> (Type) \u2014 Get the path class for a URI scheme.&lt;/&gt;</li> <li><code>get_registered_schemes</code><code>(</code><code>)</code> (list) \u2014 Get all registered URI schemes.&lt;/&gt;</li> <li><code>register_path_class</code><code>(</code><code>scheme</code>, <code>path_class</code><code>)</code> \u2014 Register a path class implementation for a URI scheme.&lt;/&gt;</li> <li><code>restore_registry</code><code>(</code><code>snapshot</code><code>)</code> \u2014 Restore the registry from a snapshot (for testing).&lt;/&gt;</li> <li><code>swap_implementation</code><code>(</code><code>scheme</code>, <code>path_class</code><code>)</code> (Type) \u2014 Swap implementation for a scheme (for testing with local mocks).&lt;/&gt;</li> </ul> function &lt;/&gt; <p>Register a path class implementation for a URI scheme.</p> Parameters <ul> <li><code>scheme</code> (str) \u2014 URI scheme (e.g., 's3', 'gs', 'az')</li> <li><code>path_class</code> (Type) \u2014 Cloud path class (with both sync and async methods)</li> </ul> function &lt;/&gt; <p>Get the path class for a URI scheme.</p> Parameters <ul> <li><code>scheme</code> (str) \u2014 URI scheme (e.g., 's3', 'gs', 'az')</li> </ul> Returns (Type) <p>Path class for the scheme</p> Raises <ul> <li><code>KeyError</code> \u2014 If scheme is not registered</li> </ul> function &lt;/&gt; <p>Get all registered URI schemes.</p> function &lt;/&gt; <p>Clear the registry (mainly for testing).</p> function &lt;/&gt; <p>Swap implementation for a scheme (for testing with local mocks).</p> Parameters <ul> <li><code>scheme</code> (str) \u2014 URI scheme to swap</li> <li><code>path_class</code> (Type) \u2014 New path class</li> </ul> Returns (Type) <p>Old path class (or None if not previously registered)</p> function &lt;/&gt; <p>Restore the registry from a snapshot (for testing).</p> Parameters <ul> <li><code>snapshot</code> (Dict) \u2014 Registry snapshot to restore</li> </ul>"},{"location":"api/panpath.registry/#panpathregistry","title":"panpath.registry","text":""},{"location":"api/panpath.registry/#panpathregistryregister_path_class","title":"<code>panpath.registry.</code><code>register_path_class</code><code>(</code><code>scheme</code>, <code>path_class</code><code>)</code>","text":""},{"location":"api/panpath.registry/#panpathregistryget_path_class","title":"<code>panpath.registry.</code><code>get_path_class</code><code>(</code><code>scheme</code><code>)</code>","text":""},{"location":"api/panpath.registry/#panpathregistryget_registered_schemes","title":"<code>panpath.registry.</code><code>get_registered_schemes</code><code>(</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.registry/#panpathregistryclear_registry","title":"<code>panpath.registry.</code><code>clear_registry</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.registry/#panpathregistryswap_implementation","title":"<code>panpath.registry.</code><code>swap_implementation</code><code>(</code><code>scheme</code>, <code>path_class</code><code>)</code>","text":""},{"location":"api/panpath.registry/#panpathregistryrestore_registry","title":"<code>panpath.registry.</code><code>restore_registry</code><code>(</code><code>snapshot</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/","title":"panpath.s3_async_client","text":"module &lt;/&gt; <p>Async S3 client implementation.</p> Classes <ul> <li><code>AsyncS3Client</code> \u2014 Asynchronous S3 client implementation using aioboto3.&lt;/&gt;</li> <li><code>S3AsyncFileHandle</code> \u2014 Async file handle for S3 with streaming support.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.clients.AsyncClient panpath.clients.Client <p>Asynchronous S3 client implementation using aioboto3.</p> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncClient) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the client and cleanup resources.&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete S3 object.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if S3 object exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get object metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if S3 path is a directory.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if S3 path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if object is a symlink (has symlink-target metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (list) \u2014 List S3 objects with prefix.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty object with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (s3asyncfilehandle) \u2014 Open S3 object and return async file handle with streaming support.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read S3 object as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read Azure blob as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set object metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (stat_result) \u2014 Get S3 object metadata.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>exist_ok</code>, <code>mode</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2014 Write bytes to S3 object.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to Azure blob.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read Azure blob as text.</p> method &lt;/&gt; <p>Write text to Azure blob.</p> method &lt;/&gt; <p>Close the client and cleanup resources.</p> method &lt;/&gt; <p>Check if S3 object exists.</p> method &lt;/&gt; <p>Read S3 object as bytes.</p> method &lt;/&gt; <p>Write bytes to S3 object.</p> method &lt;/&gt; <p>Delete S3 object.</p> method &lt;/&gt; <p>List S3 objects with prefix.</p> method &lt;/&gt; <p>Check if S3 path is a directory.</p> method &lt;/&gt; <p>Check if S3 path is a file.</p> method &lt;/&gt; <p>Get S3 object metadata.</p> method &lt;/&gt; <p>Open S3 object and return async file handle with streaming support.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path (s3://bucket/key)</li> <li><code>mode</code> (str, optional) \u2014 File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments (chunk_size, upload_warning_threshold,upload_interval supported) </li> </ul> Returns (s3asyncfilehandle) <p>S3AsyncFileHandle with streaming support</p> method &lt;/&gt; <p>Create a directory marker (empty object with trailing slash).</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path (s3://bucket/path)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Get object metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> Returns (dict) <p>Dictionary containing response metadata including 'Metadata' key with user metadata</p> method &lt;/&gt; <p>Set object metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> <li><code>metadata</code> (dict) \u2014 Dictionary of metadata key-value pairs</li> </ul> method &lt;/&gt; <p>Check if object is a symlink (has symlink-target metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> Returns (str) <p>Symlink target path</p> method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path for the symlink</li> <li><code>target</code> (str) \u2014 Target path the symlink should point to</li> </ul> method &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base S3 path</li> <li><code>pattern</code> (str) \u2014 Glob pattern (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths (as PanPath objects or strings)</p> method &lt;/&gt; <p>Walk directory tree.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base S3 path</li> </ul> Yields <p>Tuples of (dirpath, dirnames, filenames)</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> <li><code>mode</code> (Optional, optional) \u2014 Ignored for S3 (for compatibility)</li> </ul> method &lt;/&gt; <p>Rename/move file.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source S3 path</li> <li><code>target</code> (str) \u2014 Target S3 path</li> </ul> method &lt;/&gt; <p>Remove directory marker.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source S3 path</li> <li><code>target</code> (str) \u2014 Target S3 path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> method &lt;/&gt; <p>Copy directory tree to target recursively.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source S3 path</li> <li><code>target</code> (str) \u2014 Target S3 path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> class &lt;/&gt; Bases panpath.clients.AsyncFileHandle <p>Async file handle for S3 with streaming support.</p><p>Uses aioboto3's streaming API to avoid loading entire files into memory.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__aenter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Enter async context manager.&lt;/&gt;</li> <li><code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__aiter__</code><code>(</code><code>)</code> (AsyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__anext__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset the underlying stream to the beginning.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Reset the underlying stream to the beginning.</p> method &lt;/&gt; <p>Enter async context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul>"},{"location":"api/panpath.s3_async_client/#panpaths3_async_client","title":"panpath.s3_async_client","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3client","title":"<code>panpath.s3_async_client.</code><code>AsyncS3Client</code><code>(</code><code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncclientaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncClient","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncclientaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 stat_result","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientopen","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>exist_ok=True</code>, <code>mode=None</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientrename","title":"<code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientcopy","title":"<code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clientasyncs3clientcopytree","title":"<code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpaths3_async_clients3asyncfilehandle","title":"<code>panpath.s3_async_client.</code><code>S3AsyncFileHandle</code><code>(</code><code>client_factory</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>chunk_size=4096</code>, <code>upload_warning_threshold=100</code>, <code>upload_interval=1.0</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleaenter","title":"<code>__aenter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleaexit","title":"<code>__aexit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleaiter","title":"<code>__aiter__</code><code>(</code><code>)</code> \u2192 AsyncFileHandle","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleanext","title":"<code>__anext__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_async_client/#panpathclientsasyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/","title":"panpath.s3_client","text":"module &lt;/&gt; <p>S3 client implementation.</p> Classes <ul> <li><code>S3Client</code> \u2014 Synchronous S3 client implementation using boto3.&lt;/&gt;</li> <li><code>S3SyncFileHandle</code> \u2014 Sync file handle for S3 with chunked streaming support.&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.clients.SyncClient panpath.clients.Client <p>Synchronous S3 client implementation using boto3.</p> Methods <ul> <li><code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks</code><code>)</code> \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>delete</code><code>(</code><code>path</code><code>)</code> \u2014 Delete S3 object.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if S3 object exists.&lt;/&gt;</li> <li><code>get_metadata</code><code>(</code><code>path</code><code>)</code> (dict) \u2014 Get object metadata.&lt;/&gt;</li> <li><code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code> (Iterator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if S3 path is a directory (has objects with prefix).&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if S3 path is a file.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>path</code><code>)</code> (bool) \u2014 Check if object is a symlink (has symlink-target metadata).&lt;/&gt;</li> <li><code>list_dir</code><code>(</code><code>path</code><code>)</code> (list) \u2014 List S3 objects with prefix.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>path</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker (empty object with trailing slash).&lt;/&gt;</li> <li><code>open</code><code>(</code><code>path</code>, <code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Any) \u2014 Open S3 object for reading/writing with streaming support.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>path</code><code>)</code> (bytes) \u2014 Read S3 object as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>path</code>, <code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>path</code><code>)</code> (str) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code> \u2014 Rename/move file.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>path</code><code>)</code> \u2014 Remove directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code> \u2014 Set object metadata.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>path</code><code>)</code> (stat_result) \u2014 Get S3 object metadata.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code> \u2014 Create symlink by storing target in metadata.&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>path</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>path</code><code>)</code> (Iterator) \u2014 Walk directory tree.&lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code> \u2014 Write bytes to S3 object.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Check if S3 object exists.</p> method &lt;/&gt; <p>Read S3 object as bytes.</p> method &lt;/&gt; <p>Write bytes to S3 object.</p> method &lt;/&gt; <p>Delete S3 object.</p> method &lt;/&gt; <p>List S3 objects with prefix.</p> method &lt;/&gt; <p>Check if S3 path is a directory (has objects with prefix).</p> method &lt;/&gt; <p>Check if S3 path is a file.</p> method &lt;/&gt; <p>Get S3 object metadata.</p> method &lt;/&gt; <p>Open S3 object for reading/writing with streaming support.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path (s3://bucket/key)</li> <li><code>mode</code> (str, optional) \u2014 File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments (chunk_size, upload_warning_threshold,upload_interval supported) </li> </ul> Returns (Any) <p>S3SyncFileHandle with streaming support</p> method &lt;/&gt; <p>Create a directory marker (empty object with trailing slash).</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path (s3://bucket/path)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Get object metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> Returns (dict) <p>Dictionary containing response metadata including 'Metadata' key with user metadata</p> method &lt;/&gt; <p>Set object metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> <li><code>metadata</code> (dict) \u2014 Dictionary of metadata key-value pairs</li> </ul> method &lt;/&gt; <p>Check if object is a symlink (has symlink-target metadata).</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> Returns (str) <p>Symlink target path</p> method &lt;/&gt; <p>Create symlink by storing target in metadata.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path for the symlink</li> <li><code>target</code> (str) \u2014 Target path the symlink should point to</li> </ul> generator &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base S3 path</li> <li><code>pattern</code> (str) \u2014 Glob pattern (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (Iterator) <p>List of matching paths (as PanPath objects or strings)</p> generator &lt;/&gt; <p>Walk directory tree.</p> Parameters <ul> <li><code>path</code> (str) \u2014 Base S3 path</li> </ul> Returns (Iterator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source S3 path</li> <li><code>target</code> (str) \u2014 Target S3 path</li> </ul> method &lt;/&gt; <p>Remove directory marker.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>path</code> (str) \u2014 S3 path</li> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source S3 path</li> <li><code>target</code> (str) \u2014 Target S3 path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> method &lt;/&gt; <p>Copy directory tree to target recursively.</p> Parameters <ul> <li><code>source</code> (str) \u2014 Source S3 path</li> <li><code>target</code> (str) \u2014 Target S3 path</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> class &lt;/&gt; Bases panpath.clients.SyncFileHandle <p>Sync file handle for S3 with chunked streaming support.</p><p>Uses boto3's streaming API for efficient reading of large files.</p> Attributes <ul> <li><code>closed</code> (bool) \u2014 Check if file is closed.&lt;/&gt;</li> </ul> Methods <ul> <li><code>__enter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Enter context manager.&lt;/&gt;</li> <li><code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code> \u2014 Exit async context manager.&lt;/&gt;</li> <li><code>__iter__</code><code>(</code><code>)</code> (SyncFileHandle) \u2014 Support async iteration over lines.&lt;/&gt;</li> <li><code>__next__</code><code>(</code><code>)</code> (Union) \u2014 Get next line in async iteration.&lt;/&gt;</li> <li><code>close</code><code>(</code><code>)</code> \u2014 Close the file and flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>flush</code><code>(</code><code>)</code> \u2014 Flush write buffer to cloud storage.&lt;/&gt;</li> <li><code>read</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return up to size bytes/characters.&lt;/&gt;</li> <li><code>readline</code><code>(</code><code>size</code><code>)</code> (Union) \u2014 Read and return one line from the file.&lt;/&gt;</li> <li><code>readlines</code><code>(</code><code>)</code> (List) \u2014 Read and return all lines from the file.&lt;/&gt;</li> <li><code>reset_stream</code><code>(</code><code>)</code> \u2014 Reset the underlying stream to the beginning.&lt;/&gt;</li> <li><code>seek</code><code>(</code><code>offset</code>, <code>whence</code><code>)</code> (int) \u2014 Change stream position (forward seeking only).&lt;/&gt;</li> <li><code>tell</code><code>(</code><code>)</code> (int) \u2014 Return current stream position.&lt;/&gt;</li> <li><code>write</code><code>(</code><code>data</code><code>)</code> (int) \u2014 Write data to the file.&lt;/&gt;</li> <li><code>writelines</code><code>(</code><code>lines</code><code>)</code> \u2014 Write a list of lines to the file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Flush write buffer to cloud storage.</p><p>After open, all flushes append to existing content using provider-native append operations. The difference between 'w' and 'a' modes is that 'w' clears existing content on open, while 'a' preserves it.</p> method &lt;/&gt; <p>Reset the underlying stream to the beginning.</p> method &lt;/&gt; <p>Enter context manager.</p> method &lt;/&gt; <p>Exit async context manager.</p> method &lt;/&gt; <p>Read and return up to size bytes/characters.</p> Parameters <ul> <li><code>size</code> (int, optional) \u2014 Number of bytes/chars to read (-1 for all)</li> </ul> Returns (Union) <p>Data read from file</p> method &lt;/&gt; <p>Read and return one line from the file.</p> method &lt;/&gt; <p>Read and return all lines from the file.</p> method &lt;/&gt; <p>Write data to the file.</p> method &lt;/&gt; <p>Write a list of lines to the file.</p> method &lt;/&gt; <p>Close the file and flush write buffer to cloud storage.</p> method &lt;/&gt; <p>Support async iteration over lines.</p> method &lt;/&gt; <p>Get next line in async iteration.</p> method &lt;/&gt; <p>Return current stream position.</p> Returns (int) <p>Current position in the file</p> method &lt;/&gt; <p>Change stream position (forward seeking only).</p> Parameters <ul> <li><code>offset</code> (int) \u2014 Position offset</li> <li><code>whence</code> (int, optional) \u2014 Reference point (0=start, 1=current, 2=end)</li> </ul> Returns (int) <p>New absolute position</p> Raises <ul> <li><code>OSError</code> \u2014 If backward seeking is attempted</li> <li><code>ValueError</code> \u2014 If called in write mode or on closed file</li> </ul> <p>Note</p> <ul> <li>Only forward seeking is supported due to streaming limitations</li> <li>SEEK_END (whence=2) is not supported as blob size may be unknown</li> <li>Backward seeking requires re-opening the stream</li> </ul>"},{"location":"api/panpath.s3_client/#panpaths3_client","title":"panpath.s3_client","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3client","title":"<code>panpath.s3_client.</code><code>S3Client</code><code>(</code><code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncclientread_text","title":"<code>read_text</code><code>(</code><code>path</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncclientwrite_text","title":"<code>write_text</code><code>(</code><code>path</code>, <code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientexists","title":"<code>exists</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientread_bytes","title":"<code>read_bytes</code><code>(</code><code>path</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>path</code>, <code>data</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientdelete","title":"<code>delete</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientlist_dir","title":"<code>list_dir</code><code>(</code><code>path</code><code>)</code> \u2192 list","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientis_dir","title":"<code>is_dir</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientis_file","title":"<code>is_file</code><code>(</code><code>path</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientstat","title":"<code>stat</code><code>(</code><code>path</code><code>)</code> \u2192 stat_result","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientopen","title":"<code>open</code><code>(</code><code>path</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientmkdir","title":"<code>mkdir</code><code>(</code><code>path</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientget_metadata","title":"<code>get_metadata</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientset_metadata","title":"<code>set_metadata</code><code>(</code><code>path</code>, <code>metadata</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientis_symlink","title":"<code>is_symlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientreadlink","title":"<code>readlink</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientsymlink_to","title":"<code>symlink_to</code><code>(</code><code>path</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientglob","title":"<code>glob</code><code>(</code><code>path</code>, <code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientwalk","title":"<code>walk</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clienttouch","title":"<code>touch</code><code>(</code><code>path</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientrename","title":"<code>rename</code><code>(</code><code>source</code>, <code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientrmdir","title":"<code>rmdir</code><code>(</code><code>path</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientrmtree","title":"<code>rmtree</code><code>(</code><code>path</code>, <code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientcopy","title":"<code>copy</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3clientcopytree","title":"<code>copytree</code><code>(</code><code>source</code>, <code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpaths3_clients3syncfilehandle","title":"<code>panpath.s3_client.</code><code>S3SyncFileHandle</code><code>(</code><code>client</code>, <code>bucket</code>, <code>blob</code>, <code>prefix</code>, <code>mode='r'</code>, <code>encoding=None</code>, <code>chunk_size=4096</code>, <code>upload_warning_threshold=100</code>, <code>upload_interval=1.0</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandleflush","title":"<code>flush</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandlereset_stream","title":"<code>reset_stream</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandleenter","title":"<code>__enter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandleexit","title":"<code>__exit__</code><code>(</code><code>exc_type</code>, <code>exc_val</code>, <code>exc_tb</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandleread","title":"<code>read</code><code>(</code><code>size=-1</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandlereadline","title":"<code>readline</code><code>(</code><code>size=-1</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandlereadlines","title":"<code>readlines</code><code>(</code><code>)</code> \u2192 List","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandlewrite","title":"<code>write</code><code>(</code><code>data</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandlewritelines","title":"<code>writelines</code><code>(</code><code>lines</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandleclose","title":"<code>close</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandleiter","title":"<code>__iter__</code><code>(</code><code>)</code> \u2192 SyncFileHandle","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandlenext","title":"<code>__next__</code><code>(</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandletell","title":"<code>tell</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_client/#panpathclientssyncfilehandleseek","title":"<code>seek</code><code>(</code><code>offset</code>, <code>whence=0</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/","title":"panpath.s3_path","text":"module &lt;/&gt; <p>S3 path implementation.</p> Classes <ul> <li><code>S3Path</code> (CloudPath) \u2014 S3 path implementation (sync and async methods).&lt;/&gt;</li> </ul> class &lt;/&gt; Bases panpath.cloud.CloudPath panpath.base.PanPath pathlib.Path pathlib.PurePosixPath pathlib.PurePath <p>S3 path implementation (sync and async methods).</p> Attributes <ul> <li><code>anchor</code> \u2014 The concatenation of the drive and root, or ''.&lt;/&gt;</li> <li><code>async_client</code> (AsyncClient) \u2014 Get or create the async client for this path.&lt;/&gt;</li> <li><code>client</code> (SyncClient) \u2014 Get or create the sync client for this path.&lt;/&gt;</li> <li><code>cloud_prefix</code> (str) \u2014 Return the cloud prefix (e.g., 's3://bucket').&lt;/&gt;</li> <li><code>drive</code> \u2014 The drive prefix (letter or UNC path), if any.&lt;/&gt;</li> <li><code>key</code> (str) \u2014 Return the key/blob name without the cloud prefix.&lt;/&gt;</li> <li><code>name</code> \u2014 The final path component, if any.&lt;/&gt;</li> <li><code>parent</code> (CloudPath) \u2014 Return parent directory as same path type.&lt;/&gt;</li> <li><code>parents</code> \u2014 A sequence of this path's logical parents.&lt;/&gt;</li> <li><code>parts</code> \u2014 An object providing sequence-like access to thecomponents in the filesystem path. &lt;/&gt;</li> <li><code>root</code> \u2014 The root of the path, if any.&lt;/&gt;</li> <li><code>stem</code> \u2014 The final path component, minus its last suffix.&lt;/&gt;</li> <li><code>suffix</code> \u2014 The final component's last suffix, if any.This includes the leading period. For example: '.txt' &lt;/&gt;</li> <li><code>suffixes</code> \u2014 A list of the final component's suffixes, if any.These include the leading periods. For example: ['.tar', '.gz'] &lt;/&gt;</li> </ul> Methods <ul> <li><code>__bytes__</code><code>(</code><code>)</code> \u2014 Return the bytes representation of the path.  This is onlyrecommended to use under Unix. &lt;/&gt;</li> <li><code>__eq__</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check equality.&lt;/&gt;</li> <li><code>__hash__</code><code>(</code><code>)</code> (int) \u2014 Return hash of path.&lt;/&gt;</li> <li><code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> (CloudPath) \u2014 Create new cloud path instance.&lt;/&gt;</li> <li><code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Right join paths while preserving type and client.&lt;/&gt;</li> <li><code>__str__</code><code>(</code><code>)</code> (str) \u2014 Return properly formatted cloud URI with double slash.&lt;/&gt;</li> <li><code>__truediv__</code><code>(</code><code>other</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (PanPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>a_exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>a_glob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>a_is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>a_is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>a_is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>a_iterdir</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 List directory contents (async version returns list).&lt;/&gt;</li> <li><code>a_mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>a_open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (AsyncFileHandle) \u2014 Open file and return async file handle.&lt;/&gt;</li> <li><code>a_read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>a_read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>a_readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>a_rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>a_replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>a_resolve</code><code>(</code><code>)</code> (PanPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>a_rglob</code><code>(</code><code>pattern</code><code>)</code> (AsyncGenerator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>a_rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>a_rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>a_stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>a_touch</code><code>(</code><code>mode</code>, <code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>a_unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>a_walk</code><code>(</code><code>)</code> (AsyncGenerator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>a_write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>a_write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> (int) \u2014 Write text to file.&lt;/&gt;</li> <li><code>absolute</code><code>(</code><code>)</code> (CloudPath) \u2014 Return absolute path - cloud paths are already absolute.&lt;/&gt;</li> <li><code>as_posix</code><code>(</code><code>)</code> \u2014 Return the string representation of the path with forward (/)slashes. &lt;/&gt;</li> <li><code>as_uri</code><code>(</code><code>)</code> (str) \u2014 Return the path as a URI (same as string representation).&lt;/&gt;</li> <li><code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks</code><code>)</code> \u2014 Change the permissions of the path, like os.chmod().&lt;/&gt;</li> <li><code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy file to target.&lt;/&gt;</li> <li><code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks</code><code>)</code> (CloudPath) \u2014 Copy directory tree to target recursively.&lt;/&gt;</li> <li><code>cwd</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the current working directory.&lt;/&gt;</li> <li><code>exists</code><code>(</code><code>)</code> (bool) \u2014 Check if path exists.&lt;/&gt;</li> <li><code>expanduser</code><code>(</code><code>)</code> \u2014 Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser) &lt;/&gt;</li> <li><code>glob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Glob for files matching pattern.&lt;/&gt;</li> <li><code>group</code><code>(</code><code>)</code> \u2014 Return the group name of the file gid.&lt;/&gt;</li> <li><code>hardlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Make this path a hard link pointing to the same file as target.&lt;/&gt;</li> <li><code>home</code><code>(</code><code>)</code> \u2014 Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')). &lt;/&gt;</li> <li><code>is_absolute</code><code>(</code><code>)</code> (bool) \u2014 Cloud paths are always absolute.&lt;/&gt;</li> <li><code>is_block_device</code><code>(</code><code>)</code> \u2014 Whether this path is a block device.&lt;/&gt;</li> <li><code>is_char_device</code><code>(</code><code>)</code> \u2014 Whether this path is a character device.&lt;/&gt;</li> <li><code>is_dir</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a directory.&lt;/&gt;</li> <li><code>is_fifo</code><code>(</code><code>)</code> \u2014 Whether this path is a FIFO.&lt;/&gt;</li> <li><code>is_file</code><code>(</code><code>)</code> (bool) \u2014 Check if path is a file.&lt;/&gt;</li> <li><code>is_junction</code><code>(</code><code>)</code> \u2014 Whether this path is a junction.&lt;/&gt;</li> <li><code>is_mount</code><code>(</code><code>)</code> \u2014 Check if this path is a mount point&lt;/&gt;</li> <li><code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code> \u2014 Return True if the path is relative to another path or False.&lt;/&gt;</li> <li><code>is_reserved</code><code>(</code><code>)</code> \u2014 Return True if the path contains one of the special names reservedby the system, if any. &lt;/&gt;</li> <li><code>is_socket</code><code>(</code><code>)</code> \u2014 Whether this path is a socket.&lt;/&gt;</li> <li><code>is_symlink</code><code>(</code><code>)</code> (bool) \u2014 Check if this is a symbolic link (via metadata).&lt;/&gt;</li> <li><code>iterdir</code><code>(</code><code>)</code> (CloudPath) \u2014 Iterate over directory contents.&lt;/&gt;</li> <li><code>joinpath</code><code>(</code><code>*args</code><code>)</code> (CloudPath) \u2014 Join paths while preserving type and client.&lt;/&gt;</li> <li><code>lchmod</code><code>(</code><code>mode</code><code>)</code> \u2014 Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's. &lt;/&gt;</li> <li><code>lstat</code><code>(</code><code>)</code> \u2014 Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's. &lt;/&gt;</li> <li><code>match</code><code>(</code><code>pattern</code><code>)</code> (bool) \u2014 Match path against glob pattern.&lt;/&gt;</li> <li><code>mkdir</code><code>(</code><code>mode</code>, <code>parents</code>, <code>exist_ok</code><code>)</code> \u2014 Create a directory marker in cloud storage.&lt;/&gt;</li> <li><code>open</code><code>(</code><code>mode</code>, <code>encoding</code>, <code>**kwargs</code><code>)</code> (Union) \u2014 Open file for reading/writing.&lt;/&gt;</li> <li><code>owner</code><code>(</code><code>)</code> \u2014 Return the login name of the file owner.&lt;/&gt;</li> <li><code>read_bytes</code><code>(</code><code>)</code> (bytes) \u2014 Read file as bytes.&lt;/&gt;</li> <li><code>read_text</code><code>(</code><code>encoding</code><code>)</code> (str) \u2014 Read file as text.&lt;/&gt;</li> <li><code>readlink</code><code>(</code><code>)</code> (CloudPath) \u2014 Read symlink target from metadata.&lt;/&gt;</li> <li><code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up</code><code>)</code> \u2014 Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError. &lt;/&gt;</li> <li><code>rename</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Rename/move file to target.&lt;/&gt;</li> <li><code>replace</code><code>(</code><code>target</code><code>)</code> (CloudPath) \u2014 Replace file at target (overwriting if exists).&lt;/&gt;</li> <li><code>resolve</code><code>(</code><code>)</code> (CloudPath) \u2014 Resolve to absolute path (no-op for cloud paths).&lt;/&gt;</li> <li><code>rglob</code><code>(</code><code>pattern</code><code>)</code> (Iterator) \u2014 Recursively glob for files matching pattern.&lt;/&gt;</li> <li><code>rmdir</code><code>(</code><code>)</code> \u2014 Remove empty directory marker.&lt;/&gt;</li> <li><code>rmtree</code><code>(</code><code>ignore_errors</code>, <code>onerror</code><code>)</code> \u2014 Remove directory and all its contents recursively.&lt;/&gt;</li> <li><code>samefile</code><code>(</code><code>other</code><code>)</code> (bool) \u2014 Check if this path refers to same file as other.&lt;/&gt;</li> <li><code>stat</code><code>(</code><code>follow_symlinks</code><code>)</code> (Any) \u2014 Get file stats.&lt;/&gt;</li> <li><code>symlink_to</code><code>(</code><code>target</code><code>)</code> \u2014 Create symlink pointing to target (via metadata).&lt;/&gt;</li> <li><code>touch</code><code>(</code><code>exist_ok</code><code>)</code> \u2014 Create empty file.&lt;/&gt;</li> <li><code>unlink</code><code>(</code><code>missing_ok</code><code>)</code> \u2014 Delete file.&lt;/&gt;</li> <li><code>walk</code><code>(</code><code>)</code> (Iterator) \u2014 Walk directory tree (like os.walk).&lt;/&gt;</li> <li><code>with_name</code><code>(</code><code>name</code><code>)</code> \u2014 Return a new path with the file name changed.&lt;/&gt;</li> <li><code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code> \u2014 Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>. &lt;/&gt;</li> <li><code>with_stem</code><code>(</code><code>stem</code><code>)</code> \u2014 Return a new path with the stem changed.&lt;/&gt;</li> <li><code>with_suffix</code><code>(</code><code>suffix</code><code>)</code> \u2014 Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path. &lt;/&gt;</li> <li><code>write_bytes</code><code>(</code><code>data</code><code>)</code> \u2014 Write bytes to file.&lt;/&gt;</li> <li><code>write_text</code><code>(</code><code>data</code>, <code>encoding</code><code>)</code> \u2014 Write text to file.&lt;/&gt;</li> </ul> method &lt;/&gt; <p>Construct a new path object from any number of path-like objects.Subclasses may override this method to customize how new path objects are created from methods like <code>iterdir()</code>.</p> method &lt;/&gt; <p>Return the string representation of the path with forward (/)slashes.</p> method &lt;/&gt; <p>Return the bytes representation of the path.  This is onlyrecommended to use under Unix.</p> method &lt;/&gt; <p>Return a new path with the file name changed.</p> method &lt;/&gt; <p>Return a new path with the stem changed.</p> method &lt;/&gt; <p>Return a new path with the file suffix changed.  If the pathhas no suffix, add given suffix.  If the given suffix is an empty string, remove the suffix from the path.</p> method &lt;/&gt; <p>Return the relative path to another path identified by the passedarguments.  If the operation is not possible (because this is not related to the other path), raise ValueError.</p> <p>The walk_up parameter controls whether <code>..</code> may be used to resolve the path.</p> method &lt;/&gt; <p>Return True if the path is relative to another path or False.</p> method &lt;/&gt; <p>Return True if the path contains one of the special names reservedby the system, if any.</p> method &lt;/&gt; <p>Like stat(), except if the path points to a symlink, the symlink'sstatus information is returned, rather than its target's.</p> method &lt;/&gt; <p>Check if this path is a mount point</p> method &lt;/&gt; <p>Whether this path is a junction.</p> method &lt;/&gt; <p>Whether this path is a block device.</p> method &lt;/&gt; <p>Whether this path is a character device.</p> method &lt;/&gt; <p>Whether this path is a FIFO.</p> method &lt;/&gt; <p>Whether this path is a socket.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the current working directory.</p> classmethod &lt;/&gt; <p>Return a new path pointing to the user's home directory (asreturned by os.path.expanduser('~')).</p> method &lt;/&gt; <p>Return the login name of the file owner.</p> method &lt;/&gt; <p>Return the group name of the file gid.</p> method &lt;/&gt; <p>Change the permissions of the path, like os.chmod().</p> method &lt;/&gt; <p>Like chmod(), except if the path points to a symlink, the symlink'spermissions are changed, rather than its target's.</p> method &lt;/&gt; <p>Make this path a hard link pointing to the same file as target.</p><p>Note the order of arguments (self, target) is the reverse of os.link's.</p> method &lt;/&gt; <p>Return a new path with expanded ~ and ~user constructs(as returned by os.path.expanduser)</p> staticmethod &lt;/&gt; <p>Create new cloud path instance.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Right join paths while preserving type and client.</p> method &lt;/&gt; <p>Join paths while preserving type and client.</p> method &lt;/&gt; <p>Return properly formatted cloud URI with double slash.</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> method &lt;/&gt; <p>Write bytes to file.</p> method &lt;/&gt; <p>Write text to file.</p> method &lt;/&gt; <p>Delete file.</p> generator &lt;/&gt; <p>Iterate over directory contents.</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Open file for reading/writing.</p> method &lt;/&gt; <p>Check equality.</p> method &lt;/&gt; <p>Return hash of path.</p> method &lt;/&gt; <p>Return absolute path - cloud paths are already absolute.</p> method &lt;/&gt; <p>Cloud paths are always absolute.</p> method &lt;/&gt; <p>Return the path as a URI (same as string representation).</p> method &lt;/&gt; <p>Match path against glob pattern.</p><p>Override to work correctly with cloud URIs by matching against the key portion of the path (excluding scheme and bucket).</p> generator &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (Iterator) <p>List of matching paths</p> generator &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (Iterator) <p>List of matching paths (recursive)</p> generator &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (Iterator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (CloudPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Check if this path refers to same file as other.</p> Parameters <ul> <li><code>other</code> (Union) \u2014 Path to compare</li> </ul> Returns (bool) <p>True if paths are the same</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Check if path exists.</p> method &lt;/&gt; <p>Read file as bytes.</p> method &lt;/&gt; <p>Read file as text.</p> Parameters <ul> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Write bytes to file.</p> Parameters <ul> <li><code>data</code> (bytes) \u2014 Bytes to write to the file.</li> </ul> method &lt;/&gt; <p>Write text to file.</p> Parameters <ul> <li><code>data</code> (str) \u2014 Text to write to the file.</li> <li><code>encoding</code> (str, optional) \u2014 Text encoding to use (default: 'utf-8')</li> </ul> method &lt;/&gt; <p>Delete file.</p> Parameters <ul> <li><code>missing_ok</code> (bool, optional) \u2014 If True, does not raise an error if the file does not exist.</li> </ul> method &lt;/&gt; <p>List directory contents (async version returns list).</p> method &lt;/&gt; <p>Check if path is a directory.</p> method &lt;/&gt; <p>Check if path is a file.</p> method &lt;/&gt; <p>Get file stats.</p> method &lt;/&gt; <p>Create a directory marker in cloud storage.</p><p>In cloud storage (S3, GCS, Azure), directories are implicit. This method creates an empty object with a trailing slash to serve as a directory marker.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 Ignored (for compatibility with pathlib)</li> <li><code>parents</code> (bool, optional) \u2014 If True, create parent directories as needed</li> <li><code>exist_ok</code> (bool, optional) \u2014 If True, don't raise error if directory already exists</li> </ul> method &lt;/&gt; <p>Glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \"**/.py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths</p> method &lt;/&gt; <p>Recursively glob for files matching pattern.</p> Parameters <ul> <li><code>pattern</code> (str) \u2014 Pattern to match (e.g., \".txt\", \".py\")</li> </ul> Returns (AsyncGenerator) <p>List of matching paths (recursive)</p> method &lt;/&gt; <p>Walk directory tree (like os.walk).</p> Returns (AsyncGenerator) <p>List of (dirpath, dirnames, filenames) tuples</p> method &lt;/&gt; <p>Create empty file.</p> Parameters <ul> <li><code>mode</code> (int, optional) \u2014 File mode (permissions) to set if creating the file.</li> <li><code>exist_ok</code> (bool, optional) \u2014 If False, raise error if file exists</li> </ul> method &lt;/&gt; <p>Rename/move file to target.</p><p>Can move between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 New path (can be cloud or local)</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Replace file at target (overwriting if exists).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Target path</li> </ul> Returns (CloudPath) <p>New path instance</p> method &lt;/&gt; <p>Resolve to absolute path (no-op for cloud paths).</p> Returns (PanPath) <p>Self (cloud paths are already absolute)</p> method &lt;/&gt; <p>Remove empty directory marker.</p> method &lt;/&gt; <p>Check if this is a symbolic link (via metadata).</p> Returns (bool) <p>True if symlink metadata exists</p> method &lt;/&gt; <p>Read symlink target from metadata.</p> Returns (CloudPath) <p>Path that this symlink points to</p> method &lt;/&gt; <p>Create symlink pointing to target (via metadata).</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Path this symlink should point to (absolute with scheme or relative)</li> <li><code>target_is_directory</code> (bool, optional) \u2014 Ignored (for compatibility with pathlib)</li> </ul> method &lt;/&gt; <p>Remove directory and all its contents recursively.</p> Parameters <ul> <li><code>ignore_errors</code> (bool, optional) \u2014 If True, errors are ignored</li> <li><code>onerror</code> (Optional, optional) \u2014 Callable that accepts (function, path, excinfo)</li> </ul> method &lt;/&gt; <p>Copy file to target.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> </ul> Returns (PanPath) <p>Target path instance</p> method &lt;/&gt; <p>Copy directory tree to target recursively.</p><p>Can copy between cloud and local paths.</p> Parameters <ul> <li><code>target</code> (Union) \u2014 Destination path (can be cloud or local)</li> <li><code>follow_symlinks</code> (bool, optional) \u2014 If False, symlinks are copied as symlinks (not dereferenced)</li> </ul> Returns (CloudPath) <p>Target path instance</p> method &lt;/&gt; <p>Open file and return async file handle.</p> Parameters <ul> <li><code>mode</code> (str, optional) \u2014 File mode (e.g., 'r', 'w', 'rb', 'wb')</li> <li><code>encoding</code> (Optional, optional) \u2014 Text encoding (for text modes)</li> <li><code>**kwargs</code> (Any) \u2014 Additional arguments passed to the async client</li> </ul> Returns (AsyncFileHandle) <p>Async file handle from the async client</p>"},{"location":"api/panpath.s3_path/#panpaths3_path","title":"panpath.s3_path","text":""},{"location":"api/panpath.s3_path/#panpaths3_paths3path","title":"<code>panpath.s3_path.</code><code>S3Path</code><code>(</code><code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathwith_segments","title":"<code>with_segments</code><code>(</code><code>*pathsegments</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathas_posix","title":"<code>as_posix</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathbytes","title":"<code>__bytes__</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathwith_name","title":"<code>with_name</code><code>(</code><code>name</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathwith_stem","title":"<code>with_stem</code><code>(</code><code>stem</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathwith_suffix","title":"<code>with_suffix</code><code>(</code><code>suffix</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathrelative_to","title":"<code>relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code>, <code>walk_up=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathis_relative_to","title":"<code>is_relative_to</code><code>(</code><code>other</code>, <code>*_deprecated</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpurepathis_reserved","title":"<code>is_reserved</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathlstat","title":"<code>lstat</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathis_mount","title":"<code>is_mount</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathis_junction","title":"<code>is_junction</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathis_block_device","title":"<code>is_block_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathis_char_device","title":"<code>is_char_device</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathis_fifo","title":"<code>is_fifo</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathis_socket","title":"<code>is_socket</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathcwd","title":"<code>cwd</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathhome","title":"<code>home</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathowner","title":"<code>owner</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathgroup","title":"<code>group</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathchmod","title":"<code>chmod</code><code>(</code><code>mode</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathlchmod","title":"<code>lchmod</code><code>(</code><code>mode</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathhardlink_to","title":"<code>hardlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#pathlibpathexpanduser","title":"<code>expanduser</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathnew","title":"<code>__new__</code><code>(</code><code>cls</code>, <code>*args</code>, <code>**kwargs</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathtruediv","title":"<code>__truediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathrtruediv","title":"<code>__rtruediv__</code><code>(</code><code>other</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathjoinpath","title":"<code>joinpath</code><code>(</code><code>*args</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathstr","title":"<code>__str__</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathexists","title":"<code>exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathread_bytes","title":"<code>read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathread_text","title":"<code>read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathwrite_bytes","title":"<code>write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathwrite_text","title":"<code>write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathunlink","title":"<code>unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathiterdir","title":"<code>iterdir</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathis_dir","title":"<code>is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathis_file","title":"<code>is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathstat","title":"<code>stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathmkdir","title":"<code>mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathopen","title":"<code>open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code> \u2192 Union","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatheq","title":"<code>__eq__</code><code>(</code><code>other</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathhash","title":"<code>__hash__</code><code>(</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathabsolute","title":"<code>absolute</code><code>(</code><code>)</code> \u2192 CloudPath","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathis_absolute","title":"<code>is_absolute</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathas_uri","title":"<code>as_uri</code><code>(</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathmatch","title":"<code>match</code><code>(</code><code>pattern</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathglob","title":"<code>glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathrglob","title":"<code>rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathwalk","title":"<code>walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathtouch","title":"<code>touch</code><code>(</code><code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathrename","title":"<code>rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathreplace","title":"<code>replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathrmdir","title":"<code>rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathresolve","title":"<code>resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathsamefile","title":"<code>samefile</code><code>(</code><code>other</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathis_symlink","title":"<code>is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathreadlink","title":"<code>readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathsymlink_to","title":"<code>symlink_to</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathrmtree","title":"<code>rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathcopy","title":"<code>copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpathcopytree","title":"<code>copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_exists","title":"<code>a_exists</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_read_bytes","title":"<code>a_read_bytes</code><code>(</code><code>)</code> \u2192 bytes","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_read_text","title":"<code>a_read_text</code><code>(</code><code>encoding='utf-8'</code><code>)</code> \u2192 str","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_write_bytes","title":"<code>a_write_bytes</code><code>(</code><code>data</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_write_text","title":"<code>a_write_text</code><code>(</code><code>data</code>, <code>encoding='utf-8'</code><code>)</code> \u2192 int","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_unlink","title":"<code>a_unlink</code><code>(</code><code>missing_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_iterdir","title":"<code>a_iterdir</code><code>(</code><code>)</code> \u2192 AsyncGenerator","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_is_dir","title":"<code>a_is_dir</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_is_file","title":"<code>a_is_file</code><code>(</code><code>)</code> \u2192 bool","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_stat","title":"<code>a_stat</code><code>(</code><code>follow_symlinks=True</code><code>)</code> \u2192 Any","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_mkdir","title":"<code>a_mkdir</code><code>(</code><code>mode=511</code>, <code>parents=False</code>, <code>exist_ok=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_glob","title":"<code>a_glob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_rglob","title":"<code>a_rglob</code><code>(</code><code>pattern</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_walk","title":"<code>a_walk</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_touch","title":"<code>a_touch</code><code>(</code><code>mode=438</code>, <code>exist_ok=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_rename","title":"<code>a_rename</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_replace","title":"<code>a_replace</code><code>(</code><code>target</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_resolve","title":"<code>a_resolve</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_rmdir","title":"<code>a_rmdir</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_is_symlink","title":"<code>a_is_symlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_readlink","title":"<code>a_readlink</code><code>(</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_symlink_to","title":"<code>a_symlink_to</code><code>(</code><code>target</code>, <code>target_is_directory=False</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_rmtree","title":"<code>a_rmtree</code><code>(</code><code>ignore_errors=False</code>, <code>onerror=None</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_copy","title":"<code>a_copy</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_copytree","title":"<code>a_copytree</code><code>(</code><code>target</code>, <code>follow_symlinks=True</code><code>)</code>","text":""},{"location":"api/panpath.s3_path/#panpathcloudcloudpatha_open","title":"<code>a_open</code><code>(</code><code>mode='r'</code>, <code>encoding=None</code>, <code>**kwargs</code><code>)</code>","text":""},{"location":"api/source/panpath.azure_async_client/","title":"panpath.azure_async_client","text":""},{"location":"api/source/panpath.azure_async_client/","title":"SOURCE CODE panpath.azure_async_client DOCS","text":"<pre><code>\"\"\"Async Azure Blob Storage client implementation.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, Optional, Set, Union, AsyncGenerator\n\nimport asyncio\nimport os\nimport weakref\nfrom panpath.clients import AsyncClient, AsyncFileHandle\nfrom panpath.exceptions import MissingDependencyError, NoStatError\n\nif TYPE_CHECKING:\n    from azure.storage.blob.aio import BlobServiceClient  # type: ignore[import-not-found]\n    from azure.core.exceptions import ResourceNotFoundError  # type: ignore[import-not-found]\n\ntry:\n    from azure.storage.blob.aio import BlobServiceClient\n    from azure.core.exceptions import ResourceNotFoundError\n\n    HAS_AZURE_AIO = True\nexcept ImportError:\n    HAS_AZURE_AIO = False\n    ResourceNotFoundError = Exception\n\n\n# Track all active client instances for cleanup\n_active_clients: Set[weakref.ref] = set()  # type: ignore[type-arg]\n\n\nasync def _async_cleanup_all_clients() -&gt; None:\n    \"\"\"Async cleanup of all active client instances.\"\"\"\n    # Create a copy of the set to avoid modification during iteration\n    clients_to_clean = list(_active_clients)\n\n    for client_ref in clients_to_clean:\n        client = client_ref()\n        if client is None:  # pragma: no cover\n            continue\n\n        try:\n            await client.close()\n        except Exception:  # pragma: no cover\n            # Ignore errors during cleanup\n            pass\n\n    _active_clients.clear()\n\n\ndef _register_loop_cleanup(loop: asyncio.AbstractEventLoop) -&gt; None:\n    \"\"\"Register cleanup to run before loop closes.\"\"\"\n    # Get the original shutdown_asyncgens method\n    original_shutdown = loop.shutdown_asyncgens\n\n    async def shutdown_with_cleanup():  # type: ignore[no-untyped-def]\n        \"\"\"Shutdown that includes client cleanup.\"\"\"\n        # Clean up clients first\n        await _async_cleanup_all_clients()\n        # Then run original shutdown\n        await original_shutdown()\n\n    # Replace with our version\n    loop.shutdown_asyncgens = shutdown_with_cleanup  # type: ignore[method-assign]\n\n\nclass AsyncAzureBlobClient(AsyncClient):DOCS\n    \"\"\"Asynchronous Azure Blob Storage client implementation.\"\"\"\n\n    prefix = (\"azure\", \"az\")\n\n    def __init__(self, connection_string: Optional[str] = None, **kwargs: Any):\n        \"\"\"Initialize async Azure Blob client.\n\n        Args:\n            connection_string: Azure storage connection string\n            **kwargs: Additional arguments\n        \"\"\"\n        if not HAS_AZURE_AIO:\n            raise MissingDependencyError(\n                backend=\"async Azure Blob Storage\",\n                package=\"azure-storage-blob[aio]\",\n                extra=\"async-azure\",\n            )\n        if not connection_string and \"AZURE_STORAGE_CONNECTION_STRING\" in os.environ:\n            connection_string = os.environ[\"AZURE_STORAGE_CONNECTION_STRING\"]\n        self._client: Optional[BlobServiceClient] = None\n        self._connection_string = connection_string\n        self._kwargs = kwargs\n        self._client_ref: Optional[weakref.ref] = None  # type: ignore[type-arg]\n\n    async def _get_client(self) -&gt; BlobServiceClient:\n        \"\"\"Get or create shared BlobServiceClient.\"\"\"\n        # Check if client needs to be recreated (closed or never created)\n        needs_recreation = False\n        if self._client is None:\n            needs_recreation = True\n        else:\n            # Check if the underlying aiohttp session is closed\n            try:\n                # Azure BlobServiceClient uses aiohttp internally\n                # Check if the transport/session is closed\n                if (\n                    self._client._client._client._pipeline._transport._has_been_opened\n                    and not self._client._client._client._pipeline._transport.session\n                ):\n                    needs_recreation = True\n                    # Clean up the old client reference\n                    if self._client_ref is not None:\n                        _active_clients.discard(self._client_ref)\n                        self._client_ref = None\n                    self._client = None\n            except (AttributeError, RuntimeError):  # pragma: no cover\n                needs_recreation = True\n                self._client = None\n\n        if needs_recreation:\n            if self._connection_string:\n                self._client = BlobServiceClient.from_connection_string(\n                    self._connection_string, **self._kwargs\n                )\n            else:  # pragma: no cover\n                self._client = BlobServiceClient(**self._kwargs)\n\n            # Track this client instance for cleanup\n            self._client_ref = weakref.ref(self._client, self._on_client_deleted)\n            _active_clients.add(self._client_ref)\n\n            # Register cleanup with the current event loop\n            try:\n                loop = asyncio.get_running_loop()\n                # Check if we've already patched this loop\n                if not hasattr(loop, \"_panpath_az_cleanup_registered\"):\n                    _register_loop_cleanup(loop)\n                    loop._panpath_az_cleanup_registered = True  # type: ignore\n            except RuntimeError:  # pragma: no cover\n                # No running loop, cleanup will be handled by explicit close\n                pass\n\n        return self._client\n\n    def _on_client_deleted(self, ref: \"weakref.ref[Any]\") -&gt; None:  # pragma: no cover\n        \"\"\"Called when client is garbage collected.\"\"\"\n        _active_clients.discard(ref)\n\n    async def close(self) -&gt; None:DOCS\n        \"\"\"Close the client and cleanup resources.\"\"\"\n        if self._client is not None:\n            # Remove from active clients\n            if self._client_ref is not None:\n                _active_clients.discard(self._client_ref)\n            # Close the client\n            await self._client.close()\n            self._client = None\n\n    async def exists(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if Azure blob exists.\"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            try:\n                container_client = client.get_container_client(container_name)\n                return await container_client.exists()  # type: ignore[no-any-return]\n            except Exception:  # pragma: no cover\n                return False\n\n        try:\n            blob_client = client.get_blob_client(container_name, blob_name)\n            exists = await blob_client.exists()\n            if exists:\n                return True\n            if blob_name.endswith(\"/\"):\n                # Already checking as directory\n                return False\n            # Checking if it is possibly a directory\n            blob_client_dir = client.get_blob_client(container_name, blob_name + \"/\")\n            return await blob_client_dir.exists()  # type: ignore[no-any-return]\n        except Exception:  # pragma: no cover\n            return False\n\n    async def read_bytes(self, path: str) -&gt; bytes:DOCS\n        \"\"\"Read Azure blob as bytes.\"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n\n        try:\n            download_stream = await blob_client.download_blob()\n            return await download_stream.readall()  # type: ignore[no-any-return]\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n\n    async def write_bytes(  # type: ignore[override]DOCS\n        self,\n        path: str,\n        data: bytes,\n    ) -&gt; None:\n        \"\"\"Write bytes to Azure blob.\"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n        await blob_client.upload_blob(data, overwrite=True)\n\n    async def delete(self, path: str) -&gt; None:DOCS\n        \"\"\"Delete Azure blob.\"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n\n        if await self.is_dir(path):\n            raise IsADirectoryError(f\"Path is a directory: {path}\")\n\n        try:\n            await blob_client.delete_blob()\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n\n    async def list_dir(self, path: str) -&gt; list[str]:DOCS\n        \"\"\"List Azure blobs with prefix.\"\"\"\n        client = await self._get_client()\n        container_name, prefix = self.__class__._parse_path(path)\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        container_client = client.get_container_client(container_name)\n        results = []\n\n        async for item in container_client.walk_blobs(name_starts_with=prefix, delimiter=\"/\"):\n            if hasattr(item, \"name\"):\n                # BlobProperties (file)\n                if item.name != prefix:\n                    results.append(f\"{self.prefix[0]}://{container_name}/{item.name}\")\n            else:  # pragma: no cover\n                # BlobPrefix (directory)\n                results.append(f\"{self.prefix[0]}://{container_name}/{item.prefix.rstrip('/')}\")\n\n        return results\n\n    async def is_dir(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if Azure path is a directory.\"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            return True\n\n        prefix = blob_name if blob_name.endswith(\"/\") else blob_name + \"/\"\n        container_client = client.get_container_client(container_name)\n\n        async for _ in container_client.list_blobs(name_starts_with=prefix, timeout=5):\n            return True\n        return False\n\n    async def is_file(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if Azure path is a file.\"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            return False\n\n        blob_client = client.get_blob_client(container_name, blob_name.rstrip(\"/\"))\n        return await blob_client.exists()  # type: ignore[no-any-return]\n\n    async def stat(self, path: str) -&gt; os.stat_result:DOCS\n        \"\"\"Get Azure blob metadata.\"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n\n        try:\n            props = await blob_client.get_blob_properties()\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n        except Exception:  # pragma: no cover\n            raise NoStatError(f\"Cannot retrieve stat for: {path}\")\n        else:\n            return os.stat_result(\n                (  # type: ignore[arg-type]\n                    None,  # mode\n                    None,  # ino\n                    f\"{self.prefix[0]}://\",  # dev,\n                    None,  # nlink,\n                    None,  # uid,\n                    None,  # gid,\n                    props.size,  # size,\n                    # atime\n                    props.last_modified,\n                    # mtime\n                    props.last_modified,\n                    # ctime\n                    props.creation_time,\n                )\n            )\n\n    def open(DOCS\n        self,\n        path: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Open Azure blob for reading/writing.\n\n        Note: For better streaming support, use a_open() instead.\n        This method returns a file-like object that supports the standard file API.\n\n        Args:\n            path: Azure path\n            mode: File mode\n            encoding: Text encoding\n            **kwargs: Additional arguments (chunk_size, upload_warning_threshold,\n                upload_interval supported)\n        \"\"\"\n        if mode not in (\"r\", \"rb\", \"w\", \"wb\", \"a\", \"ab\"):\n            raise ValueError(f\"Unsupported mode '{mode}'. Use 'r', 'rb', 'w', 'wb', 'a', or 'ab'.\")\n\n        container_name, blob_name = self.__class__._parse_path(path)\n        return AzureAsyncFileHandle(  # type: ignore[no-untyped-call]\n            client_factory=self._get_client,\n            bucket=container_name,\n            blob=blob_name,\n            prefix=self.prefix[0],\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )\n\n    async def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Create a directory marker (empty blob with trailing slash).\n\n        Args:\n            path: Azure path (az://container/path or azure://container/path)\n            parents: If True, create parent directories as needed (ignored for Azure)\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure blob_name ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        blob_client = client.get_blob_client(container_name, blob_name)\n\n        # Check if it already exists\n        if await blob_client.exists():\n            if not exist_ok:\n                raise FileExistsError(f\"Directory already exists: {path}\")\n            return\n\n        # check parents\n        if blob_name:  # not container root\n            stripped_blob = blob_name.rstrip(\"/\")\n            parts = stripped_blob.rsplit(\"/\", 1)\n            if len(parts) &gt; 1:  # Has a parent directory\n                parent_path = parts[0]\n                parent_blob_client = client.get_blob_client(container_name, parent_path + \"/\")\n                if not await parent_blob_client.exists():\n                    if not parents:\n                        raise FileNotFoundError(f\"Parent directory does not exist: {path}\")\n                    # Create parent directories recursively\n                    await self.mkdir(\n                        f\"{self.prefix[0]}://{container_name}/{parent_path}\",\n                        parents=True,\n                        exist_ok=True,\n                    )\n\n        # Create empty directory marker\n        await blob_client.upload_blob(b\"\", overwrite=False)\n\n    async def get_metadata(self, path: str) -&gt; dict[str, str]:DOCS\n        \"\"\"Get blob metadata.\n\n        Args:\n            path: Azure path\n\n        Returns:\n            Dictionary of metadata key-value pairs\n        \"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n\n        try:\n            return await blob_client.get_blob_properties()  # type: ignore[no-any-return]\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n\n    async def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:DOCS\n        \"\"\"Set blob metadata.\n\n        Args:\n            path: Azure path\n            metadata: Dictionary of metadata key-value pairs\n        \"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n        await blob_client.set_blob_metadata(metadata)\n\n    async def symlink_to(self, path: str, target: str) -&gt; None:DOCS\n        \"\"\"Create symlink by storing target in metadata.\n\n        Args:\n            path: Azure path for the symlink\n            target: Target path the symlink should point to\n        \"\"\"\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n\n        # Create empty blob\n        await blob_client.upload_blob(b\"\", overwrite=True)\n\n        # Set symlink metadata\n        await blob_client.set_blob_metadata({self.__class__.symlink_target_metaname: target})\n\n    async def glob(  # type: ignore[override]DOCS\n        self,\n        path: str,\n        pattern: str,\n    ) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            path: Base Azure path\n            pattern: Glob pattern (e.g., \"*.txt\", \"**/*.py\")\n\n        Yields:\n            Matching paths as strings or PanPath objects\n        \"\"\"\n        from fnmatch import fnmatch\n\n        client = await self._get_client()\n        container_name, blob_prefix = self.__class__._parse_path(path)\n        container_client = client.get_container_client(container_name)\n\n        # Handle recursive patterns\n        if \"**\" in pattern:\n            # Extract the pattern part after **\n            pattern_parts = pattern.split(\"**/\")\n            if len(pattern_parts) &gt; 1:\n                file_pattern = pattern_parts[-1]\n            else:\n                file_pattern = \"*\"\n\n            async for blob in container_client.list_blobs(name_starts_with=blob_prefix):\n                if fnmatch(blob.name, f\"*{file_pattern}\"):\n                    # Determine scheme from original path\n                    scheme = \"az\" if path.startswith(f\"{self.prefix[0]}://\") else \"azure\"\n                    yield f\"{scheme}://{container_name}/{blob.name}\"\n\n        else:\n            # Non-recursive - list blobs with prefix\n            prefix_with_slash = (\n                f\"{blob_prefix}/\" if blob_prefix and not blob_prefix.endswith(\"/\") else blob_prefix\n            )\n\n            async for blob in container_client.list_blobs(name_starts_with=prefix_with_slash):\n                # Only include direct children (no additional slashes)\n                rel_name = blob.name[len(prefix_with_slash) :]\n                if \"/\" not in rel_name and fnmatch(blob.name, f\"{prefix_with_slash}{pattern}\"):\n                    scheme = \"az\" if path.startswith(f\"{self.prefix[0]}://\") else \"azure\"\n                    yield f\"{scheme}://{container_name}/{blob.name}\"\n\n    async def walk(  # type: ignore[override]DOCS\n        self,\n        path: str,\n    ) -&gt; AsyncGenerator[tuple[str, list[str], list[str]], None]:\n        \"\"\"Walk directory tree.\n\n        Args:\n            path: Base Azure path\n\n        Yields:\n            Tuples of (dirpath, dirnames, filenames)\n        \"\"\"\n\n        client = await self._get_client()\n        container_name, blob_prefix = self.__class__._parse_path(path)\n        container_client = client.get_container_client(container_name)\n\n        # List all blobs under prefix\n        prefix = blob_prefix if blob_prefix else \"\"\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        # Organize into directory structure as we stream blobs\n        dirs: dict[str, tuple[set[str], set[str]]] = {}  # dirpath -&gt; (subdirs, files)\n        async for blob in container_client.list_blobs(name_starts_with=prefix):\n            # Get relative path from prefix\n            rel_path = blob.name[len(prefix) :] if prefix else blob.name\n\n            # Split into directory and filename\n            parts = rel_path.split(\"/\")\n            if len(parts) == 1:\n                # File in root\n                if path not in dirs:\n                    dirs[path] = (set(), set())\n                if parts[0]:  # Skip empty strings\n                    dirs[path][1].add(parts[0])\n            else:\n                # File in subdirectory\n                # First, ensure root directory exists and add the first subdir to it\n                if path not in dirs:  # pragma: no cover\n                    dirs[path] = (set(), set())\n                if parts[0]:  # Add first-level subdirectory to root\n                    dirs[path][0].add(parts[0])\n\n                # Process all intermediate directories\n                for i in range(len(parts) - 1):\n                    dir_path = (\n                        f\"{path}/\" + \"/\".join(parts[: i + 1]) if path else \"/\".join(parts[: i + 1])\n                    )\n                    if dir_path not in dirs:\n                        dirs[dir_path] = (set(), set())\n\n                    # Add subdirectory if not last part\n                    if i &lt; len(parts) - 2:\n                        dirs[dir_path][0].add(parts[i + 1])\n\n                # Add file to its parent directory\n                parent_dir = f\"{path}/\" + \"/\".join(parts[:-1]) if path else \"/\".join(parts[:-1])\n                if parent_dir not in dirs:  # pragma: no cover\n                    dirs[parent_dir] = (set(), set())\n                if parts[-1]:  # Skip empty strings\n                    dirs[parent_dir][1].add(parts[-1])\n\n        # Yield each directory tuple\n        for d, (subdirs, files) in sorted(dirs.items()):\n            yield (d, sorted(subdirs), sorted(filter(None, files)))\n\n    async def touch(  # type: ignore[no-untyped-def, override]DOCS\n        self,\n        path: str,\n        mode=None,\n        exist_ok: bool = True,\n    ) -&gt; None:\n        \"\"\"Create empty file.\n\n        Args:\n            path: Azure path\n            exist_ok: If False, raise error if file exists\n        \"\"\"\n        if mode is not None:\n            raise ValueError(\"Mode setting is not supported for Azure Blob Storage.\")\n\n        if not exist_ok and await self.exists(path):\n            raise FileExistsError(f\"File already exists: {path}\")\n\n        client = await self._get_client()\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = client.get_blob_client(container_name, blob_name)\n\n        await blob_client.upload_blob(b\"\", overwrite=True)\n\n    async def rename(self, source: str, target: str) -&gt; None:DOCS\n        \"\"\"Rename/move file.\n\n        Args:\n            source: Source Azure path\n            target: Target Azure path\n        \"\"\"\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        # Copy to new location\n        client = await self._get_client()\n        src_container, src_blob = self.__class__._parse_path(source)\n        tgt_container, tgt_blob = self.__class__._parse_path(target)\n\n        src_blob_client = client.get_blob_client(src_container, src_blob)\n        tgt_blob_client = client.get_blob_client(tgt_container, tgt_blob)\n\n        # Copy blob\n        await tgt_blob_client.start_copy_from_url(src_blob_client.url)\n\n        # Delete source\n        await src_blob_client.delete_blob()\n\n    async def rmdir(self, path: str) -&gt; None:DOCS\n        \"\"\"Remove directory marker.\n\n        Args:\n            path: Azure path\n        \"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure blob_name ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        blob_client = self._client.get_blob_client(  # type: ignore[union-attr]\n            container_name,\n            blob_name,\n        )\n\n        # Check if it is empty\n        if await self.is_dir(path) and await self.list_dir(path):\n            raise OSError(f\"Directory not empty: {path}\")\n\n        try:\n            await blob_client.delete_blob()\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Directory not found: {path}\")\n\n    async def rmtree(DOCS\n        self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None\n    ) -&gt; None:\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            path: Azure path\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        if not await self.exists(path):\n            if ignore_errors:\n                return\n            else:\n                raise FileNotFoundError(f\"Path not found: {path}\")\n\n        if not await self.is_dir(path):\n            if ignore_errors:\n                return\n            else:\n                raise NotADirectoryError(f\"Path is not a directory: {path}\")\n\n        container_name, prefix = self.__class__._parse_path(path)\n\n        # Ensure prefix ends with / for directory listing\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        try:\n            client = await self._get_client()\n            container_client = client.get_container_client(container_name)\n\n            # List and delete all blobs with this prefix\n            async for blob in container_client.list_blobs(name_starts_with=prefix):\n                blob_client = client.get_blob_client(container_name, blob.name)\n                await blob_client.delete_blob()\n        except Exception:  # pragma: no cover\n            if ignore_errors:\n                return\n            if onerror is not None:\n                import sys\n\n                onerror(blob_client.delete_blob, path, sys.exc_info())\n            else:\n                raise\n\n    async def copy(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy file to target.\n\n        Args:\n            source: Source Azure path\n            target: Target Azure path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and await self.is_symlink(source):\n            source = await self.readlink(source)\n\n        if await self.is_dir(source):\n            raise IsADirectoryError(f\"Source is a directory: {source}\")\n\n        client = await self._get_client()\n        src_container_name, src_blob_name = self.__class__._parse_path(source)\n        tgt_container_name, tgt_blob_name = self.__class__._parse_path(target)\n\n        src_blob_client = client.get_blob_client(src_container_name, src_blob_name)\n        tgt_blob_client = client.get_blob_client(tgt_container_name, tgt_blob_name)\n\n        # Use Azure's copy operation\n        source_url = src_blob_client.url\n        await tgt_blob_client.start_copy_from_url(source_url)\n\n    async def copytree(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy directory tree to target recursively.\n\n        Args:\n            source: Source Azure path\n            target: Target Azure path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and await self.is_symlink(source):\n            source = await self.readlink(source)\n\n        if not await self.is_dir(source):\n            raise NotADirectoryError(f\"Source is not a directory: {source}\")\n\n        src_container_name, src_prefix = self.__class__._parse_path(source)\n        tgt_container_name, tgt_prefix = self.__class__._parse_path(target)\n\n        # Ensure prefixes end with / for directory operations\n        if src_prefix and not src_prefix.endswith(\"/\"):\n            src_prefix += \"/\"\n        if tgt_prefix and not tgt_prefix.endswith(\"/\"):\n            tgt_prefix += \"/\"\n\n        client = await self._get_client()\n        src_container_client = client.get_container_client(src_container_name)\n\n        # List all blobs with source prefix\n        async for blob in src_container_client.list_blobs(name_starts_with=src_prefix):\n            src_blob_name = blob.name\n            # Calculate relative path and target blob name\n            rel_path = src_blob_name[len(src_prefix) :]\n            tgt_blob_name = tgt_prefix + rel_path\n\n            # Copy blob\n            src_blob_client = client.get_blob_client(src_container_name, src_blob_name)\n            tgt_blob_client = client.get_blob_client(tgt_container_name, tgt_blob_name)\n            source_url = src_blob_client.url\n            await tgt_blob_client.start_copy_from_url(source_url)\n\n\nclass AzureAsyncFileHandle(AsyncFileHandle):DOCS\n    \"\"\"Async file handle for Azure with chunked streaming support.\n\n    Uses Azure SDK's download_blob streaming API.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):  # type: ignore[no-untyped-def]\n        super().__init__(*args, **kwargs)\n        self._read_residue = b\"\" if self._is_binary else \"\"\n\n    async def reset_stream(self) -&gt; None:DOCS\n        \"\"\"Reset the underlying stream to the beginning.\"\"\"\n        await super().reset_stream()\n        self._read_residue = b\"\" if self._is_binary else \"\"\n\n    async def _create_stream(self):  # type: ignore[no-untyped-def]\n        \"\"\"Create async read stream generator.\"\"\"\n        return (\n            await self._client.get_blob_client(  # type: ignore[union-attr]\n                self._bucket,\n                self._blob,\n            ).download_blob()\n        ).chunks()\n\n    @classmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:\n        \"\"\"Check if exception indicates blob does not exist.\"\"\"\n        return isinstance(exception, ResourceNotFoundError)\n\n    async def _stream_read(self, size: int = -1) -&gt; Union[str, bytes]:\n        \"\"\"Read from stream in chunks.\"\"\"\n        if self._eof:\n            return b\"\" if self._is_binary else \"\"\n\n        if size == -1:\n            # Read all remaining data from current position\n            chunks = [self._read_residue]\n            self._read_residue = b\"\" if self._is_binary else \"\"\n\n            try:\n                async for chunk in self._stream:\n                    if self._is_binary:\n                        chunks.append(chunk)\n                    else:\n                        chunks.append(chunk.decode(self._encoding))\n            except StopAsyncIteration:  # pragma: no cover\n                pass\n\n            self._eof = True\n            result = (b\"\" if self._is_binary else \"\").join(chunks)  # type: ignore[attr-defined]\n            return result  # type: ignore[no-any-return]\n        else:\n            while len(self._read_residue) &lt; size:\n                try:\n                    chunk = await self._stream.__anext__()\n                except StopAsyncIteration:\n                    break\n\n                if self._is_binary:\n                    self._read_residue += chunk\n                else:\n                    self._read_residue += chunk.decode(self._encoding)\n\n                if len(self._read_residue) &gt;= size:\n                    break\n\n            if len(self._read_residue) &lt; size:\n                self._eof = True\n                result = self._read_residue\n                self._read_residue = b\"\" if self._is_binary else \"\"\n                return result  # type: ignore[no-any-return]\n\n            result = self._read_residue[:size]\n            self._read_residue = self._read_residue[size:]\n            return result  # type: ignore[no-any-return]\n\n    async def _upload(self, data: Union[str, bytes]) -&gt; None:\n        \"\"\"Upload data to Azure blob using append semantics.\n\n        This method uses Azure append blobs for efficient appending.\n        For 'w' mode on first write, it overwrites. Subsequently it appends.\n        For 'a' mode, it always appends.\n\n        Args:\n            data: Data to upload\n                (will be appended to existing content after first write)\n        \"\"\"\n        if isinstance(data, str):\n            data = data.encode(self._encoding)\n\n        blob_client = self._client.get_blob_client(  # type: ignore[union-attr]\n            self._bucket, self._blob\n        )\n\n        # For 'w' mode on first write, overwrite existing content\n        if self._first_write and not self._is_append:\n            self._first_write = False\n            # Simple overwrite\n            await blob_client.upload_blob(data, overwrite=True)\n            return\n\n        from azure.storage.blob import BlobType  # type: ignore[import-not-found]\n\n        self._first_write = False\n\n        # For subsequent writes or 'a' mode, use append semantics\n        # Check if blob exists and its type\n        try:\n            properties = await blob_client.get_blob_properties()\n            blob_exists = True\n            blob_type = properties.blob_type\n        except ResourceNotFoundError:\n            blob_exists = False\n            blob_type = None\n\n        if not blob_exists:\n            # Create new append blob\n            await blob_client.upload_blob(data, blob_type=BlobType.AppendBlob)\n        elif blob_type == \"AppendBlob\":\n            # Append to existing append blob\n            await blob_client.append_block(data)\n        else:\n            # Convert block blob to append blob by reading, then creating append blob\n            existing_data = await blob_client.download_blob()\n            existing_content = await existing_data.readall()\n\n            # Delete the old block blob\n            await blob_client.delete_blob()\n\n            # Create new append blob with combined content\n            await blob_client.upload_blob(\n                existing_content + data, blob_type=BlobType.AppendBlob\n            )\n</code></pre>"},{"location":"api/source/panpath.azure_client/","title":"panpath.azure_client","text":""},{"location":"api/source/panpath.azure_client/","title":"SOURCE CODE panpath.azure_client DOCS","text":"<pre><code>\"\"\"Azure Blob Storage client implementation.\"\"\"\n\nfrom typing import TYPE_CHECKING, Any, Iterator, Optional, Union\nimport os\n\nfrom panpath.clients import SyncClient, SyncFileHandle\nfrom panpath.exceptions import MissingDependencyError, NoStatError\n\nif TYPE_CHECKING:\n    from azure.storage.blob import BlobServiceClient  # type: ignore[import-not-found]\n    from azure.core.exceptions import ResourceNotFoundError  # type: ignore[import-not-found]\n\ntry:\n    from azure.storage.blob import BlobServiceClient\n    from azure.core.exceptions import ResourceNotFoundError\n\n    HAS_AZURE = True\nexcept ImportError:\n    HAS_AZURE = False\n    ResourceNotFoundError = Exception\n\n\nclass AzureBlobClient(SyncClient):DOCS\n    \"\"\"Synchronous Azure Blob Storage client implementation.\"\"\"\n\n    prefix = (\"azure\", \"az\")\n\n    def __init__(self, connection_string: Optional[str] = None, **kwargs: Any):\n        \"\"\"Initialize Azure Blob client.\n\n        Args:\n            connection_string: Azure storage connection string\n            **kwargs: Additional arguments passed to BlobServiceClient\n        \"\"\"\n        if not HAS_AZURE:\n            raise MissingDependencyError(\n                backend=\"Azure Blob Storage\",\n                package=\"azure-storage-blob\",\n                extra=\"azure\",\n            )\n        if not connection_string and \"AZURE_STORAGE_CONNECTION_STRING\" in os.environ:\n            connection_string = os.environ[\"AZURE_STORAGE_CONNECTION_STRING\"]\n        if connection_string:\n            self._client = BlobServiceClient.from_connection_string(connection_string, **kwargs)\n        else:  # pragma: no cover\n            # Assume credentials from environment or other auth methods\n            self._client = BlobServiceClient(**kwargs)\n\n    def exists(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if Azure blob exists.\"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            # Check if container exists\n            try:\n                container_client = self._client.get_container_client(container_name)\n                return container_client.exists()  # type: ignore[no-any-return]\n            except Exception:  # pragma: no cover\n                return False\n\n        try:\n            blob_client = self._client.get_blob_client(container_name, blob_name)\n            if blob_client.exists():\n                return True\n            if blob_name.endswith(\"/\"):\n                # Already checking as directory\n                return False\n            # Checking if it is possibly a directory\n            blob_client_dir = self._client.get_blob_client(container_name, blob_name + \"/\")\n            return blob_client_dir.exists()  # type: ignore[no-any-return]\n        except Exception:  # pragma: no cover\n            return False\n\n    def read_bytes(self, path: str) -&gt; bytes:DOCS\n        \"\"\"Read Azure blob as bytes.\"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n        try:\n            return blob_client.download_blob().readall()  # type: ignore[no-any-return]\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n\n    def write_bytes(self, path: str, data: bytes) -&gt; None:DOCS\n        \"\"\"Write bytes to Azure blob.\"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n        blob_client.upload_blob(data, overwrite=True)\n\n    def delete(self, path: str) -&gt; None:DOCS\n        \"\"\"Delete Azure blob.\"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n\n        if self.is_dir(path):\n            raise IsADirectoryError(f\"Path is a directory: {path}\")\n\n        try:\n            blob_client.delete_blob()\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n\n    def list_dir(self, path: str) -&gt; list[str]:  # type: ignore[override]DOCS\n        \"\"\"List Azure blobs with prefix.\"\"\"\n        container_name, prefix = self.__class__._parse_path(path)\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        container_client = self._client.get_container_client(container_name)\n        blob_list = container_client.walk_blobs(name_starts_with=prefix, delimiter=\"/\")\n        results = []\n\n        for item in blob_list:\n            # walk_blobs returns both BlobProperties and BlobPrefix objects\n            if hasattr(item, \"name\"):\n                # BlobProperties (file)\n                if item.name != prefix:\n                    results.append(f\"{self.prefix[0]}://{container_name}/{item.name}\")\n            else:  # pragma: no cover\n                # BlobPrefix (directory)\n                results.append(f\"{self.prefix[0]}://{container_name}/{item.prefix.rstrip('/')}\")\n\n        return results\n\n    def is_dir(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if Azure path is a directory (has blobs with prefix).\"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            return True  # Container root is a directory\n\n        prefix = blob_name if blob_name.endswith(\"/\") else blob_name + \"/\"\n        container_client = self._client.get_container_client(container_name)\n        blob_list = container_client.list_blobs(name_starts_with=prefix)\n\n        for _ in blob_list:\n            return True\n        return False\n\n    def is_file(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if Azure path is a file.\"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            return False\n\n        blob_client = self._client.get_blob_client(container_name, blob_name.rstrip(\"/\"))\n        return blob_client.exists()  # type: ignore[no-any-return]\n\n    def stat(self, path: str) -&gt; os.stat_result:DOCS\n        \"\"\"Get Azure blob metadata.\"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n\n        try:\n            props = blob_client.get_blob_properties()\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n        except Exception:  # pragma: no cover\n            raise NoStatError(f\"Cannot retrieve stat for: {path}\")\n        else:\n            return os.stat_result(\n                (  # type: ignore[arg-type]\n                    None,  # mode\n                    None,  # ino\n                    f\"{self.prefix[0]}://\",  # dev,\n                    None,  # nlink,\n                    None,  # uid,\n                    None,  # gid,\n                    props.size,  # size,\n                    # atime\n                    props.last_modified,\n                    # mtime\n                    props.last_modified,\n                    # ctime\n                    props.creation_time,\n                )\n            )\n\n    def open(DOCS\n        self,\n        path: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; SyncFileHandle:\n        \"\"\"Open Azure blob for reading/writing.\n\n        Args:\n            path: Azure path\n            mode: File mode\n            encoding: Text encoding\n            **kwargs: Additional arguments (chunk_size, upload_warning_threshold,\n                upload_interval supported)\n        \"\"\"\n        if mode not in (\"r\", \"rb\", \"w\", \"wb\", \"a\", \"ab\"):\n            raise ValueError(f\"Unsupported mode '{mode}'. Use 'r', 'rb', 'w', 'wb', 'a', or 'ab'.\")\n\n        container_name, blob_name = self.__class__._parse_path(path)\n        return AzureSyncFileHandle(  # type: ignore[no-untyped-call]\n            client=self._client,\n            bucket=container_name,\n            blob=blob_name,\n            prefix=self.prefix[0],\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )\n\n    def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Create a directory marker (empty blob with trailing slash).\n\n        Args:\n            path: Azure path (az://container/path or azure://container/path)\n            parents: If True, create parent directories as needed\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure blob_name ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n\n        # Check if it already exists\n        if blob_client.exists():\n            if not exist_ok:\n                raise FileExistsError(f\"Directory already exists: {path}\")\n            return\n\n        # check parents\n        if blob_name:  # not container root\n            parts = blob_name.rstrip(\"/\").rsplit(\"/\", 1)\n            if len(parts) &gt; 1:  # has a parent (not directly under container)\n                parent_path = parts[0]\n                parent_blob_client = self._client.get_blob_client(container_name, parent_path + \"/\")\n                if not parent_blob_client.exists():\n                    if not parents:\n                        raise FileNotFoundError(f\"Parent directory does not exist: {path}\")\n                    # Create parent directories recursively\n                    self.mkdir(\n                        f\"{self.prefix[0]}://{container_name}/{parent_path}/\",\n                        parents=True,\n                        exist_ok=True,\n                    )\n\n        # Create empty directory marker\n        blob_client.upload_blob(b\"\", overwrite=False)\n\n    def get_metadata(self, path: str) -&gt; dict[str, str]:DOCS\n        \"\"\"Get blob metadata.\n\n        Args:\n            path: Azure path\n\n        Returns:\n            Dictionary of metadata key-value pairs\n        \"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n        try:\n            return blob_client.get_blob_properties()  # type: ignore[no-any-return]\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Azure blob not found: {path}\")\n\n    def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:DOCS\n        \"\"\"Set blob metadata.\n\n        Args:\n            path: Azure path\n            metadata: Dictionary of metadata key-value pairs\n        \"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n        blob_client.set_blob_metadata(metadata)\n\n    def symlink_to(self, path: str, target: str) -&gt; None:DOCS\n        \"\"\"Create symlink by storing target in metadata.\n\n        Args:\n            path: Azure path for the symlink\n            target: Target path the symlink should point to\n        \"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n\n        # Create empty blob\n        blob_client.upload_blob(b\"\", overwrite=True)\n\n        # Set symlink metadata\n        blob_client.set_blob_metadata({self.__class__.symlink_target_metaname: target})\n\n    def glob(self, path: str, pattern: str) -&gt; Iterator[str]:DOCS\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            path: Base Azure path\n            pattern: Glob pattern (e.g., \"*.txt\", \"**/*.py\")\n\n        Returns:\n            List of matching CloudPath objects\n        \"\"\"\n        from fnmatch import fnmatch\n\n        container_name, blob_prefix = self.__class__._parse_path(path)\n        container_client = self._client.get_container_client(container_name)\n\n        # Handle recursive patterns\n        if \"**\" in pattern:\n            # Recursive search - list all blobs under prefix\n            blobs = container_client.list_blobs(name_starts_with=blob_prefix)\n\n            # Extract the pattern part after **\n            pattern_parts = pattern.split(\"**/\")\n            if len(pattern_parts) &gt; 1:\n                file_pattern = pattern_parts[-1]\n            else:\n                file_pattern = \"*\"\n\n            for blob in blobs:\n                if fnmatch(blob.name, f\"*{file_pattern}\"):\n                    # Determine scheme from original path\n                    scheme = \"az\" if path.startswith(f\"{self.prefix[0]}://\") else \"azure\"\n                    yield f\"{scheme}://{container_name}/{blob.name}\"\n        else:\n            # Non-recursive - list blobs with prefix\n            prefix_with_slash = (\n                f\"{blob_prefix}/\" if blob_prefix and not blob_prefix.endswith(\"/\") else blob_prefix\n            )\n            blobs = container_client.list_blobs(name_starts_with=prefix_with_slash)\n\n            for blob in blobs:\n                # Only include direct children (no additional slashes)\n                rel_name = blob.name[len(prefix_with_slash) :]\n                if \"/\" not in rel_name and fnmatch(blob.name, f\"{prefix_with_slash}{pattern}\"):\n                    scheme = \"az\" if path.startswith(f\"{self.prefix[0]}://\") else \"azure\"\n                    yield f\"{scheme}://{container_name}/{blob.name}\"\n\n    def walk(self, path: str) -&gt; Iterator[tuple[str, list[str], list[str]]]:DOCS\n        \"\"\"Walk directory tree.\n\n        Args:\n            path: Base Azure path\n\n        Yields:\n            Tuples of (dirpath, dirnames, filenames)\n        \"\"\"\n\n        container_name, blob_prefix = self.__class__._parse_path(path)\n        container_client = self._client.get_container_client(container_name)\n\n        # List all blobs under prefix\n        prefix = blob_prefix if blob_prefix else \"\"\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        # Organize into directory structure as we stream blobs\n        dirs: dict[str, tuple[set[str], set[str]]] = {}  # dirpath -&gt; (subdirs, files)\n        for blob in container_client.list_blobs(name_starts_with=prefix):\n            # Get relative path from prefix\n            rel_path = blob.name[len(prefix) :] if prefix else blob.name\n\n            # Split into directory and filename\n            parts = rel_path.split(\"/\")\n            if len(parts) == 1:\n                # File in root\n                if path not in dirs:\n                    dirs[path] = (set(), set())\n                if parts[0]:  # Skip empty strings\n                    dirs[path][1].add(parts[0])\n            else:\n                # File in subdirectory\n                # First, ensure root directory exists and add the first subdir to it\n                if path not in dirs:  # pragma: no cover\n                    dirs[path] = (set(), set())\n                if parts[0]:  # Add first-level subdirectory to root\n                    dirs[path][0].add(parts[0])\n\n                # Process all intermediate directories\n                for i in range(len(parts) - 1):\n                    dir_path = (\n                        f\"{path}/\" + \"/\".join(parts[: i + 1]) if path else \"/\".join(parts[: i + 1])\n                    )\n                    if dir_path not in dirs:\n                        dirs[dir_path] = (set(), set())\n\n                    # Add subdirectory if not last part\n                    if i &lt; len(parts) - 2:\n                        dirs[dir_path][0].add(parts[i + 1])\n\n                # Add file to its parent directory\n                parent_dir = f\"{path}/\" + \"/\".join(parts[:-1]) if path else \"/\".join(parts[:-1])\n                if parent_dir not in dirs:  # pragma: no cover\n                    dirs[parent_dir] = (set(), set())\n                if parts[-1]:  # Skip empty strings\n                    dirs[parent_dir][1].add(parts[-1])\n\n        # Yield each directory tuple\n        for d, (subdirs, files) in sorted(dirs.items()):\n            yield (d, sorted(subdirs), sorted(filter(None, files)))\n\n    def touch(  # type: ignore[no-untyped-def, override]DOCS\n        self,\n        path: str,\n        mode=None,\n        exist_ok: bool = True,\n    ) -&gt; None:\n        \"\"\"Create empty file.\n\n        Args:\n            path: Azure path\n            mode: File mode (not supported for Azure)\n            exist_ok: If False, raise error if file exists\n        \"\"\"\n        if mode is not None:\n            raise ValueError(\"Mode setting is not supported for Azure Blob Storage.\")\n\n        if not exist_ok and self.exists(path):\n            raise FileExistsError(f\"File already exists: {path}\")\n\n        container_name, blob_name = self.__class__._parse_path(path)\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n        blob_client.upload_blob(b\"\", overwrite=True)\n\n    def rename(self, source: str, target: str) -&gt; None:DOCS\n        \"\"\"Rename/move file.\n\n        Args:\n            source: Source Azure path\n            target: Target Azure path\n        \"\"\"\n        if not self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        # Copy to new location\n        src_container, src_blob = self.__class__._parse_path(source)\n        tgt_container, tgt_blob = self.__class__._parse_path(target)\n\n        src_blob_client = self._client.get_blob_client(src_container, src_blob)\n        tgt_blob_client = self._client.get_blob_client(tgt_container, tgt_blob)\n\n        # Copy blob\n        tgt_blob_client.start_copy_from_url(src_blob_client.url)\n\n        # Delete source\n        src_blob_client.delete_blob()\n\n    def rmdir(self, path: str) -&gt; None:DOCS\n        \"\"\"Remove directory marker.\n\n        Args:\n            path: Azure path\n        \"\"\"\n        container_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure blob_name ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        blob_client = self._client.get_blob_client(container_name, blob_name)\n\n        # Check if it is empty\n        if self.is_dir(path) and self.list_dir(path):\n            raise OSError(f\"Directory not empty: {path}\")\n\n        try:\n            blob_client.delete_blob()\n        except ResourceNotFoundError:\n            raise FileNotFoundError(f\"Directory not found: {path}\")\n\n    def rmtree(self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None) -&gt; None:DOCS\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            path: Azure path\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        if not self.exists(path):\n            if ignore_errors:\n                return\n            else:\n                raise FileNotFoundError(f\"Path not found: {path}\")\n\n        if not self.is_dir(path):\n            if ignore_errors:\n                return\n            else:\n                raise NotADirectoryError(f\"Path is not a directory: {path}\")\n\n        container_name, prefix = self.__class__._parse_path(path)\n\n        # Ensure prefix ends with / for directory listing\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        try:\n            container_client = self._client.get_container_client(container_name)\n\n            # List and delete all blobs with this prefix\n            for blob in container_client.list_blobs(name_starts_with=prefix):\n                blob_client = self._client.get_blob_client(container_name, blob.name)\n                blob_client.delete_blob()\n        except Exception:  # pragma: no cover\n            if ignore_errors:\n                return\n            if onerror is not None:\n                import sys\n\n                onerror(blob_client.delete_blob, path, sys.exc_info())\n            else:\n                raise\n\n    def copy(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy file to target.\n\n        Args:\n            source: Source Azure path\n            target: Target Azure path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and self.is_symlink(source):\n            source = self.readlink(source)\n\n        if self.is_dir(source):\n            raise IsADirectoryError(f\"Source is a directory: {source}\")\n\n        src_container_name, src_blob_name = self.__class__._parse_path(source)\n        tgt_container_name, tgt_blob_name = self.__class__._parse_path(target)\n\n        src_blob_client = self._client.get_blob_client(src_container_name, src_blob_name)\n        tgt_blob_client = self._client.get_blob_client(tgt_container_name, tgt_blob_name)\n\n        # Use Azure's copy operation\n        source_url = src_blob_client.url\n        tgt_blob_client.start_copy_from_url(source_url)\n\n    def copytree(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy directory tree to target recursively.\n\n        Args:\n            source: Source Azure path\n            target: Target Azure path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and self.is_symlink(source):\n            source = self.readlink(source)\n\n        if not self.is_dir(source):\n            raise NotADirectoryError(f\"Source is not a directory: {source}\")\n\n        src_container_name, src_prefix = self.__class__._parse_path(source)\n        tgt_container_name, tgt_prefix = self.__class__._parse_path(target)\n\n        # Ensure prefixes end with / for directory operations\n        if src_prefix and not src_prefix.endswith(\"/\"):\n            src_prefix += \"/\"\n        if tgt_prefix and not tgt_prefix.endswith(\"/\"):\n            tgt_prefix += \"/\"\n\n        src_container_client = self._client.get_container_client(src_container_name)\n\n        # List all blobs with source prefix\n        for blob in src_container_client.list_blobs(name_starts_with=src_prefix):\n            src_blob_name = blob.name\n            # Calculate relative path and target blob name\n            rel_path = src_blob_name[len(src_prefix) :]\n            tgt_blob_name = tgt_prefix + rel_path\n\n            # Copy blob\n            src_blob_client = self._client.get_blob_client(src_container_name, src_blob_name)\n            tgt_blob_client = self._client.get_blob_client(tgt_container_name, tgt_blob_name)\n            source_url = src_blob_client.url\n            tgt_blob_client.start_copy_from_url(source_url)\n\n\nclass AzureSyncFileHandle(SyncFileHandle):DOCS\n    \"\"\"Synchronous file handle for Azure Blob Storage.\"\"\"\n\n    def __init__(self, *args, **kwargs):  # type: ignore[no-untyped-def]\n        super().__init__(*args, **kwargs)\n        self._read_residue = b\"\" if self._is_binary else \"\"\n\n    @classmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:\n        \"\"\"Check if exception indicates blob does not exist.\"\"\"\n        return isinstance(exception, ResourceNotFoundError)\n\n    def reset_stream(self) -&gt; None:DOCS\n        \"\"\"Reset the underlying stream to the beginning.\"\"\"\n        super().reset_stream()\n        self._read_residue = b\"\" if self._is_binary else \"\"\n\n    def _create_stream(self):  # type: ignore[no-untyped-def]\n        \"\"\"Create sync read stream generator.\"\"\"\n        return self._client.get_blob_client(self._bucket, self._blob).download_blob().chunks()\n\n    def _stream_read(self, size: int = -1) -&gt; Union[str, bytes]:\n        \"\"\"Read from stream in chunks.\"\"\"\n        if self._eof:\n            return b\"\" if self._is_binary else \"\"\n\n        if size == -1:\n            # Read all remaining data from current position\n            chunks = [self._read_residue]\n            self._read_residue = b\"\" if self._is_binary else \"\"\n\n            try:\n                for chunk in self._stream:\n                    if self._is_binary:\n                        chunks.append(chunk)\n                    else:\n                        chunks.append(chunk.decode(self._encoding))\n            except StopIteration:  # pragma: no cover\n                pass\n\n            self._eof = True\n            result = (b\"\" if self._is_binary else \"\").join(chunks)  # type: ignore[attr-defined]\n            return result  # type: ignore[no-any-return]\n        else:\n            while len(self._read_residue) &lt; size:\n                try:\n                    chunk = next(self._stream)\n                except StopIteration:\n                    break\n\n                if self._is_binary:\n                    self._read_residue += chunk\n                else:\n                    self._read_residue += chunk.decode(self._encoding)\n\n                if len(self._read_residue) &gt;= size:\n                    break\n\n            if len(self._read_residue) &lt; size:\n                self._eof = True\n                result = self._read_residue\n                self._read_residue = b\"\" if self._is_binary else \"\"\n                return result  # type: ignore[no-any-return]\n\n            result = self._read_residue[:size]\n            self._read_residue = self._read_residue[size:]\n            return result  # type: ignore[no-any-return]\n\n    def _upload(self, data: Union[str, bytes]) -&gt; None:\n        \"\"\"Upload data to Azure blob using append semantics.\n\n        This method uses Azure append blobs for efficient appending.\n        For 'w' mode on first write, it overwrites. Subsequently it appends.\n        For 'a' mode, it always appends.\n\n        Args:\n            data: Data to upload\n                (will be appended to existing content after first write)\n        \"\"\"\n        if isinstance(data, str):\n            data = data.encode(self._encoding)\n\n        blob_client = self._client.get_blob_client(self._bucket, self._blob)\n\n        # For 'w' mode on first write, overwrite existing content\n        if self._first_write and not self._is_append:\n            self._first_write = False\n            # Simple overwrite\n            blob_client.upload_blob(data, overwrite=True)\n            return\n\n        self._first_write = False\n\n        # For subsequent writes or 'a' mode, use append semantics\n        # Check if blob exists and its type\n        try:\n            properties = blob_client.get_blob_properties()\n            blob_exists = True\n            blob_type = properties.blob_type\n        except ResourceNotFoundError:\n            blob_exists = False\n            blob_type = None\n\n        if not blob_exists:\n            # Create new append blob\n            from azure.storage.blob import BlobType\n\n            blob_client.upload_blob(data, blob_type=BlobType.AppendBlob)\n        elif blob_type == \"AppendBlob\":\n            # Append to existing append blob\n            blob_client.append_block(data)\n        else:\n            # Convert block blob to append blob by reading, then creating append blob\n            existing_data = blob_client.download_blob()\n            existing_content = existing_data.readall()\n\n            # Delete the old block blob\n            blob_client.delete_blob()\n\n            # Create new append blob with combined content\n            from azure.storage.blob import BlobType\n\n            blob_client.upload_blob(existing_content + data, blob_type=BlobType.AppendBlob)\n</code></pre>"},{"location":"api/source/panpath.azure_path/","title":"panpath.azure_path","text":""},{"location":"api/source/panpath.azure_path/","title":"SOURCE CODE panpath.azure_path DOCS","text":"<pre><code>\"\"\"Azure Blob Storage path implementation.\"\"\"\n\nfrom typing import TYPE_CHECKING, Optional\n\nfrom panpath.cloud import CloudPath\nfrom panpath.azure_client import AzureBlobClient\nfrom panpath.azure_async_client import AsyncAzureBlobClient\n\nif TYPE_CHECKING:\n    from panpath.clients import Client, AsyncClient\n\n\nclass AzurePath(CloudPath):DOCS\n    \"\"\"Azure Blob Storage path implementation (sync and async methods).\"\"\"\n\n    _client: Optional[AzureBlobClient] = None\n    _default_client: Optional[AzureBlobClient] = None\n\n    @classmethod\n    def _create_default_client(cls) -&gt; \"Client\":  # type: ignore[override]\n        \"\"\"Create default Azure Blob client.\"\"\"\n        return AzureBlobClient()\n\n    @classmethod\n    def _create_default_async_client(cls) -&gt; \"AsyncClient\":\n        \"\"\"Create default async Azure Blob client.\"\"\"\n        return AsyncAzureBlobClient()\n</code></pre>"},{"location":"api/source/panpath.base/","title":"panpath.base","text":""},{"location":"api/source/panpath.base/","title":"SOURCE CODE panpath.base DOCS","text":"<pre><code>\"\"\"Base class for all PanPath path implementations.\"\"\"\n\nimport os\nimport re\nimport sys\nfrom pathlib import Path as PathlibPath, PurePosixPath\nfrom typing import TYPE_CHECKING, Any, AsyncGenerator, List, Union\n\nfrom panpath.registry import get_path_class\n\nif TYPE_CHECKING:\n    from panpath.clients import AsyncFileHandle\n\n\n# URI scheme pattern\n_URI_PATTERN = re.compile(r\"^([a-z][a-z0-9+.-]*):\\/\\/\", re.IGNORECASE)\n\n\ndef _parse_uri(path: str) -&gt; tuple[Union[str, None], str]:\n    \"\"\"Parse URI to extract scheme and path.\n\n    Args:\n        path: Path string that may contain URI scheme\n\n    Returns:\n        Tuple of (scheme, path_without_scheme) or (None, path) for local paths\n    \"\"\"\n    match = _URI_PATTERN.match(path)\n    if match:\n        scheme = match.group(1).lower()\n        # Special handling for file:// URLs - strip to local path\n        if scheme == \"file\":\n            return None, path[7:]  # Keeps path from file://path\n        return scheme, path\n    return None, path\n\n\nclass PanPath(PathlibPath):DOCS\n    \"\"\"Universal path base class and factory.\n\n    This class inherits from pathlib.Path and serves dual purposes:\n    1. Base class for all path types in the panpath package\n    2. Factory for creating appropriate path instances via __new__\n\n    As a base class, it's inherited by:\n    - LocalPath (local filesystem paths with sync and async methods)\n    - CloudPath (cloud storage paths with sync and async methods)\n    - All cloud-specific subclasses (GSPath, S3Path, AzurePath, etc.)\n\n    As a factory, calling PanPath(...) returns the appropriate concrete implementation\n    based on the URI scheme.\n\n    Use `isinstance(obj, PanPath)` to check if an object is a path created by this package.\n\n    Examples:\n        &gt;&gt;&gt; # Local path\n        &gt;&gt;&gt; path = PanPath(\"/local/file.txt\")\n        &gt;&gt;&gt; isinstance(path, PanPath)\n        True\n\n        &gt;&gt;&gt; # S3 path\n        &gt;&gt;&gt; path = PanPath(\"s3://bucket/key.txt\")\n        &gt;&gt;&gt; isinstance(path, PanPath)\n        True\n\n        &gt;&gt;&gt; # Async method with a_ prefix\n        &gt;&gt;&gt; content = await path.a_read_text()\n    \"\"\"\n\n    def __new__(cls, *args: Any, **kwargs: Any) -&gt; \"PanPath\":DOCS\n        \"\"\"Create and return the appropriate path instance.\n\n        If called on a subclass, returns instance of that subclass.\n        If called on PanPath itself, routes to the appropriate concrete class.\n        \"\"\"\n        # If this is a subclass (not PanPath itself), use normal Path behavior\n        if cls is not PanPath:\n            # For CloudPath and its subclasses, we need special handling\n            # since they inherit from PurePosixPath behavior\n            if hasattr(cls, \"_is_cloud_path\") and cls._is_cloud_path:  # pragma: no cover\n                # CloudPath subclasses use PurePosixPath-like behavior\n                # Create via PurePosixPath mechanism\n                return PurePosixPath.__new__(cls, *args)\n            # For LocalPath, use pathlib.Path behavior\n            return PathlibPath.__new__(cls, *args)\n\n        # PanPath factory logic - only when called as PanPath(...) directly\n        # Extract the first argument as the path\n        if not args:\n            args = (\"\",)  # Default to empty path if no args provided\n\n        path = args[0]\n        if isinstance(path, PanPath):\n            # If already a PanPath instance, return as is\n            return path\n\n        path_str = str(path)\n\n        # Parse URI to get scheme\n        scheme, clean_path = _parse_uri(path_str)\n\n        if scheme is None:\n            # Local path - create a new args tuple with the clean path\n            # This will be passed to LocalPath.__new__ and __init__\n            from panpath.local_path import LocalPath\n\n            new_args = (clean_path,) + args[1:]\n            # Use PathlibPath.__new__() to properly initialize the path object\n            instance = PathlibPath.__new__(LocalPath, *new_args)\n            # In Python 3.10, __init__ doesn't accept arguments\n            # In Python 3.12+, __init__ needs the arguments\n            if sys.version_info &gt;= (3, 12):\n                LocalPath.__init__(instance, *new_args, **kwargs)  # type: ignore[no-untyped-call]\n            else:  # pragma: no cover\n                LocalPath.__init__(instance)  # type: ignore[no-untyped-call]\n            return instance\n\n        # Cloud path - look up in registry and instantiate\n        try:\n            path_class = get_path_class(scheme)\n            return path_class(*args, **kwargs)  # type: ignore[no-any-return]\n        except KeyError:\n            raise ValueError(f\"Unsupported URI scheme: {scheme!r}\")\n\n    # These methods are used for IDE type hinting and documentation generation.\n    # Actual implementations are in LocalPath and CloudPath subclasses and\n    # are routed via __new__.\n    async def a_resolve(self) -&gt; \"PanPath\":  # type: ignore[empty-body]DOCS\n        \"\"\"Resolve to absolute path (no-op for cloud paths).\n\n        Returns:\n            Self (cloud paths are already absolute)\n        \"\"\"\n\n    async def a_exists(self) -&gt; bool:  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously check if the path exists.\n\n        Returns:\n            True if the path exists, False otherwise.\n        \"\"\"\n\n    async def a_read_bytes(self) -&gt; bytes:  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously read the file's bytes.\n\n        Returns:\n            File content as bytes.\n        \"\"\"\n\n    async def a_read_text(self, encoding: str = \"utf-8\") -&gt; str:  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously read the file's text content.\n\n        Args:\n            encoding: Text encoding to use (default: 'utf-8')\n\n        Returns:\n            File content as string.\n        \"\"\"\n\n    async def a_write_bytes(self, data: bytes) -&gt; Union[int, None]:DOCS\n        \"\"\"Asynchronously write bytes to the file.\n\n        Args:\n            data: Bytes to write to the file.\n\n        Returns:\n            Number of bytes written. For some cloud paths, may return None.\n        \"\"\"\n\n    async def a_write_text(  # type: ignore[empty-body]DOCS\n        self,\n        data: str,\n        encoding: str = \"utf-8\",\n    ) -&gt; int:\n        \"\"\"Asynchronously write text to the file.\n\n        Args:\n            data: Text to write to the file.\n            encoding: Text encoding to use (default: 'utf-8')\n\n        Returns:\n            Number of characters written.\n        \"\"\"\n\n    async def a_unlink(self, missing_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Asynchronously remove (delete) the file or empty directory.\n\n        Args:\n            missing_ok: If True, does not raise an error if the file does not exist.\n        \"\"\"\n\n    async def a_iterdir(self) -&gt; AsyncGenerator[\"PanPath\", None]:  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously iterate over directory contents.\n\n        Yields:\n            PanPath instances for each item in the directory.\n        \"\"\"\n\n    async def a_is_dir(self) -&gt; bool:  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously check if the path is a directory.\n\n        Returns:\n            True if the path is a directory, False otherwise.\n        \"\"\"\n\n    async def a_is_file(self) -&gt; bool:  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously check if the path is a file.\n\n        Returns:\n            True if the path is a file, False otherwise.\n        \"\"\"\n\n    async def a_stat(  # type: ignore[empty-body]DOCS\n        self,\n        follow_symlinks: bool = True,\n    ) -&gt; os.stat_result:\n        \"\"\"Asynchronously get the file or directory's status information.\n\n        Returns:\n            An object containing file status information (platform-dependent).\n        \"\"\"\n\n    async def a_mkdir(DOCS\n        self,\n        mode: int = 0o777,\n        parents: bool = False,\n        exist_ok: bool = False,\n    ) -&gt; None:\n        \"\"\"Asynchronously create a directory at this path.\n\n        Args:\n            mode: Directory mode (permissions) to set.\n            parents: If True, create parent directories as needed.\n            exist_ok: If True, does not raise an error if the directory already exists.\n        \"\"\"\n\n    async def a_glob(  # type: ignore[empty-body]DOCS\n        self,\n        pattern: str,\n    ) -&gt; AsyncGenerator[\"PanPath\", None]:\n        \"\"\"Asynchronously yield paths matching a glob pattern.\n\n        Args:\n            pattern: Glob pattern to match.\n\n        Returns:\n            List of PanPath instances matching the pattern.\n        \"\"\"\n\n    async def a_rglob(  # type: ignore[empty-body]DOCS\n        self,\n        pattern: str,\n    ) -&gt; AsyncGenerator[\"PanPath\", None]:\n        \"\"\"Asynchronously yield paths matching a recursive glob pattern.\n\n        Args:\n            pattern: Recursive glob pattern to match.\n\n        Returns:\n            List of PanPath instances matching the pattern.\n        \"\"\"\n\n    async def a_walk(  # type: ignore[empty-body]DOCS\n        self,\n    ) -&gt; AsyncGenerator[tuple[\"PanPath\", List[str], List[str]], None]:\n        \"\"\"Asynchronously walk the directory tree.\n\n        Yields:\n            Tuples of (current_path, dirnames, filenames) at each level.\n        \"\"\"\n\n    async def a_touch(DOCS\n        self,\n        mode: int = 0o666,\n        exist_ok: bool = True,\n    ) -&gt; None:\n        \"\"\"Asynchronously create the file if it does not exist.\n\n        Args:\n            mode: File mode (permissions) to set if creating the file.\n            exist_ok: If False, raises an error if the file already exists.\n        \"\"\"\n\n    async def a_rename(  # type: ignore[empty-body]DOCS\n        self,\n        target: Union[str, \"PathlibPath\"],\n    ) -&gt; \"PanPath\":\n        \"\"\"Asynchronously rename this path to the target path.\n\n        Args:\n            target: New path to rename to.\n\n        Returns:\n            The renamed PanPath instance.\n        \"\"\"\n\n    async def a_replace(  # type: ignore[empty-body]DOCS\n        self,\n        target: Union[str, \"PathlibPath\"],\n    ) -&gt; \"PanPath\":\n        \"\"\"Asynchronously replace this path with the target path.\n\n        Args:\n            target: New path to replace with.\n\n        Returns:\n            The replaced PanPath instance.\n        \"\"\"\n\n    async def a_rmdir(self) -&gt; None:DOCS\n        \"\"\"Asynchronously remove the directory and its contents recursively.\"\"\"\n\n    async def a_is_symlink(self) -&gt; bool:  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously check if the path is a symbolic link.\n\n        For local path, this checks if the path is a symlink.\n        For cloud paths, this will check if the object has a metdata flag indicating it's a symlink.\n        Note that it is not a real symlink like in local filesystems.\n        But for example, gcsfuse supports symlink-like behavior via metadata.\n\n        Returns:\n            True if the path is a symlink, False otherwise.\n        \"\"\"\n\n    async def a_readlink(self) -&gt; \"PanPath\":  # type: ignore[empty-body]DOCS\n        \"\"\"Asynchronously read the target of the symbolic link.\n\n        For local path, this reads the symlink target.\n        For cloud paths, this reads the metadata flag indicating the symlink target.\n\n        Returns:\n            The target PanPath of the symlink.\n        \"\"\"\n\n    async def a_symlink_to(DOCS\n        self,\n        target: Union[str, \"PathlibPath\"],\n        target_is_directory: bool = False,\n    ) -&gt; None:\n        \"\"\"Asynchronously create a symbolic link pointing to the target path.\n\n        For local path, this creates a real symlink.\n        For cloud paths, this sets a metadata flag indicating the symlink target.\n\n        Args:\n            target: The target PanPath the symlink points to.\n            target_is_directory: Whether the target is a directory (ignored for cloud paths).\n        \"\"\"\n\n    async def a_rmtree(self, ignore_errors: bool = False, onerror: Any = None) -&gt; None:DOCS\n        \"\"\"Asynchronously remove the directory and all its contents recursively.\n\n        Args:\n            ignore_errors: If True, ignores errors during removal.\n            onerror: Optional function to call on errors.\n        \"\"\"\n\n    async def a_copy(  # type: ignore[empty-body]DOCS\n        self,\n        target: Union[str, \"PathlibPath\"],\n    ) -&gt; \"PanPath\":\n        \"\"\"Asynchronously copy this path to the target path.\n\n        Args:\n            target: Destination PanPath to copy to.\n\n        Returns:\n            The copied PanPath instance.\n        \"\"\"\n\n    async def a_copytree(  # type: ignore[empty-body]DOCS\n        self,\n        target: Union[str, \"PathlibPath\"],\n        follow_symlinks: bool = True,\n    ) -&gt; \"PanPath\":\n        \"\"\"Asynchronously copy the directory and all its contents recursively to the target path.\n\n        Args:\n            target: Destination PanPath to copy to.\n            follow_symlinks: If True, copies the contents of symlinks.\n\n        Returns:\n            The copied PanPath instance.\n        \"\"\"\n\n    def a_open(  # type: ignore[empty-body]DOCS\n        self,\n        mode: str = \"r\",\n        encoding: str = \"utf-8\",\n        **kwargs: Any,\n    ) -&gt; \"AsyncFileHandle\":\n        \"\"\"Asynchronously open the file and return an async file handle.\n\n        Args:\n            mode: Mode to open the file (e.g., 'r', 'rb', 'w', 'wb').\n            encoding: Text encoding to use (default: 'utf-8').\n            **kwargs: Additional arguments to pass to the underlying open method.\n\n        Returns:\n            An async file handle.\n        \"\"\"\n\n    # backports\n    def walk(self) -&gt; Any:  # type: ignore[empty-body]DOCS\n        \"\"\"Walk the directory tree.\n\n        Yields:\n            Tuples of (current_path, dirnames, filenames) at each level.\n        \"\"\"\n</code></pre>"},{"location":"api/source/panpath.clients/","title":"panpath.clients","text":""},{"location":"api/source/panpath.clients/","title":"SOURCE CODE panpath.clients DOCS","text":"<pre><code>\"\"\"Base client classes for sync and async cloud storage operations.\"\"\"\n\nfrom abc import ABC, abstractmethod\nimport asyncio\nimport time\nfrom typing import (\n    Any,\n    AsyncGenerator,\n    Callable,\n    Iterator,\n    List,\n    Optional,\n    Tuple,\n    Union,\n    Awaitable,\n)\n\nimport re\nimport warnings\n\n\nclass Client(ABC):DOCS\n    \"\"\"Base class for cloud storage clients.\"\"\"\n\n    prefix: Tuple[str, ...]\n    symlink_target_metaname: str = \"symlink_target\"\n\n    @abstractmethodDOCS\n    def open(\n        self,\n        path: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; Union[\"SyncFileHandle\", \"AsyncFileHandle\"]:\n        \"\"\"Open file and return sync/async file handle.\n\n        Args:\n            path: Cloud storage path\n            mode: File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')\n            encoding: Text encoding (for text modes)\n            **kwargs: Additional arguments for specific implementations\n\n        Returns:\n            SyncFileHandle/AsyncFileHandle instance\n        \"\"\"\n\n    @classmethod\n    def _parse_path(cls, path: str) -&gt; tuple[str, str]:\n        \"\"\"Parse cloud storage path into bucket/container and blob/object key.\n\n        Args:\n            path: Full cloud storage path\n\n        Returns:\n            Tuple of (bucket/container, blob/object key)\n        \"\"\"\n        for prefix in cls.prefix:\n            if path.startswith(f\"{prefix}://\"):\n                path = path[len(f\"{prefix}://\") :]\n                break\n\n        path = re.sub(r\"/+\", \"/\", path)  # Normalize slashes\n        parts = path.split(\"/\", 1)\n        bucket = parts[0].lstrip(\"/\")\n        blob = parts[1] if len(parts) &gt; 1 else \"\"\n        return bucket, blob\n\n\nclass SyncClient(Client, ABC):DOCS\n    \"\"\"Base class for synchronous cloud storage clients.\"\"\"\n\n    @abstractmethodDOCS\n    def exists(self, path: str) -&gt; bool:\n        \"\"\"Check if path exists.\"\"\"\n\n    @abstractmethodDOCS\n    def read_bytes(self, path: str) -&gt; bytes:\n        \"\"\"Read file as bytes.\"\"\"\n\n    @abstractmethodDOCS\n    def write_bytes(self, path: str, data: bytes) -&gt; None:\n        \"\"\"Write bytes to file.\"\"\"\n\n    @abstractmethodDOCS\n    def delete(self, path: str) -&gt; None:\n        \"\"\"Delete file.\"\"\"\n\n    @abstractmethodDOCS\n    def list_dir(self, path: str) -&gt; Iterator[str]:\n        \"\"\"List directory contents.\"\"\"\n\n    @abstractmethodDOCS\n    def is_dir(self, path: str) -&gt; bool:\n        \"\"\"Check if path is a directory.\"\"\"\n\n    @abstractmethodDOCS\n    def is_file(self, path: str) -&gt; bool:\n        \"\"\"Check if path is a file.\"\"\"\n\n    @abstractmethodDOCS\n    def stat(self, path: str) -&gt; Any:\n        \"\"\"Get file stats.\"\"\"\n\n    @abstractmethodDOCS\n    def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:\n        \"\"\"Create a directory marker (empty blob with trailing slash).\"\"\"\n\n    @abstractmethodDOCS\n    def glob(self, path: str, pattern: str) -&gt; Iterator[str]:\n        \"\"\"Find all paths matching pattern.\"\"\"\n\n    @abstractmethodDOCS\n    def walk(self, path: str) -&gt; Iterator[tuple[str, list[str], list[str]]]:\n        \"\"\"Walk directory tree.\"\"\"\n\n    @abstractmethodDOCS\n    def touch(self, path: str, exist_ok: bool = True) -&gt; None:\n        \"\"\"Create empty file or update metadata.\"\"\"\n\n    @abstractmethodDOCS\n    def rename(self, src: str, dst: str) -&gt; None:\n        \"\"\"Rename/move file.\"\"\"\n\n    @abstractmethodDOCS\n    def rmdir(self, path: str) -&gt; None:\n        \"\"\"Remove directory marker.\"\"\"\n\n    @abstractmethodDOCS\n    def symlink_to(self, path: str, target: str) -&gt; None:\n        \"\"\"Create symlink by storing target in metadata.\"\"\"\n\n    @abstractmethodDOCS\n    def get_metadata(self, path: str) -&gt; dict[str, str]:\n        \"\"\"Get object metadata.\"\"\"\n\n    @abstractmethodDOCS\n    def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:\n        \"\"\"Set object metadata.\"\"\"\n\n    @abstractmethodDOCS\n    def rmtree(self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None) -&gt; None:\n        \"\"\"Remove directory and all its contents recursively.\"\"\"\n\n    @abstractmethodDOCS\n    def copy(self, src: str, dst: str, follow_symlinks: bool = True) -&gt; None:\n        \"\"\"Copy file from src to dst.\"\"\"\n\n    @abstractmethodDOCS\n    def copytree(self, src: str, dst: str, follow_symlinks: bool = True) -&gt; None:\n        \"\"\"Copy directory tree from src to dst recursively.\"\"\"\n\n    def read_text(self, path: str, encoding: str = \"utf-8\") -&gt; str:DOCS\n        \"\"\"Read file as text.\"\"\"\n        data = self.read_bytes(path)\n        return data.decode(encoding)\n\n    def write_text(self, path: str, data: str, encoding: str = \"utf-8\") -&gt; None:DOCS\n        \"\"\"Write text to file.\"\"\"\n        self.write_bytes(path, data.encode(encoding))\n\n    def is_symlink(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if path is a symlink (has symlink metadata).\n\n        Args:\n            path: Cloud path\n\n        Returns:\n            True if path is a symlink\n        \"\"\"\n        try:\n            metadata = self.get_metadata(path)\n            meta_dict: Any = metadata.get(\"metadata\", {})\n            if isinstance(meta_dict, dict):\n                return self.__class__.symlink_target_metaname in meta_dict\n            return False  # pragma: no cover\n        except Exception:\n            return False\n\n    def readlink(self, path: str) -&gt; str:DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Args:\n            path: Cloud path\n\n        Returns:\n            Symlink target path\n        \"\"\"\n        metadata = self.get_metadata(path)\n        meta_dict: Any = metadata.get(\"metadata\", {})\n        if not isinstance(meta_dict, dict):  # pragma: no cover\n            raise ValueError(f\"Invalid metadata format for: {path}\")\n        target: Any = meta_dict.get(self.__class__.symlink_target_metaname, None)\n        if not target or not isinstance(target, str):\n            raise ValueError(f\"Not a symlink: {path}\")\n\n        if any(target.startswith(f\"{prefix}://\") for prefix in self.__class__.prefix):\n            return str(target)\n\n        path = path.rstrip(\"/\").rsplit(\"/\", 1)[0]  # pragma: no cover\n        return f\"{path}/{target}\"  # pragma: no cover\n\n\nclass AsyncClient(Client, ABC):DOCS\n    \"\"\"Base class for asynchronous cloud storage clients.\"\"\"\n\n    @abstractmethodDOCS\n    async def close(self) -&gt; None:\n        \"\"\"Close any open connections/resources.\"\"\"\n\n    @abstractmethodDOCS\n    async def exists(self, path: str) -&gt; bool:\n        \"\"\"Check if path exists.\"\"\"\n\n    @abstractmethodDOCS\n    async def read_bytes(self, path: str) -&gt; bytes:\n        \"\"\"Read file as bytes.\"\"\"\n\n    @abstractmethodDOCS\n    async def write_bytes(self, path: str, data: bytes) -&gt; int:\n        \"\"\"Write bytes to file.\"\"\"\n\n    @abstractmethodDOCS\n    async def delete(self, path: str) -&gt; None:\n        \"\"\"Delete file.\"\"\"\n\n    @abstractmethodDOCS\n    async def list_dir(self, path: str) -&gt; list[str]:\n        \"\"\"List directory contents.\"\"\"\n\n    @abstractmethodDOCS\n    async def is_dir(self, path: str) -&gt; bool:\n        \"\"\"Check if path is a directory.\"\"\"\n\n    @abstractmethodDOCS\n    async def is_file(self, path: str) -&gt; bool:\n        \"\"\"Check if path is a file.\"\"\"\n\n    @abstractmethodDOCS\n    async def stat(self, path: str) -&gt; Any:\n        \"\"\"Get file stats.\"\"\"\n\n    @abstractmethodDOCS\n    async def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:\n        \"\"\"Create a directory marker (empty blob with trailing slash).\"\"\"\n\n    @abstractmethodDOCS\n    async def glob(self, path: str, pattern: str) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Find all paths matching pattern.\"\"\"\n\n    @abstractmethodDOCS\n    async def walk(\n        self,\n        path: str,\n    ) -&gt; AsyncGenerator[tuple[str, list[str], list[str]], None]:\n        \"\"\"Walk directory tree.\"\"\"\n\n    @abstractmethodDOCS\n    async def touch(self, path: str, exist_ok: bool = True) -&gt; None:\n        \"\"\"Create empty file or update metadata.\"\"\"\n\n    @abstractmethodDOCS\n    async def rename(self, src: str, dst: str) -&gt; None:\n        \"\"\"Rename/move file.\"\"\"\n\n    @abstractmethodDOCS\n    async def rmdir(self, path: str) -&gt; None:\n        \"\"\"Remove directory marker.\"\"\"\n\n    @abstractmethodDOCS\n    async def symlink_to(self, path: str, target: str) -&gt; None:\n        \"\"\"Create symlink by storing target in metadata.\"\"\"\n\n    @abstractmethodDOCS\n    async def get_metadata(self, path: str) -&gt; dict[str, str]:\n        \"\"\"Get object metadata.\"\"\"\n\n    @abstractmethodDOCS\n    async def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:\n        \"\"\"Set object metadata.\"\"\"\n\n    @abstractmethodDOCS\n    async def rmtree(\n        self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None\n    ) -&gt; None:\n        \"\"\"Remove directory and all its contents recursively.\"\"\"\n\n    @abstractmethodDOCS\n    async def copy(self, src: str, dst: str, follow_symlinks: bool = True) -&gt; None:\n        \"\"\"Copy file from src to dst.\"\"\"\n\n    @abstractmethodDOCS\n    async def copytree(self, src: str, dst: str, follow_symlinks: bool = True) -&gt; None:\n        \"\"\"Copy directory tree from src to dst recursively.\"\"\"\n\n    async def __aenter__(self) -&gt; \"AsyncClient\":DOCS\n        \"\"\"Enter async context manager.\"\"\"\n        return self\n\n    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:DOCS\n        \"\"\"Exit async context manager.\"\"\"\n        await self.close()\n\n    async def read_text(self, path: str, encoding: str = \"utf-8\") -&gt; str:DOCS\n        \"\"\"Read Azure blob as text.\"\"\"\n        data = await self.read_bytes(path)\n        return data.decode(encoding)\n\n    async def write_text(self, path: str, data: str, encoding: str = \"utf-8\") -&gt; int:DOCS\n        \"\"\"Write text to Azure blob.\"\"\"\n        return await self.write_bytes(path, data.encode(encoding))\n\n    async def is_symlink(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if path is a symlink (has symlink metadata).\n\n        Args:\n            path: Cloud path\n\n        Returns:\n            True if path is a symlink\n        \"\"\"\n        try:\n            metadata = await self.get_metadata(path)\n            meta_dict: Any = metadata.get(\"metadata\", {})\n            if isinstance(meta_dict, dict):\n                return self.__class__.symlink_target_metaname in meta_dict\n            return False  # pragma: no cover\n        except Exception:\n            return False\n\n    async def readlink(self, path: str) -&gt; str:DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Args:\n            path: Cloud path\n\n        Returns:\n            Symlink target path\n        \"\"\"\n        metadata = await self.get_metadata(path)\n        meta_dict: Any = metadata.get(\"metadata\", {})\n        if not isinstance(meta_dict, dict):  # pragma: no cover\n            raise ValueError(f\"Invalid metadata format for: {path}\")\n        target: Any = meta_dict.get(self.__class__.symlink_target_metaname, None)\n        if not target or not isinstance(target, str):\n            raise ValueError(f\"Not a symlink: {path}\")\n\n        if any(target.startswith(f\"{prefix}://\") for prefix in self.__class__.prefix):\n            return str(target)\n\n        path = path.rstrip(\"/\").rsplit(\"/\", 1)[0]  # # pragma: no cover\n        return f\"{path}/{target}\"  # # pragma: no cover\n\n\nclass AsyncFileHandle(ABC):DOCS\n    \"\"\"Base class for async file handles.\n\n    This abstract base class defines the interface for async file operations\n    on cloud storage. Each cloud provider implements its own version using\n    the provider's specific streaming capabilities.\n    \"\"\"\n\n    def __init__(\n        self,\n        client_factory: Callable[[], Awaitable[Any]],\n        bucket: str,\n        blob: str,\n        prefix: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        chunk_size: int = 4096,\n        upload_warning_threshold: int = 100,\n        upload_interval: float = 1.0,\n    ):\n        \"\"\"Initialize async file handle.\n\n        Args:\n            client_factor: Async client factory for cloud operations\n            bucket: Cloud storage bucket name or container\n            blob: Cloud storage blob name or object key\n            prefix: Cloud storage path prefix\n            mode: File mode ('r', 'w', 'rb', 'wb', etc.)\n            encoding: Text encoding (for text modes)\n            chunk_size: Size of chunks to read\n            upload_warning_threshold: Number of chunk uploads before warning (default: 100)\n                -1 to disable warning\n            upload_interval: Minimum interval (in seconds) between uploads to avoid\n                rate limits (default: 1.0)\n        \"\"\"\n        self._client_factory = client_factory\n        self._client: Optional[AsyncClient] = None\n        self._bucket = bucket\n        self._blob = blob\n        self._prefix = prefix\n        self._mode = mode\n        self._encoding = encoding or \"utf-8\"\n        self._chunk_size = chunk_size\n        self._closed = False\n        self._upload_warning_threshold = upload_warning_threshold\n        self._upload_count = 0\n        self._first_write = True  # Track if this is the first write (for 'w' mode clearing)\n        self._upload_interval = upload_interval\n        self._last_upload_time: Optional[float] = None\n\n        # For write modes\n        self._write_buffer: Union[bytearray, List[str]] = bytearray() if \"b\" in mode else []\n\n        # Parse mode\n        self._is_read = \"r\" in mode\n        self._is_write = \"w\" in mode or \"a\" in mode\n        self._is_binary = \"b\" in mode\n        self._is_append = \"a\" in mode\n\n        self._stream: Any = None\n        self._read_buffer: Union[bytes, str] = b\"\" if self._is_binary else \"\"\n        self._read_pos = 0\n        self._eof = False\n\n    @classmethod\n    @abstractmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:\n        \"\"\"Check if exception indicates 'file not found'.\"\"\"\n\n    @abstractmethod\n    async def _create_stream(self) -&gt; Any:\n        \"\"\"Create and return the underlying async stream for reading.\"\"\"\n\n    @abstractmethod\n    async def _upload(self, data: Union[bytes, str]) -&gt; None:\n        \"\"\"Upload data to cloud storage (used internally).\"\"\"\n\n    async def _stream_read(self, size: int = -1) -&gt; Union[str, bytes]:\n        \"\"\"Read from stream (used internally).\"\"\"\n        if self._stream is None:  # pragma: no cover\n            raise ValueError(\"Stream not initialized\")\n        chunk = await self._stream.read(size)\n        if self._is_binary:\n            return chunk  # type: ignore\n        else:\n            return chunk.decode(self._encoding)  # type: ignore\n\n    async def flush(self) -&gt; None:DOCS\n        \"\"\"Flush write buffer to cloud storage.\n\n        After open, all flushes append to existing content using provider-native\n        append operations. The difference between 'w' and 'a' modes is that 'w'\n        clears existing content on open, while 'a' preserves it.\n        \"\"\"\n        if self._closed:  # pragma: no cover\n            raise ValueError(\"I/O operation on closed file\")\n\n        if not self._is_write:  # pragma: no cover\n            return\n\n        if not self._write_buffer and not self._first_write:\n            return\n\n        if self._is_binary:\n            data: Union[bytes, str] = bytes(self._write_buffer)  # type: ignore\n        else:\n            data = \"\".join(self._write_buffer)  # type: ignore\n\n        # Rate limiting: wait if needed to respect upload_interval\n        if self._upload_interval &gt; 0 and self._last_upload_time is not None:\n            elapsed = time.time() - self._last_upload_time\n            if elapsed &lt; self._upload_interval:\n                await asyncio.sleep(self._upload_interval - elapsed)\n\n        await self._upload(data)\n        self._last_upload_time = time.time()\n        self._write_buffer = bytearray() if self._is_binary else []\n\n        # Track upload count and warn if threshold exceeded\n        self._upload_count += 1\n        if self._upload_count == self._upload_warning_threshold:\n            warnings.warn(\n                f\"File handle has flushed {self._upload_count} times. \"\n                \"Consider using larger chunk_size or buffering writes to reduce \"\n                \"cloud API calls. Set upload_warning_threshold=-1 to suppress \"\n                \"this warning.\",\n                ResourceWarning,\n                stacklevel=2,\n            )\n\n    async def reset_stream(self) -&gt; None:DOCS\n        \"\"\"Reset the underlying stream to the beginning.\"\"\"\n        self._stream = await self._create_stream()\n        self._read_buffer = b\"\" if self._is_binary else \"\"\n        self._read_pos = 0\n        self._eof = False\n\n    async def __aenter__(self) -&gt; \"AsyncFileHandle\":DOCS\n        \"\"\"Enter async context manager.\"\"\"\n        self._client = await self._client_factory()\n\n        if self._is_read:\n            try:\n                self._stream = await self._create_stream()\n            except Exception as e:\n                if self.__class__._expception_as_filenotfound(e):\n                    raise FileNotFoundError(\n                        f\"File not found: {self._prefix}://{self._bucket}/{self._blob}\"\n                    ) from None\n                else:  # pragma: no cover\n                    raise\n        elif self._is_write and not self._is_append:\n            # 'w' mode: clear existing content - do nothing here, will create on first write\n            # The difference is that subsequent flushes will append\n            pass\n        return self\n\n    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:DOCS\n        \"\"\"Exit async context manager.\"\"\"\n        await self.close()\n        self._client = None\n\n    async def read(self, size: int = -1) -&gt; Union[str, bytes]:DOCS\n        \"\"\"Read and return up to size bytes/characters.\n\n        Args:\n            size: Number of bytes/chars to read (-1 for all)\n\n        Returns:\n            Data read from file\n        \"\"\"\n        if not self._is_read:\n            raise ValueError(\"File not opened for reading\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        # First, consume any buffered data\n        if self._read_buffer:\n            if size == -1:  # pragma: no cover\n                # Return all buffered data plus rest of stream\n                buffered = self._read_buffer\n                self._read_buffer = b\"\" if self._is_binary else \"\"\n                rest = await self._stream_read(-1)\n                self._read_pos += len(rest)\n                self._eof = True\n                result: Union[str, bytes] = buffered + rest  # type: ignore\n                return result\n            else:\n                # Return from buffer first\n                if len(self._read_buffer) &gt;= size:  # pragma: no cover\n                    result_buf: Union[str, bytes] = self._read_buffer[:size]\n                    self._read_buffer = self._read_buffer[size:]\n                    return result_buf\n                else:  # pragma: no cover\n                    # Not enough in buffer, need to read more\n                    buffered = self._read_buffer\n                    self._read_buffer = b\"\" if self._is_binary else \"\"\n                    remaining = size - len(buffered)\n                    result_chunk = await self._stream_read(remaining)\n                    if not result_chunk:\n                        self._eof = True\n                        return buffered\n                    self._read_pos += len(result_chunk)\n                    combined: Union[str, bytes] = buffered + result_chunk  # type: ignore\n                    return combined\n\n        # No buffered data, read from stream\n        if size == -1:\n            result_stream = await self._stream_read(-1)\n            self._read_pos += len(result_stream)\n            self._eof = True\n            return result_stream\n        else:\n            result_stream = await self._stream_read(size)\n            if not result_stream:  # pragma: no cover\n                self._eof = True\n                return result_stream\n\n            self._read_pos += len(result_stream)\n            return result_stream\n\n    async def readline(self, size: int = -1) -&gt; Union[str, bytes]:DOCS\n        \"\"\"Read and return one line from the file.\"\"\"\n        if not self._is_read:\n            raise ValueError(\"File not opened for reading\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        newline: Union[bytes, str] = b\"\\n\" if self._is_binary else \"\\n\"\n        # Fill buffer until we find a newline or reach EOF\n        while not self._eof:\n            if self._is_binary:  # pragma: no cover\n                bytes_buffer: bytes = self._read_buffer  # type: ignore\n                bytes_newline: bytes = newline  # type: ignore\n                if bytes_newline in bytes_buffer:\n                    break\n            else:\n                str_buffer_check: str = self._read_buffer  # type: ignore\n                str_newline: str = newline  # type: ignore\n                if str_newline in str_buffer_check:\n                    break\n\n            chunk = await self._stream_read(self._chunk_size)\n            if not chunk:\n                self._eof = True\n                break\n            self._read_pos += len(chunk)\n            buffer_tmp: Union[bytes, str] = self._read_buffer + chunk  # type: ignore\n            self._read_buffer = buffer_tmp\n\n        try:\n            end = self._read_buffer.index(newline) + 1  # type: ignore\n        except ValueError:\n            end = len(self._read_buffer)\n\n        if size != -1 and end &gt; size:\n            end = size\n\n        result_line: Union[str, bytes] = self._read_buffer[:end]\n        self._read_buffer = self._read_buffer[end:]\n        return result_line\n\n    async def readlines(self) -&gt; List[Union[str, bytes]]:DOCS\n        \"\"\"Read and return all lines from the file.\"\"\"\n        lines = []\n        while True:\n            line = await self.readline()\n            if not line:\n                break\n            lines.append(line)\n        return lines\n\n    async def write(self, data: Union[str, bytes]) -&gt; int:DOCS\n        \"\"\"Write data to the file.\"\"\"\n        if not self._is_write:\n            raise ValueError(\"File not opened for writing\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        if self._is_binary:\n            if isinstance(data, str):\n                data = data.encode(self._encoding)\n            self._write_buffer.extend(data)  # type: ignore\n        else:\n            if isinstance(data, bytes):\n                data = data.decode(self._encoding)\n            self._write_buffer.append(data)  # type: ignore\n\n        if len(self._write_buffer) &gt;= self._chunk_size:\n            await self.flush()\n\n        return len(data)\n\n    async def writelines(self, lines: List[Union[str, bytes]]) -&gt; None:DOCS\n        \"\"\"Write a list of lines to the file.\"\"\"\n        for line in lines:\n            await self.write(line)\n\n    async def close(self) -&gt; None:DOCS\n        \"\"\"Close the file and flush write buffer to cloud storage.\"\"\"\n        if self._closed:\n            return\n\n        if self._is_write and self._client:\n            await self.flush()\n\n        self._closed = True\n\n    def __aiter__(self) -&gt; \"AsyncFileHandle\":DOCS\n        \"\"\"Support async iteration over lines.\"\"\"\n        if not self._is_read:\n            raise ValueError(\"File not opened for reading\")\n        return self\n\n    async def __anext__(self) -&gt; Union[str, bytes]:DOCS\n        \"\"\"Get next line in async iteration.\"\"\"\n        line = await self.readline()\n        if not line:\n            raise StopAsyncIteration\n        return line\n\n    @propertyDOCS\n    def closed(self) -&gt; bool:\n        \"\"\"Check if file is closed.\"\"\"\n        return self._closed\n\n    async def tell(self) -&gt; int:DOCS\n        \"\"\"Return current stream position.\n\n        Returns:\n            Current position in the file\n        \"\"\"\n        if not self._is_read:\n            raise ValueError(\"tell() not supported in write mode\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        # Calculate buffer size in bytes\n        if self._is_binary:\n            buffer_byte_size = len(self._read_buffer)\n        else:\n            # In text mode, encode the buffer to get its byte size\n            str_buffer: str = self._read_buffer  # type: ignore\n            buffer_byte_size = len(str_buffer.encode(self._encoding))\n\n        return self._read_pos - buffer_byte_size\n\n    async def seek(self, offset: int, whence: int = 0) -&gt; int:DOCS\n        \"\"\"Change stream position (forward seeking only).\n\n        Args:\n            offset: Position offset\n            whence: Reference point (0=start, 1=current, 2=end)\n\n        Returns:\n            New absolute position\n\n        Raises:\n            OSError: If backward seeking is attempted\n            ValueError: If called in write mode or on closed file\n\n        Note:\n            - Only forward seeking is supported due to streaming limitations\n            - SEEK_END (whence=2) is not supported as blob size may be unknown\n            - Backward seeking requires re-opening the stream\n        \"\"\"\n        if not self._is_read:\n            raise ValueError(\"seek() not supported in write mode\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n        if whence == 2:\n            raise OSError(\"SEEK_END not supported for streaming reads\")\n\n        # Calculate target position\n        current_pos = await self.tell()\n        if whence == 0:\n            target_pos = offset\n        elif whence == 1:\n            target_pos = current_pos + offset\n        else:\n            raise ValueError(f\"Invalid whence value: {whence}\")\n\n        if target_pos == 0:\n            await self.reset_stream()\n            return 0\n\n        # Check for backward seeking\n        if target_pos &lt; current_pos:\n            raise OSError(\"Backward seeking not supported for streaming reads\")\n\n        # Forward seek: read and discard data\n        bytes_to_skip = target_pos - current_pos\n        while bytes_to_skip &gt; 0 and not self._eof:\n            chunk_size = min(bytes_to_skip, 8192)\n            chunk = await self.read(chunk_size)\n            if not chunk:  # pragma: no cover\n                break\n            if self._is_binary:\n                bytes_chunk: bytes = chunk  # type: ignore\n                bytes_to_skip -= len(bytes_chunk)\n            else:  # pragma: no cover\n                str_chunk: str = chunk  # type: ignore\n                bytes_to_skip -= len(str_chunk.encode(self._encoding))\n\n        return await self.tell()\n\n\nclass SyncFileHandle(ABC):DOCS\n    \"\"\"Base class for sync file handles.\n\n    This abstract base class defines the interface for sync file operations\n    on cloud storage. Each cloud provider implements its own version using\n    the provider's specific streaming capabilities.\n    \"\"\"\n\n    def __init__(\n        self,\n        client: Any,\n        bucket: str,\n        blob: str,\n        prefix: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        chunk_size: int = 4096,\n        upload_warning_threshold: int = 100,\n        upload_interval: float = 1.0,\n    ):\n        \"\"\"Initialize sync file handle.\n\n        Args:\n            client: Sync client for cloud operations\n            bucket: Cloud storage bucket name or container\n            blob: Cloud storage blob name or object key\n            prefix: Cloud storage path prefix\n            mode: File mode ('r', 'w', 'rb', 'wb', etc.)\n            encoding: Text encoding (for text modes)\n            chunk_size: Size of chunks to read\n            upload_warning_threshold: Number of chunk uploads before warning (default: 100)\n            upload_interval: Minimum interval (in seconds) between uploads to avoid\n                rate limits (default: 1.0)\n        \"\"\"\n        self._client = client\n        self._bucket = bucket\n        self._blob = blob\n        self._prefix = prefix\n        self._mode = mode\n        self._encoding = encoding or \"utf-8\"\n        self._chunk_size = chunk_size\n        self._closed = False\n        self._upload_warning_threshold = upload_warning_threshold\n        self._upload_count = 0\n        self._first_write = True  # Track if this is the first write (for 'w' mode clearing)\n        self._upload_interval = upload_interval\n        self._last_upload_time: Optional[float] = None\n\n        # For write modes\n        self._write_buffer: Union[bytearray, List[str]] = bytearray() if \"b\" in mode else []\n\n        # Parse mode\n        self._is_read = \"r\" in mode\n        self._is_write = \"w\" in mode or \"a\" in mode\n        self._is_binary = \"b\" in mode\n        self._is_append = \"a\" in mode\n\n        self._stream: Any = None\n        self._read_buffer: Union[bytes, str] = b\"\" if self._is_binary else \"\"\n        self._read_pos = 0\n        self._eof = False\n\n    @classmethod\n    @abstractmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:\n        \"\"\"Check if exception indicates 'file not found'.\"\"\"\n\n    @abstractmethod\n    def _create_stream(self) -&gt; Any:\n        \"\"\"Create and return the underlying async stream for reading.\"\"\"\n\n    @abstractmethod\n    def _upload(self, data: Union[bytes, str]) -&gt; None:\n        \"\"\"Upload data to cloud storage (used internally).\"\"\"\n\n    def flush(self) -&gt; None:DOCS\n        \"\"\"Flush write buffer to cloud storage.\n\n        After open, all flushes append to existing content using provider-native\n        append operations. The difference between 'w' and 'a' modes is that 'w'\n        clears existing content on open, while 'a' preserves it.\n        \"\"\"\n        if self._closed:  # pragma: no cover\n            raise ValueError(\"I/O operation on closed file\")\n\n        if not self._is_write:  # pragma: no cover\n            return\n\n        if not self._write_buffer and not self._first_write:\n            return\n\n        if self._is_binary:\n            data = bytes(self._write_buffer)  # type: ignore\n        else:\n            data = \"\".join(self._write_buffer)  # type: ignore\n\n        # Rate limiting: wait if needed to respect upload_interval\n        if self._upload_interval &gt; 0 and self._last_upload_time is not None:\n            elapsed = time.time() - self._last_upload_time\n            if elapsed &lt; self._upload_interval:\n                time.sleep(self._upload_interval - elapsed)\n\n        self._upload(data)\n        self._last_upload_time = time.time()\n        self._write_buffer = bytearray() if self._is_binary else []\n\n        # Track upload count and warn if threshold exceeded\n        self._upload_count += 1\n        if self._upload_count == self._upload_warning_threshold:\n            warnings.warn(\n                f\"File handle has flushed {self._upload_count} times. Consider using larger \"\n                f\"chunk_size or buffering writes to reduce cloud API calls. \"\n                f\"Set upload_warning_threshold=-1 to suppress this warning.\",\n                ResourceWarning,\n                stacklevel=2,\n            )\n\n    def _stream_read(self, size: int = -1) -&gt; Union[str, bytes]:\n        \"\"\"Read from stream (used internally).\"\"\"\n        # Python 3.9 compatibility: http.client.HTTPResponse.read() doesn't accept -1\n        # but google.cloud.storage.fileio.BlobReader doesn't accept None\n        # Check the stream type to determine which to use\n        if self._stream is None:  # pragma: no cover\n            raise ValueError(\"Stream not initialized\")\n        if size == -1:\n            # Check if this is a boto3/botocore stream (wraps HTTPResponse)\n            # These don't accept -1 in Python 3.9\n            stream_module = getattr(self._stream.__class__, \"__module__\", \"\")\n            if \"botocore\" in stream_module or \"urllib3\" in stream_module:\n                size = None  # type: ignore\n\n        chunk = self._stream.read(size)\n        if self._is_binary:\n            return chunk  # type: ignore\n        else:\n            return chunk.decode(self._encoding)  # type: ignore\n\n    def reset_stream(self) -&gt; None:DOCS\n        \"\"\"Reset the underlying stream to the beginning.\"\"\"\n        self._stream = self._create_stream()\n        self._read_buffer = b\"\" if self._is_binary else \"\"\n        self._read_pos = 0\n        self._eof = False\n\n    def __enter__(self) -&gt; \"SyncFileHandle\":DOCS\n        \"\"\"Enter context manager.\"\"\"\n        if self._is_read:\n            try:\n                self._stream = self._create_stream()\n            except Exception as e:\n                if self.__class__._expception_as_filenotfound(e):\n                    raise FileNotFoundError(\n                        f\"File not found: {self._prefix}://{self._bucket}/{self._blob}\"\n                    ) from None\n                else:  # pragma: no cover\n                    raise\n        elif self._is_write and not self._is_append:\n            # 'w' mode: clear existing content - do nothing here, will create on\n            # first write\n            # The difference is that subsequent flushes will append\n            pass\n        return self\n\n    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:DOCS\n        \"\"\"Exit async context manager.\"\"\"\n        self.close()\n        self._client = None\n\n    def read(self, size: int = -1) -&gt; Union[str, bytes]:DOCS\n        \"\"\"Read and return up to size bytes/characters.\n\n        Args:\n            size: Number of bytes/chars to read (-1 for all)\n\n        Returns:\n            Data read from file\n        \"\"\"\n        if not self._is_read:\n            raise ValueError(\"File not opened for reading\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        # No buffered data, read from stream\n        if size == -1:\n            result = self._stream_read(-1)\n            self._read_pos += len(result)\n            self._eof = True\n            return result\n        else:\n            result = self._stream_read(size)\n            if not result:  # pragma: no cover\n                self._eof = True\n                return result\n\n            self._read_pos += len(result)\n            return result\n\n    def readline(self, size: int = -1) -&gt; Union[str, bytes]:DOCS\n        \"\"\"Read and return one line from the file.\"\"\"\n        if not self._is_read:\n            raise ValueError(\"File not opened for reading\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        newline: Union[bytes, str] = b\"\\n\" if self._is_binary else \"\\n\"\n        # Fill buffer until we find a newline or reach EOF\n        while not self._eof:\n            if self._is_binary:  # pragma: no cover\n                bytes_buffer_sync: bytes = self._read_buffer  # type: ignore\n                bytes_newline_sync: bytes = newline  # type: ignore\n                if bytes_newline_sync in bytes_buffer_sync:\n                    break\n            else:\n                str_buffer_check_sync: str = self._read_buffer  # type: ignore\n                str_newline_sync: str = newline  # type: ignore\n                if str_newline_sync in str_buffer_check_sync:  # pragma: no cover\n                    break\n\n            chunk = self._stream_read(self._chunk_size)\n            if not chunk:  # pragma: no cover\n                self._eof = True\n                break\n            self._read_pos += len(chunk)\n            buffer_tmp: Union[bytes, str] = self._read_buffer + chunk  # type: ignore\n            self._read_buffer = buffer_tmp\n\n        try:\n            end = self._read_buffer.index(newline) + 1  # type: ignore\n        except ValueError:\n            end = len(self._read_buffer)\n\n        if size != -1 and end &gt; size:\n            end = size\n\n        result_line: Union[str, bytes] = self._read_buffer[:end]\n        self._read_buffer = self._read_buffer[end:]\n        return result_line\n\n    def readlines(self) -&gt; List[Union[str, bytes]]:DOCS\n        \"\"\"Read and return all lines from the file.\"\"\"\n        lines = []\n        while True:\n            line = self.readline()\n            if not line:\n                break\n            lines.append(line)\n        return lines\n\n    def write(self, data: Union[str, bytes]) -&gt; int:DOCS\n        \"\"\"Write data to the file.\"\"\"\n        if not self._is_write:\n            raise ValueError(\"File not opened for writing\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        if self._is_binary:\n            if isinstance(data, str):\n                data = data.encode(self._encoding)\n            self._write_buffer.extend(data)  # type: ignore\n        else:\n            if isinstance(data, bytes):\n                data = data.decode(self._encoding)\n            self._write_buffer.append(data)  # type: ignore\n\n        if len(self._write_buffer) &gt;= self._chunk_size:\n            self.flush()\n\n        return len(data)\n\n    def writelines(self, lines: List[Union[str, bytes]]) -&gt; None:DOCS\n        \"\"\"Write a list of lines to the file.\"\"\"\n        for line in lines:\n            self.write(line)\n\n    def close(self) -&gt; None:DOCS\n        \"\"\"Close the file and flush write buffer to cloud storage.\"\"\"\n        if self._closed:\n            return\n\n        if self._is_write and self._client:\n            self.flush()\n\n        self._closed = True\n\n    def __iter__(self) -&gt; \"SyncFileHandle\":DOCS\n        \"\"\"Support async iteration over lines.\"\"\"\n        if not self._is_read:\n            raise ValueError(\"File not opened for reading\")\n        return self\n\n    def __next__(self) -&gt; Union[str, bytes]:DOCS\n        \"\"\"Get next line in async iteration.\"\"\"\n        line = self.readline()\n        if not line:\n            raise StopIteration\n        return line\n\n    @propertyDOCS\n    def closed(self) -&gt; bool:\n        \"\"\"Check if file is closed.\"\"\"\n        return self._closed\n\n    def tell(self) -&gt; int:DOCS\n        \"\"\"Return current stream position.\n\n        Returns:\n            Current position in the file\n        \"\"\"\n        if not self._is_read:\n            raise ValueError(\"tell() not supported in write mode\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        # Calculate buffer size in bytes\n        if self._is_binary:\n            buffer_byte_size = len(self._read_buffer)\n        else:\n            # In text mode, encode the buffer to get its byte size\n            str_buffer_sync: str = self._read_buffer  # type: ignore\n            buffer_byte_size = len(str_buffer_sync.encode(self._encoding))\n\n        return self._read_pos - buffer_byte_size\n\n    def seek(self, offset: int, whence: int = 0) -&gt; int:DOCS\n        \"\"\"Change stream position (forward seeking only).\n\n        Args:\n            offset: Position offset\n            whence: Reference point (0=start, 1=current, 2=end)\n\n        Returns:\n            New absolute position\n\n        Raises:\n            OSError: If backward seeking is attempted\n            ValueError: If called in write mode or on closed file\n\n        Note:\n            - Only forward seeking is supported due to streaming limitations\n            - SEEK_END (whence=2) is not supported as blob size may be unknown\n            - Backward seeking requires re-opening the stream\n        \"\"\"\n        if not self._is_read:\n            raise ValueError(\"seek() not supported in write mode\")\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n        if whence == 2:\n            raise OSError(\"SEEK_END not supported for streaming reads\")\n\n        # Calculate target position\n        current_pos = self.tell()\n        if whence == 0:\n            target_pos = offset\n        elif whence == 1:\n            target_pos = current_pos + offset\n        else:\n            raise ValueError(f\"Invalid whence value: {whence}\")\n\n        if target_pos == 0:\n            self.reset_stream()\n            return 0\n\n        # Check for backward seeking\n        if target_pos &lt; current_pos:\n            raise OSError(\"Backward seeking not supported for streaming reads\")\n\n        # Forward seek: read and discard data\n        bytes_to_skip = target_pos - current_pos\n        while bytes_to_skip &gt; 0 and not self._eof:\n            chunk_size = min(bytes_to_skip, 8192)\n            chunk = self.read(chunk_size)\n            if not chunk:  # pragma: no cover\n                break\n            if self._is_binary:\n                bytes_chunk_sync: bytes = chunk  # type: ignore\n                bytes_to_skip -= len(bytes_chunk_sync)\n            else:  # pragma: no cover\n                str_chunk_sync: str = chunk  # type: ignore\n                bytes_to_skip -= len(str_chunk_sync.encode(self._encoding))\n\n        return self.tell()\n</code></pre>"},{"location":"api/source/panpath.cloud/","title":"panpath.cloud","text":""},{"location":"api/source/panpath.cloud/","title":"SOURCE CODE panpath.cloud DOCS","text":"<pre><code>\"\"\"Base classes for cloud path implementations.\"\"\"\n\nimport sys\n\nfrom abc import ABC, abstractmethod\nfrom pathlib import PurePosixPath\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    AsyncGenerator,\n    BinaryIO,\n    Iterator,\n    List,\n    Optional,\n    TextIO,\n    Tuple,\n    Union,\n)\nfrom panpath.base import PanPath\n\nif TYPE_CHECKING:\n    from pathlib import Path\n    from panpath.clients import AsyncClient, AsyncFileHandle, SyncClient\n\n\nclass CloudPath(PanPath, PurePosixPath, ABC):DOCS\n    \"\"\"Base class for cloud path implementations.\n\n    Inherits from PanPath and PurePosixPath for path operations.\n    Includes both sync and async methods (async methods prefixed with a_).\n    \"\"\"\n\n    _is_cloud_path = True  # Marker for PanPath.__new__\n    _client: Optional[\"SyncClient\"] = None\n    _default_client: Optional[\"SyncClient\"] = None\n    _async_client: Optional[\"AsyncClient\"] = None\n    _default_async_client: Optional[\"AsyncClient\"] = None\n\n    def __new__(cls, *args: Any, **kwargs: Any) -&gt; \"CloudPath\":DOCS\n        \"\"\"Create new cloud path instance.\"\"\"\n        # Extract client before passing to PurePosixPath\n        client = kwargs.pop(\"client\", None)\n        async_client = kwargs.pop(\"async_client\", None)\n        obj = PurePosixPath.__new__(cls, *args)\n        obj._client = client\n        obj._async_client = async_client\n        return obj\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize cloud path (clients already handled in __new__()).\"\"\"\n        # Remove client from kwargs if present (already handled in __new__())\n        kwargs.pop(\"client\", None)\n        kwargs.pop(\"async_client\", None)\n        # Python version compatibility for PurePosixPath.__init__():\n        # - Python 3.9-3.11: Fully initialized in __new__()\n        # - Python 3.12+: Needs __init__(*args) to set _raw_paths, _drv, etc.\n        if sys.version_info &gt;= (3, 12):\n            # Python 3.12+ requires calling __init__ with args to set internal properties\n            PurePosixPath.__init__(self, *args)  # type: ignore\n        # else: Python 3.9-3.11 don't need __init__ called (already done in __new__)\n\n    @propertyDOCS\n    def client(self) -&gt; \"SyncClient\":\n        \"\"\"Get or create the sync client for this path.\"\"\"\n        if self._client is None:  # pragma: no cover\n            if self.__class__._default_client is None:\n                self.__class__._default_client = self._create_default_client()\n            self._client = self.__class__._default_client\n        return self._client\n\n    @propertyDOCS\n    def async_client(self) -&gt; \"AsyncClient\":\n        \"\"\"Get or create the async client for this path.\"\"\"\n        if self._async_client is None:  # pragma: no cover\n            if self.__class__._default_async_client is None:\n                self.__class__._default_async_client = self._create_default_async_client()\n            self._async_client = self.__class__._default_async_client\n        return self._async_client\n\n    @classmethod\n    @abstractmethod\n    def _create_default_client(cls) -&gt; \"SyncClient\":\n        \"\"\"Create the default sync client for this path class.\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def _create_default_async_client(cls) -&gt; \"AsyncClient\":\n        \"\"\"Create the default async client for this path class.\"\"\"\n\n    def _new_cloudpath(self, path: str) -&gt; \"CloudPath\":\n        \"\"\"Create a new cloud path preserving client and type.\n\n        This is called by parent, joinpath, etc. to maintain the path type\n        and associated client.\n        \"\"\"\n        return self.__class__(path, client=self._client, async_client=self._async_client)\n\n    @propertyDOCS\n    def parent(self) -&gt; \"CloudPath\":\n        \"\"\"Return parent directory as same path type.\"\"\"\n        parent_path = PurePosixPath.parent.fget(self)  # type: ignore\n        return self._new_cloudpath(str(parent_path))\n\n    def __truediv__(self, other: Any) -&gt; \"CloudPath\":DOCS\n        \"\"\"Join paths while preserving type and client.\"\"\"\n        result = PurePosixPath.__truediv__(self, other)\n        return self._new_cloudpath(str(result))\n\n    def __rtruediv__(self, other: Any) -&gt; \"CloudPath\":DOCS\n        \"\"\"Right join paths while preserving type and client.\"\"\"\n        result = PurePosixPath.__rtruediv__(self, other)\n        return self._new_cloudpath(str(result))\n\n    def joinpath(self, *args: Any) -&gt; \"CloudPath\":DOCS\n        \"\"\"Join paths while preserving type and client.\"\"\"\n        result = PurePosixPath.joinpath(self, *args)\n        return self._new_cloudpath(str(result))\n\n    def __str__(self) -&gt; str:DOCS\n        \"\"\"Return properly formatted cloud URI with double slash.\"\"\"\n        parts = self.parts\n        if len(parts) &gt;= 2:\n            scheme = parts[0].rstrip(\":\")\n            bucket = parts[1]\n            if len(parts) &gt; 2:\n                key = \"/\".join(parts[2:])\n                return f\"{scheme}://{bucket}/{key}\"\n            else:\n                return f\"{scheme}://{bucket}\"\n        return PurePosixPath.__str__(self)  # pragma: no cover\n\n    @propertyDOCS\n    def cloud_prefix(self) -&gt; str:\n        \"\"\"Return the cloud prefix (e.g., 's3://bucket').\"\"\"\n        parts = self.parts\n        if len(parts) &gt;= 2:\n            # parts[0] is 's3:', parts[1] is 'bucket'\n            scheme = parts[0].rstrip(\":\")\n            bucket = parts[1]\n            return f\"{scheme}://{bucket}\"\n        return \"\"  # pragma: no cover\n\n    @propertyDOCS\n    def key(self) -&gt; str:\n        \"\"\"Return the key/blob name without the cloud prefix.\"\"\"\n        parts = self.parts\n        if len(parts) &gt;= 3:\n            # Join all parts after scheme and bucket\n            return \"/\".join(parts[2:])\n        return \"\"\n\n    # Cloud storage operations delegated to client\n    def exists(self) -&gt; bool:DOCS\n        \"\"\"Check if path exists.\"\"\"\n        return self.client.exists(str(self))\n\n    def read_bytes(self) -&gt; bytes:DOCS\n        \"\"\"Read file as bytes.\"\"\"\n        return self.client.read_bytes(str(self))\n\n    def read_text(self, encoding: str = \"utf-8\") -&gt; str:  # type: ignore[override]DOCS\n        \"\"\"Read file as text.\"\"\"\n        return self.client.read_text(str(self), encoding=encoding)\n\n    def write_bytes(self, data: bytes) -&gt; None:  # type: ignore[override]DOCS\n        \"\"\"Write bytes to file.\"\"\"\n        self.client.write_bytes(str(self), data)\n\n    def write_text(self, data: str, encoding: str = \"utf-8\") -&gt; None:  # type: ignore[override]DOCS\n        \"\"\"Write text to file.\"\"\"\n        self.client.write_text(str(self), data, encoding=encoding)\n\n    def unlink(self, missing_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Delete file.\"\"\"\n        try:\n            self.client.delete(str(self))\n        except FileNotFoundError:  # pragma: no cover\n            if not missing_ok:\n                raise\n\n    def iterdir(self) -&gt; Iterator[\"CloudPath\"]:  # type: ignore[override]DOCS\n        \"\"\"Iterate over directory contents.\"\"\"\n        for item in self.client.list_dir(str(self)):\n            yield self._new_cloudpath(item)\n\n    def is_dir(self) -&gt; bool:DOCS\n        \"\"\"Check if path is a directory.\"\"\"\n        return self.client.is_dir(str(self))\n\n    def is_file(self) -&gt; bool:DOCS\n        \"\"\"Check if path is a file.\"\"\"\n        return self.client.is_file(str(self))\n\n    def stat(self, follow_symlinks: bool = True) -&gt; Any:DOCS\n        \"\"\"Get file stats.\"\"\"\n        if follow_symlinks and self.is_symlink():\n            target = self.readlink()\n            return target.stat()\n\n        return self.client.stat(str(self))\n\n    def mkdir(self, mode: int = 0o777, parents: bool = False, exist_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Create a directory marker in cloud storage.\n\n        In cloud storage (S3, GCS, Azure), directories are implicit. This method\n        creates an empty object with a trailing slash to serve as a directory marker.\n\n        Args:\n            mode: Ignored (for compatibility with pathlib)\n            parents: If True, create parent directories as needed\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        self.client.mkdir(str(self), parents=parents, exist_ok=exist_ok)\n\n    def open(  # type: ignore[override]DOCS\n        self,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; Union[BinaryIO, TextIO]:\n        \"\"\"Open file for reading/writing.\"\"\"\n        return self.client.open(\n            str(self),\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )  # type: ignore[return-value]\n\n    def __eq__(self, other: Any) -&gt; bool:DOCS\n        \"\"\"Check equality.\"\"\"\n        return super().__eq__(other)\n\n    def __hash__(self) -&gt; int:DOCS\n        \"\"\"Return hash of path.\"\"\"\n        return super().__hash__()\n\n    def absolute(self) -&gt; \"CloudPath\":DOCS\n        \"\"\"Return absolute path - cloud paths are already absolute.\"\"\"\n        return self\n\n    def is_absolute(self) -&gt; bool:DOCS\n        \"\"\"Cloud paths are always absolute.\"\"\"\n        return True\n\n    def as_uri(self) -&gt; str:DOCS\n        \"\"\"Return the path as a URI (same as string representation).\"\"\"\n        return str(self)\n\n    def match(self, pattern: str) -&gt; bool:DOCS\n        \"\"\"Match path against glob pattern.\n\n        Override to work correctly with cloud URIs by matching against\n        the key portion of the path (excluding scheme and bucket).\n        \"\"\"\n        from pathlib import PurePosixPath\n\n        # For cloud paths, we want to match against the key part only (path after bucket)\n        # Get the key portion (all parts after scheme and bucket)\n        our_parts = self.parts[2:] if len(self.parts) &gt; 2 else ()\n\n        # If no key parts, can only match empty patterns\n        if not our_parts:  # pragma: no cover\n            return pattern in (\"\", \"*\", \"**\")\n\n        # Create a PurePosixPath from the key parts to do matching\n        key_path = PurePosixPath(*our_parts)\n\n        # Use PurePosixPath's match which handles ** correctly\n        return key_path.match(pattern)\n\n    def glob(self, pattern: str) -&gt; Iterator[\"CloudPath\"]:  # type: ignore[override]DOCS\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            pattern: Pattern to match (e.g., \"*.txt\", \"**/*.py\")\n\n        Returns:\n            List of matching paths\n        \"\"\"\n        for p in self.client.glob(str(self), pattern):\n            yield self._new_cloudpath(p)\n\n    def rglob(self, pattern: str) -&gt; Iterator[\"CloudPath\"]:  # type: ignore[override]DOCS\n        \"\"\"Recursively glob for files matching pattern.\n\n        Args:\n            pattern: Pattern to match (e.g., \"*.txt\", \"*.py\")\n\n        Returns:\n            List of matching paths (recursive)\n        \"\"\"\n        yield from self.glob(f\"**/{pattern}\")\n\n    def walk(self) -&gt; Iterator[Tuple[\"CloudPath\", List[str], List[str]]]:DOCS\n        \"\"\"Walk directory tree (like os.walk).\n\n        Returns:\n            List of (dirpath, dirnames, filenames) tuples\n        \"\"\"\n        for d, subdirs, files in self.client.walk(str(self)):\n            yield self._new_cloudpath(d), subdirs, files\n\n    def touch(self, exist_ok: bool = True) -&gt; None:  # type: ignore[override]DOCS\n        \"\"\"Create empty file.\n\n        Args:\n            exist_ok: If False, raise error if file exists\n        \"\"\"\n        self.client.touch(str(self), exist_ok=exist_ok)\n\n    def rename(self, target: Union[str, \"CloudPath\"]) -&gt; \"CloudPath\":  # type: ignore[override]DOCS\n        \"\"\"Rename/move file to target.\n\n        Can move between cloud and local paths.\n\n        Args:\n            target: New path (can be cloud or local)\n\n        Returns:\n            New path instance\n        \"\"\"\n        target_str = str(target)\n        # Check if cross-storage operation (cloud &lt;-&gt; local or cloud &lt;-&gt; cloud)\n        if self._is_cross_storage_op(str(self), target_str):  # pragma: no cover\n            if self.is_dir():\n                self._copytree_cross_storage(str(self), target_str)\n                self.rmtree()\n            else:\n                self._copy_cross_storage(str(self), target_str)\n                self.unlink()\n        else:\n            # Same storage, use native rename\n            self.client.rename(str(self), target_str)\n\n        return PanPath(target_str)  # type: ignore\n\n    def replace(self, target: Union[str, \"CloudPath\"]) -&gt; \"CloudPath\":  # type: ignore[override]DOCS\n        \"\"\"Replace file at target (overwriting if exists).\n\n        Args:\n            target: Target path\n\n        Returns:\n            New path instance\n        \"\"\"\n        # For cloud storage, replace is same as rename (always overwrites)\n        return self.rename(target)\n\n    def rmdir(self) -&gt; None:DOCS\n        \"\"\"Remove empty directory marker.\"\"\"\n        self.client.rmdir(str(self))\n\n    def resolve(self) -&gt; \"CloudPath\":  # type: ignore[override]DOCS\n        \"\"\"Resolve to absolute path (no-op for cloud paths).\n\n        Returns:\n            Self (cloud paths are already absolute)\n        \"\"\"\n        return self.readlink() if self.is_symlink() else self\n\n    def samefile(self, other: Union[str, \"CloudPath\"]) -&gt; bool:  # type: ignore[override]DOCS\n        \"\"\"Check if this path refers to same file as other.\n\n        Args:\n            other: Path to compare\n\n        Returns:\n            True if paths are the same\n        \"\"\"\n        return str(self) == str(other)\n\n    def is_symlink(self) -&gt; bool:DOCS\n        \"\"\"Check if this is a symbolic link (via metadata).\n\n        Returns:\n            True if symlink metadata exists\n        \"\"\"\n        return self.client.is_symlink(str(self))\n\n    def readlink(self) -&gt; \"CloudPath\":DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Returns:\n            Path that this symlink points to\n        \"\"\"\n        target = self.client.readlink(str(self))\n\n        return PanPath(  # type: ignore\n            target,\n            client=self._client,\n            async_client=self._async_client,\n        )\n\n    def symlink_to(self, target: Union[str, \"CloudPath\"]) -&gt; None:  # type: ignore[override]DOCS\n        \"\"\"Create symlink pointing to target (via metadata).\n\n        Args:\n            target: Path this symlink should point to (absolute with scheme or relative)\n        \"\"\"\n        target_str = str(target)\n        # If target doesn't have a scheme prefix, treat as relative path\n        if \"://\" not in target_str:  # pragma: no cover\n            # Resolve relative to symlink's parent directory\n            target_str = str(self.parent / target_str)\n        self.client.symlink_to(str(self), target_str)\n\n    def rmtree(self, ignore_errors: bool = False, onerror: Optional[Any] = None) -&gt; None:DOCS\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        self.client.rmtree(str(self), ignore_errors=ignore_errors, onerror=onerror)\n\n    def copy(self, target: Union[str, \"CloudPath\"], follow_symlinks: bool = True) -&gt; \"CloudPath\":DOCS\n        \"\"\"Copy file to target.\n\n        Can copy between cloud and local paths.\n\n        Args:\n            target: Destination path (can be cloud or local)\n\n        Returns:\n            Target path instance\n        \"\"\"\n        if follow_symlinks and self.is_symlink():  # pragma: no cover\n            # If following symlinks, read the target and copy that instead\n            real_path = self.readlink()\n            return real_path.copy(target, follow_symlinks=False)\n\n        target_str = str(target)\n        # Check if cross-storage operation\n        if self._is_cross_storage_op(str(self), target_str):  # pragma: no cover\n            self._copy_cross_storage(str(self), target_str)\n        else:\n            # Same storage, use native copy\n            self.client.copy(str(self), target_str)\n\n        return PanPath(target_str)  # type: ignore\n\n    def copytree(DOCS\n        self, target: Union[str, \"CloudPath\"], follow_symlinks: bool = True\n    ) -&gt; \"CloudPath\":\n        \"\"\"Copy directory tree to target recursively.\n\n        Can copy between cloud and local paths.\n\n        Args:\n            target: Destination path (can be cloud or local)\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n\n        Returns:\n            Target path instance\n        \"\"\"\n        target_str = str(target)\n        # Check if cross-storage operation\n        if self._is_cross_storage_op(str(self), target_str):  # pragma: no cover\n            self._copytree_cross_storage(str(self), target_str, follow_symlinks=follow_symlinks)\n        else:\n            # Same storage, use native copytree\n            self.client.copytree(str(self), target_str, follow_symlinks=follow_symlinks)\n\n        return PanPath(target_str)  # type: ignore\n\n    @staticmethod\n    def _is_cross_storage_op(src: str, dst: str) -&gt; bool:\n        \"\"\"Check if operation crosses storage boundaries.\"\"\"\n        src_scheme = src.split(\"://\")[0] if \"://\" in src else \"file\"\n        dst_scheme = dst.split(\"://\")[0] if \"://\" in dst else \"file\"\n        return src_scheme != dst_scheme\n\n    @staticmethod\n    def _copy_cross_storage(\n        src: str,\n        dst: str,\n        follow_symlinks: bool = True,\n        chunk_size: int = 1024 * 1024,\n    ) -&gt; None:  # pragma: no cover\n        \"\"\"Copy file across storage boundaries.\n\n        Args:\n            src: Source path\n            dst: Destination path\n            follow_symlinks: If False, copy symlink as symlink\n            chunk_size: Size of chunks to read/write (for large files)\n        \"\"\"\n        src_path = PanPath(src)\n        dst_path = PanPath(dst)\n\n        if follow_symlinks and src_path.is_symlink():\n            # If following symlinks, read the target and copy that instead\n            src_path = src_path.readlink()\n\n        with src_path.open(\"rb\") as src_file, dst_path.open(\"wb\") as dst_file:\n            while True:\n                chunk = src_file.read(chunk_size)\n                if not chunk:\n                    break\n                dst_file.write(chunk)\n\n    @staticmethod\n    def _copytree_cross_storage(\n        src: str,\n        dst: str,\n        follow_symlinks: bool = True,\n        chunk_size: int = 1024 * 1024,\n    ) -&gt; None:  # pragma: no cover\n        \"\"\"Copy directory tree across storage boundaries.\n\n        Args:\n            src: Source directory path\n            dst: Destination directory path\n            follow_symlinks: If False, copy symlinks as symlinks\n            chunk_size: Size of chunks to read/write (for large files)\n        \"\"\"\n        src_path = PanPath(src)\n        dst_path = PanPath(dst)\n\n        # Create destination directory\n        dst_path.mkdir(parents=True, exist_ok=True)\n\n        # Walk source tree and copy all files\n        for dirpath, dirnames, filenames in src_path.walk():  # type: ignore[attr-defined]\n            # Calculate relative path from src\n            rel_dir = str(dirpath)[len(str(src)) :].lstrip(\"/\")\n\n            # Create subdirectories in destination\n            for dirname in dirnames:\n                dst_subdir = dst_path / rel_dir / dirname if rel_dir else dst_path / dirname\n                dst_subdir.mkdir(parents=True, exist_ok=True)\n\n            # Copy files\n            for filename in filenames:\n                src_file = dirpath / filename\n                dst_file = dst_path / rel_dir / filename if rel_dir else dst_path / filename\n                CloudPath._copy_cross_storage(\n                    str(src_file),\n                    str(dst_file),\n                    follow_symlinks=follow_symlinks,\n                    chunk_size=chunk_size,\n                )\n\n    # Async methods (prefixed with a_)\n    async def a_exists(self) -&gt; bool:DOCS\n        \"\"\"Check if path exists.\"\"\"\n        return await self.async_client.exists(str(self))\n\n    async def a_read_bytes(self) -&gt; bytes:DOCS\n        \"\"\"Read file as bytes.\"\"\"\n        return await self.async_client.read_bytes(str(self))\n\n    async def a_read_text(self, encoding: str = \"utf-8\") -&gt; str:DOCS\n        \"\"\"Read file as text.\"\"\"\n        return await self.async_client.read_text(str(self), encoding=encoding)\n\n    async def a_write_bytes(DOCS\n        self,\n        data: bytes,\n    ) -&gt; None:\n        \"\"\"Write bytes to file.\"\"\"\n        await self.async_client.write_bytes(str(self), data)\n\n    async def a_write_text(self, data: str, encoding: str = \"utf-8\") -&gt; int:DOCS\n        \"\"\"Write text to file.\"\"\"\n        return await self.async_client.write_text(str(self), data, encoding=encoding)\n\n    async def a_unlink(self, missing_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Delete file.\"\"\"\n        try:\n            await self.async_client.delete(str(self))\n        except FileNotFoundError:\n            if not missing_ok:\n                raise\n\n    async def a_iterdir(  # type: ignore[override]DOCS\n        self,\n    ) -&gt; AsyncGenerator[\"CloudPath\", None]:\n        \"\"\"List directory contents (async version returns list).\"\"\"\n        for item in await self.async_client.list_dir(str(self)):\n            yield self._new_cloudpath(item)\n\n    async def a_is_dir(self) -&gt; bool:DOCS\n        \"\"\"Check if path is a directory.\"\"\"\n        return await self.async_client.is_dir(str(self))\n\n    async def a_is_file(self) -&gt; bool:DOCS\n        \"\"\"Check if path is a file.\"\"\"\n        return await self.async_client.is_file(str(self))\n\n    async def a_stat(self, follow_symlinks: bool = True) -&gt; Any:DOCS\n        \"\"\"Get file stats.\"\"\"\n        if follow_symlinks and await self.a_is_symlink():\n            target = await self.a_readlink()\n            return await target.a_stat()\n\n        return await self.async_client.stat(str(self))\n\n    async def a_mkdir(DOCS\n        self,\n        mode: int = 0o777,\n        parents: bool = False,\n        exist_ok: bool = False,\n    ) -&gt; None:\n        \"\"\"Create a directory marker in cloud storage.\n\n        In cloud storage (S3, GCS, Azure), directories are implicit. This method\n        creates an empty object with a trailing slash to serve as a directory marker.\n\n        Args:\n            mode: Ignored (for compatibility with pathlib)\n            parents: If True, create parent directories as needed\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        await self.async_client.mkdir(str(self), parents=parents, exist_ok=exist_ok)\n\n    async def a_glob(  # type: ignore[override]DOCS\n        self,\n        pattern: str,\n    ) -&gt; AsyncGenerator[\"CloudPath\", None]:\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            pattern: Pattern to match (e.g., \"*.txt\", \"**/*.py\")\n\n        Returns:\n            List of matching paths\n        \"\"\"\n        async for p in self.async_client.glob(str(self), pattern):  # type: ignore[attr-defined]\n            yield self._new_cloudpath(p)\n\n    async def a_rglob(  # type: ignore[override]DOCS\n        self,\n        pattern: str,\n    ) -&gt; AsyncGenerator[\"CloudPath\", None]:\n        \"\"\"Recursively glob for files matching pattern.\n\n        Args:\n            pattern: Pattern to match (e.g., \"*.txt\", \"*.py\")\n\n        Returns:\n            List of matching paths (recursive)\n        \"\"\"\n        async for p in self.a_glob(f\"**/{pattern}\"):\n            yield p\n\n    async def a_walk(  # type: ignore[override]DOCS\n        self,\n    ) -&gt; AsyncGenerator[Tuple[\"CloudPath\", List[str], List[str]], None]:\n        \"\"\"Walk directory tree (like os.walk).\n\n        Returns:\n            List of (dirpath, dirnames, filenames) tuples\n        \"\"\"\n        async for d, subdirs, files in self.async_client.walk(  # type: ignore[attr-defined]\n            str(self)\n        ):\n            yield self._new_cloudpath(d), subdirs, files\n\n    async def a_touch(DOCS\n        self,\n        mode: int = 0o666,\n        exist_ok: bool = True,\n    ) -&gt; None:\n        \"\"\"Create empty file.\n\n        Args:\n            exist_ok: If False, raise error if file exists\n        \"\"\"\n        await self.async_client.touch(str(self), exist_ok=exist_ok)\n\n    async def a_rename(  # type: ignore[override]DOCS\n        self,\n        target: Union[str, \"CloudPath\"],\n    ) -&gt; \"CloudPath\":\n        \"\"\"Rename/move file to target.\n\n        Can move between cloud and local paths.\n\n        Args:\n            target: New path (can be cloud or local)\n\n        Returns:\n            New path instance\n        \"\"\"\n        if not await self.a_exists():\n            raise FileNotFoundError(f\"Source path does not exist: {self}\")\n\n        target_str = str(target)\n        if not isinstance(target, PanPath):  # pragma: no cover\n            target = PanPath(target_str)  # type: ignore[assignment]\n\n        source_is_dir = await self.a_is_dir()\n        target_is_dir = await target.a_is_dir()  # type: ignore[union-attr]\n        target_exists = await target.a_exists()  # type: ignore[union-attr]\n        if source_is_dir and not target_is_dir and target_exists:\n            raise NotADirectoryError(\n                f\"Cannot rename directory {self} to non-directory target {target}\"\n            )\n        if not source_is_dir and target_is_dir and target_exists:\n            raise IsADirectoryError(f\"Cannot rename file {self} to directory target {target}\")\n\n        if source_is_dir:\n            if not target_exists:\n                await target.a_mkdir(  # type: ignore[union-attr]\n                    parents=True,\n                    exist_ok=True,\n                )\n\n            # Support renaming directories by copying contents\n            async for item in self.a_iterdir():\n                relative_path = item.relative_to(self)\n                new_target = target / relative_path\n                await item.a_rename(new_target)\n            await self.a_rmdir()\n            return target  # type: ignore[return-value]\n\n        # Check if cross-storage operation\n        if CloudPath._is_cross_storage_op(str(self), target_str):  # pragma: no cover\n            # Copy then delete for cross-storage\n            await self._a_copy_cross_storage(str(self), target_str)\n            await self.a_unlink()\n        else:\n            # Same storage, use native rename\n            await self.async_client.rename(str(self), target_str)\n\n        return PanPath(target_str)  # type: ignore\n\n    async def a_replace(  # type: ignore[override]DOCS\n        self,\n        target: Union[str, \"CloudPath\"],\n    ) -&gt; \"CloudPath\":\n        \"\"\"Replace file at target (overwriting if exists).\n\n        Args:\n            target: Target path\n\n        Returns:\n            New path instance\n        \"\"\"\n        # For cloud storage, replace is same as rename (always overwrites)\n        return await self.a_rename(target)\n\n    async def a_resolve(self) -&gt; \"PanPath\":DOCS\n        \"\"\"Resolve to absolute path (no-op for cloud paths).\n\n        Returns:\n            Self (cloud paths are already absolute)\n        \"\"\"\n        return await self.a_readlink() if await self.a_is_symlink() else self\n\n    async def a_rmdir(self) -&gt; None:DOCS\n        \"\"\"Remove empty directory marker.\"\"\"\n        await self.async_client.rmdir(str(self))\n\n    async def a_is_symlink(self) -&gt; bool:DOCS\n        \"\"\"Check if this is a symbolic link (via metadata).\n\n        Returns:\n            True if symlink metadata exists\n        \"\"\"\n        return await self.async_client.is_symlink(str(self))\n\n    async def a_readlink(self) -&gt; \"CloudPath\":DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Returns:\n            Path that this symlink points to\n        \"\"\"\n        target = await self.async_client.readlink(str(self))\n\n        return PanPath(  # type: ignore\n            target,\n            client=self._client,\n            async_client=self._async_client,\n        )\n\n    async def a_symlink_to(  # type: ignore[override]DOCS\n        self,\n        target: Union[str, \"CloudPath\"],\n        target_is_directory: bool = False,\n    ) -&gt; None:\n        \"\"\"Create symlink pointing to target (via metadata).\n\n        Args:\n            target: Path this symlink should point to (absolute with scheme or relative)\n            target_is_directory: Ignored (for compatibility with pathlib)\n        \"\"\"\n        target_str = str(target)\n        # If target doesn't have a scheme prefix, treat as relative path\n        if \"://\" not in target_str:  # pragma: no cover\n            # Resolve relative to symlink's parent directory\n            target_str = str(self.parent / target_str)\n        await self.async_client.symlink_to(str(self), target_str)\n\n    async def a_rmtree(self, ignore_errors: bool = False, onerror: Optional[Any] = None) -&gt; None:DOCS\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        await self.async_client.rmtree(str(self), ignore_errors=ignore_errors, onerror=onerror)\n\n    async def a_copy(self, target: Union[str, \"Path\"], follow_symlinks: bool = True) -&gt; \"PanPath\":DOCS\n        \"\"\"Copy file to target.\n\n        Can copy between cloud and local paths.\n\n        Args:\n            target: Destination path (can be cloud or local)\n\n        Returns:\n            Target path instance\n        \"\"\"\n        target_str = str(target)\n        # Check if cross-storage operation\n        if CloudPath._is_cross_storage_op(str(self), target_str):  # pragma: no cover\n            await self._a_copy_cross_storage(str(self), target_str, follow_symlinks=follow_symlinks)\n        else:\n            # Same storage, use native copy\n            await self.async_client.copy(str(self), target_str, follow_symlinks=follow_symlinks)\n\n        return PanPath(target_str)\n\n    async def a_copytree(DOCS\n        self,\n        target: Union[str, \"Path\"],\n        follow_symlinks: bool = True,\n    ) -&gt; \"CloudPath\":\n        \"\"\"Copy directory tree to target recursively.\n\n        Can copy between cloud and local paths.\n\n        Args:\n            target: Destination path (can be cloud or local)\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n\n        Returns:\n            Target path instance\n        \"\"\"\n        target_str = str(target)\n        # Check if cross-storage operation\n        if CloudPath._is_cross_storage_op(str(self), target_str):  # pragma: no cover\n            await self._a_copytree_cross_storage(\n                str(self), target_str, follow_symlinks=follow_symlinks\n            )\n        else:\n            # Same storage, use native copytree\n            await self.async_client.copytree(str(self), target_str, follow_symlinks=follow_symlinks)\n\n        return PanPath(target_str)  # type: ignore\n\n    @staticmethod\n    async def _a_copy_cross_storage(\n        src: str,\n        dst: str,\n        follow_symlinks: bool = True,\n        chunk_size: int = 1024 * 1024,\n    ) -&gt; None:\n        \"\"\"Copy file across storage boundaries (async).\n\n        Args:\n            src: Source path\n            dst: Destination path\n            follow_symlinks: If False, copy symlinks as symlinks\n            chunk_size: Size of chunks to read/write (default 1MB)\n        \"\"\"\n        src_path = PanPath(src)\n        dst_path = PanPath(dst)\n\n        if follow_symlinks and await src_path.a_is_symlink():  # pragma: no cover\n            # If following symlinks, read the target and copy that instead\n            src_path = await src_path.a_readlink()\n\n        async with src_path.a_open(\"rb\") as fsrc:\n            async with dst_path.a_open(\"wb\") as fdst:\n                while True:\n                    buf = await fsrc.read(chunk_size)  # Read in 1MB chunks\n                    if not buf:\n                        break\n                    await fdst.write(buf)\n\n    @staticmethod\n    async def _a_copytree_cross_storage(\n        src: str,\n        dst: str,\n        follow_symlinks: bool = True,\n        chunk_size: int = 1024 * 1024,\n    ) -&gt; None:\n        \"\"\"Copy directory tree across storage boundaries (async).\n\n        Args:\n            src: Source path\n            dst: Destination path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n            chunk_size: Size of chunks to read/write (default 1MB)\n        \"\"\"\n        src_path = PanPath(src)\n        dst_path = PanPath(dst)\n\n        # Create destination directory\n        await dst_path.a_mkdir(parents=True, exist_ok=True)\n\n        # Walk source tree and copy all files\n        async for dirpath, dirnames, filenames in src_path.a_walk():  # type: ignore[attr-defined]\n            # Calculate relative path from src\n            rel_dir = str(dirpath)[len(str(src)) :].lstrip(\"/\")\n\n            # Create subdirectories in destination\n            for dirname in dirnames:\n                dst_subdir = dst_path / rel_dir / dirname if rel_dir else dst_path / dirname\n                await dst_subdir.a_mkdir(parents=True, exist_ok=True)\n\n            # Copy files\n            for filename in filenames:\n                src_file = dirpath / filename\n                dst_file = dst_path / rel_dir / filename if rel_dir else dst_path / filename\n                await CloudPath._a_copy_cross_storage(\n                    str(src_file),\n                    str(dst_file),\n                    follow_symlinks=follow_symlinks,\n                    chunk_size=chunk_size,\n                )\n\n    def a_open(DOCS\n        self,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; \"AsyncFileHandle\":\n        \"\"\"Open file and return async file handle.\n\n        Args:\n            mode: File mode (e.g., 'r', 'w', 'rb', 'wb')\n            encoding: Text encoding (for text modes)\n            **kwargs: Additional arguments passed to the async client\n\n        Returns:\n            Async file handle from the async client\n        \"\"\"\n        return self.async_client.open(\n            str(self),\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )  # type: ignore[return-value]\n</code></pre>"},{"location":"api/source/panpath.exceptions/","title":"panpath.exceptions","text":""},{"location":"api/source/panpath.exceptions/","title":"SOURCE CODE panpath.exceptions DOCS","text":"<pre><code>\"\"\"Exception classes for panpath.\"\"\"\n\n\nclass PanPathError(Exception):DOCS\n    \"\"\"Base exception for panpath errors.\"\"\"\n\n    pass\n\n\nclass MissingDependencyError(PanPathError, ImportError):DOCS\n    \"\"\"Raised when a required dependency is not installed.\"\"\"\n\n    def __init__(self, backend: str, package: str, extra: str):\n        self.backend = backend\n        self.package = package\n        self.extra = extra\n        super().__init__(\n            f\"The {backend} backend requires '{package}' which is not installed. \"\n            f\"Install it with: pip install panpath[{extra}]\"\n        )\n\n\nclass CloudPathError(PanPathError):DOCS\n    \"\"\"Base exception for cloud path errors.\"\"\"\n\n    pass\n\n\nclass NoStatError(CloudPathError):DOCS\n    \"\"\"Raised when stat information cannot be retrieved.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/source/panpath.gs_async_client/","title":"panpath.gs_async_client","text":""},{"location":"api/source/panpath.gs_async_client/","title":"SOURCE CODE panpath.gs_async_client DOCS","text":"<pre><code>\"\"\"Async Google Cloud Storage client implementation.\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport datetime\nimport weakref\nimport os\nimport sys\nfrom typing import TYPE_CHECKING, Any, AsyncGenerator, Optional, Set, Union\n\nfrom panpath.clients import AsyncClient, AsyncFileHandle\nfrom panpath.exceptions import MissingDependencyError, NoStatError\n\nif TYPE_CHECKING:\n    from gcloud.aio.storage import Storage\n\ntry:\n    # Monkey-patch SCOPES before importing Storage\n    # Must patch the actual storage module, not the package __init__\n    import gcloud.aio.storage.storage as _storage_module\n\n    _storage_module.SCOPES = [\n        # We need full control to update metadata\n        \"https://www.googleapis.com/auth/devstorage.full_control\",\n    ]\n\n    from gcloud.aio.storage import Storage\n\n    HAS_GCLOUD_AIO = True\nexcept ImportError:\n    HAS_GCLOUD_AIO = False\n\n\n# Track all active storage instances for cleanup\n_active_clients: Set[weakref.ref] = set()  # type: ignore[type-arg]\n\n\nasync def _async_cleanup_all_clients() -&gt; None:\n    \"\"\"Async cleanup of all active storage instances.\"\"\"\n    # Create a copy of the set to avoid modification during iteration\n    clients_to_clean = list(_active_clients)\n\n    for client_ref in clients_to_clean:\n        storage = client_ref()\n        if storage is None:  # pragma: no cover\n            continue\n\n        try:\n            await storage.close()\n        except Exception:  # pragma: no cover\n            # Ignore errors during cleanup\n            pass\n\n    _active_clients.clear()\n\n\ndef _register_loop_cleanup(loop: asyncio.AbstractEventLoop) -&gt; None:\n    \"\"\"Register cleanup to run before loop closes.\"\"\"\n    # Get the original shutdown_asyncgens method\n    original_shutdown = loop.shutdown_asyncgens\n\n    async def shutdown_with_cleanup():  # type: ignore[no-untyped-def]\n        \"\"\"Shutdown that includes storage cleanup.\"\"\"\n        # Clean up storages first\n        await _async_cleanup_all_clients()\n        # Then run original shutdown\n        await original_shutdown()\n\n    # Replace with our version\n    loop.shutdown_asyncgens = shutdown_with_cleanup  # type: ignore[method-assign]\n\n\nclass AsyncGSClient(AsyncClient):DOCS\n    \"\"\"Asynchronous Google Cloud Storage client implementation.\"\"\"\n\n    prefix = (\"gs\",)\n    symlink_target_metaname = \"gcsfuse_symlink_target\"\n\n    def __init__(self, **kwargs: Any):\n        \"\"\"Initialize async GCS client.\n\n        Args:\n            **kwargs: Additional arguments\n        \"\"\"\n        if not HAS_GCLOUD_AIO:\n            raise MissingDependencyError(\n                backend=\"async Google Cloud Storage\",\n                package=\"gcloud-aio-storage\",\n                extra=\"async-gs\",\n            )\n        self._client: Optional[Storage] = None\n        self._kwargs = kwargs\n        self._client_ref: Optional[weakref.ref] = None  # type: ignore[type-arg]\n\n    async def _get_client(self) -&gt; Storage:\n        \"\"\"Get or create shared storage client for the AsyncGSClient.\"\"\"\n        # Check if storage needs to be recreated (closed or never created)\n        needs_recreation = False\n        if self._client is None:\n            needs_recreation = True\n        else:\n            # Check if the underlying aiohttp session is closed\n            try:\n                if self._client.session.session.closed:\n                    needs_recreation = True\n                    # Clean up the old storage reference\n                    if self._client_ref is not None:\n                        _active_clients.discard(self._client_ref)\n                        self._client_ref = None\n                    self._client = None\n            except (AttributeError, RuntimeError):  # pragma: no cover\n                # If we can't check the session state, recreate to be safe\n                needs_recreation = True\n                self._client = None\n\n        if needs_recreation:\n            self._client = Storage(**self._kwargs)\n            # Track this storage instance for cleanup\n            self._client_ref = weakref.ref(self._client, self._on_client_deleted)\n            _active_clients.add(self._client_ref)\n\n            # Register cleanup with the current event loop\n            try:\n                loop = asyncio.get_running_loop()\n                # Check if we've already patched this loop\n                if not hasattr(loop, \"_panpath_gs_cleanup_registered\"):\n                    _register_loop_cleanup(loop)\n                    loop._panpath_gs_cleanup_registered = True  # type: ignore\n            except RuntimeError:  # pragma: no cover\n                # No running loop, cleanup will be handled by explicit close\n                pass\n\n        return self._client  # type: ignore[return-value]\n\n    def _on_client_deleted(self, ref: \"weakref.ref[Any]\") -&gt; None:  # pragma: no cover\n        \"\"\"Called when storage is garbage collected.\"\"\"\n        _active_clients.discard(ref)\n\n    async def close(self) -&gt; None:DOCS\n        \"\"\"Close the storage client and cleanup resources.\"\"\"\n        if self._client is not None:\n            # Remove from active storages\n            if self._client_ref is not None:\n                _active_clients.discard(self._client_ref)\n                self._client_ref = None\n            # Close the storage\n            await self._client.close()\n            self._client = None\n\n    async def exists(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if GCS blob exists.\"\"\"\n        storage = await self._get_client()\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            # check if the bucket exists\n            try:\n                await storage.get_bucket_metadata(bucket_name + \"/\")\n                return True\n            except Exception:  # pragma: no cover\n                return False\n\n        try:\n            await storage.download_metadata(bucket_name, blob_name)\n            return True\n        except Exception:\n            if blob_name.endswith(\"/\"):\n                return False\n            try:\n                await storage.download_metadata(bucket_name, f\"{blob_name}/\")\n                return True\n            except Exception:\n                return False\n\n    async def read_bytes(self, path: str) -&gt; bytes:DOCS\n        \"\"\"Read GCS blob as bytes.\"\"\"\n        storage = await self._get_client()\n        bucket_name, blob_name = self.__class__._parse_path(path)\n\n        try:\n            data = await storage.download(bucket_name, blob_name)\n            return data\n        except Exception as e:\n            raise FileNotFoundError(f\"GCS blob not found: {path}\") from e\n\n    async def write_bytes(  # type: ignore[override]DOCS\n        self,\n        path: str,\n        data: bytes,\n    ) -&gt; None:\n        \"\"\"Write bytes to GCS blob.\"\"\"\n        storage = await self._get_client()\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        await storage.upload(bucket_name, blob_name, data)\n\n    async def delete(self, path: str) -&gt; None:DOCS\n        \"\"\"Delete GCS blob.\"\"\"\n        storage = await self._get_client()\n        bucket_name, blob_name = self.__class__._parse_path(path)\n\n        if await self.is_dir(path):\n            raise IsADirectoryError(f\"Path is a directory: {path}\")\n\n        try:\n            await storage.delete(bucket_name, blob_name)\n        except Exception as e:\n            raise FileNotFoundError(f\"GCS blob not found: {path}\") from e\n\n    async def list_dir(self, path: str) -&gt; list[str]:DOCS\n        \"\"\"List GCS blobs with prefix.\"\"\"\n        storage = await self._get_client()\n        bucket_name, prefix = self.__class__._parse_path(path)\n\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        results = []\n        try:\n            blobs = await storage.list_objects(\n                bucket_name, params={\"prefix\": prefix, \"delimiter\": \"/\"}\n            )\n\n            # Add prefixes (directories)\n            for prefix_item in blobs.get(\"prefixes\", []):\n                results.append(f\"{self.prefix[0]}://{bucket_name}/{prefix_item.rstrip('/')}\")\n\n            # Add items (files)\n            for item in blobs.get(\"items\", []):\n                name = item[\"name\"]\n                if name != prefix:\n                    results.append(f\"{self.prefix[0]}://{bucket_name}/{name}\")\n\n        except Exception:  # pragma: no cover\n            pass\n\n        return results\n\n    async def is_dir(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if GCS path is a directory.\"\"\"\n        storage = await self._get_client()\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name and await self.exists(path):\n            return True\n\n        blob_name = blob_name if blob_name.endswith(\"/\") else blob_name + \"/\"\n        try:\n            # First check if directory marker exists\n            await storage.download_metadata(bucket_name, blob_name)\n            return True\n        except Exception:\n            # If no marker, check if any objects exist with this prefix\n            try:\n                response = await storage.list_objects(\n                    bucket_name,\n                    params={\"prefix\": blob_name, \"maxResults\": 1},  # type: ignore[dict-item]\n                )\n                return len(response.get(\"items\", [])) &gt; 0\n            except Exception:  # pragma: no cover\n                return False\n\n    async def is_file(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if GCS path is a file.\"\"\"\n        return not await self.is_dir(path) and await self.exists(path)\n\n    async def stat(self, path: str) -&gt; os.stat_result:DOCS\n        \"\"\"Get GCS blob metadata.\"\"\"\n        storage = await self._get_client()\n        bucket_name, blob_name = self.__class__._parse_path(path)\n\n        metadata = None\n        try:\n            metadata = await storage.download_metadata(bucket_name, blob_name)\n        except Exception as e:\n            if blob_name.endswith(\"/\"):  # pragma: no cover\n                raise NoStatError(str(path)) from e\n            try:\n                metadata = await storage.download_metadata(bucket_name, f\"{blob_name}/\")\n            except Exception:\n                raise NoStatError(str(path)) from e\n\n        if not metadata:  # pragma: no cover\n            raise NoStatError(str(path))\n\n        ctime = (\n            None\n            if \"timeCreated\" not in metadata\n            else datetime.datetime.fromisoformat(metadata[\"timeCreated\"].replace(\"Z\", \"+00:00\"))\n        )\n        mtime = (\n            None\n            if \"updated\" not in metadata\n            else datetime.datetime.fromisoformat(metadata[\"updated\"].replace(\"Z\", \"+00:00\"))\n        )\n        return os.stat_result(\n            (  # type: ignore[arg-type]\n                None,  # mode\n                None,  # ino\n                f\"{self.prefix[0]}://\",  # dev,\n                None,  # nlink,\n                None,  # uid,\n                None,  # gid,\n                int(metadata.get(\"size\", 0)),  # size,\n                # atime\n                mtime,\n                # mtime\n                mtime,\n                # ctime\n                ctime,\n            )\n        )\n\n    def open(DOCS\n        self,\n        path: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; \"GSAsyncFileHandle\":\n        \"\"\"Open GCS blob and return async file handle with streaming support.\n\n        Args:\n            path: GCS path (gs://bucket/blob)\n            mode: File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')\n            encoding: Text encoding (for text modes)\n            **kwargs: Additional arguments (chunk_size, upload_warning_threshold,\n                upload_interval supported)\n\n        Returns:\n            GSAsyncFileHandle with streaming support\n        \"\"\"\n        if mode not in (\"r\", \"rb\", \"w\", \"wb\", \"a\", \"ab\"):\n            raise ValueError(f\"Unsupported mode '{mode}'. Use 'r', 'rb', 'w', 'wb', 'a', or 'ab'.\")\n\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        return GSAsyncFileHandle(\n            client_factory=self._get_client,\n            bucket=bucket_name,\n            blob=blob_name,\n            prefix=self.prefix[0],\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )\n\n    async def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Create a directory marker (empty blob with trailing slash).\n\n        Args:\n            path: GCS path (gs://bucket/path)\n            parents: If True, create parent directories as needed\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure path ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        # Check if it already exists\n        if await self.exists(f\"{self.prefix[0]}://{bucket_name}/{blob_name}\"):\n            if not exist_ok:\n                raise FileExistsError(f\"Directory already exists: {path}\")\n            return\n\n        # check parents\n        if blob_name:  # not bucket root\n            parent_path = \"/\".join(blob_name.rstrip(\"/\").split(\"/\")[:-1])\n            if parent_path:\n                parent_exists = await self.exists(\n                    f\"{self.prefix[0]}://{bucket_name}/{parent_path}/\"\n                )\n                if not parent_exists:\n                    if not parents:\n                        raise FileNotFoundError(f\"Parent directory does not exist: {path}\")\n                    # Create parent directories recursively\n                    await self.mkdir(\n                        f\"{self.prefix[0]}://{bucket_name}/{parent_path}/\",\n                        parents=True,\n                        exist_ok=True,\n                    )\n\n        # Create empty directory marker\n        storage = await self._get_client()\n        await storage.upload(bucket_name, blob_name, b\"\")\n\n    async def get_metadata(self, path: str) -&gt; dict[str, str]:DOCS\n        \"\"\"Get blob metadata.\n\n        Args:\n            path: GCS path\n\n        Returns:\n            Dictionary of metadata key-value pairs\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        storage = await self._get_client()\n\n        # Get object metadata\n        return await storage.download_metadata(bucket_name, blob_name)\n\n    async def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:DOCS\n        \"\"\"Set blob metadata.\n\n        Args:\n            path: GCS path\n            metadata: Dictionary of metadata key-value pairs\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        storage = await self._get_client()\n\n        # Update metadata using patch\n        metadata = {\"metadata\": metadata}  # type: ignore[dict-item]\n        await storage.patch_metadata(bucket_name, blob_name, metadata=metadata)\n\n    async def readlink(self, path: str) -&gt; str:DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Args:\n            path: GCS path\n\n        Returns:\n            Symlink target path\n        \"\"\"\n        metadata = await self.get_metadata(path)\n        target = metadata.get(\"metadata\", {}).get(  # type: ignore[union-attr, call-overload]\n            self.__class__.symlink_target_metaname,\n        )\n        if not target:\n            raise ValueError(f\"Not a symlink: {path}\")\n        return target  # type: ignore[no-any-return]\n\n    async def symlink_to(self, path: str, target: str) -&gt; None:DOCS\n        \"\"\"Create symlink by storing target in metadata.\n\n        Args:\n            path: GCS path for the symlink\n            target: Target path the symlink should point to\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        storage = await self._get_client()\n\n        # Create empty blob first\n        await storage.upload(bucket_name, blob_name, b\"\")\n\n        # Then set the symlink metadata\n        await self.set_metadata(path, {self.__class__.symlink_target_metaname: target})\n\n    async def glob(  # type: ignore[override]DOCS\n        self,\n        path: str,\n        pattern: str,\n    ) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            path: Base GCS path\n            pattern: Glob pattern (e.g., \"*.txt\", \"**/*.py\")\n\n        Returns:\n            List of matching PanPath objects or strings\n        \"\"\"\n        from fnmatch import fnmatch\n\n        bucket_name, prefix = self.__class__._parse_path(path)\n        storage = await self._get_client()\n\n        # Handle recursive patterns\n        if \"**\" in pattern:\n            # Recursive search - list all blobs under prefix\n            blob_prefix = prefix if prefix else None\n            response = await storage.list_objects(\n                bucket_name, params={\"prefix\": blob_prefix} if blob_prefix else {}\n            )\n            items = response.get(\"items\", [])\n\n            # Extract the pattern part after **\n            pattern_parts = pattern.split(\"**/\")\n            if len(pattern_parts) &gt; 1:\n                file_pattern = pattern_parts[-1]\n            else:\n                file_pattern = \"*\"\n\n            for item in items:\n                blob_name = item[\"name\"]\n                if fnmatch(blob_name, f\"*{file_pattern}\"):\n                    yield f\"{self.prefix[0]}://{bucket_name}/{blob_name}\"\n        else:\n            # Non-recursive - list blobs with delimiter\n            blob_prefix = f\"{prefix}/\" if prefix and not prefix.endswith(\"/\") else prefix\n            response = await storage.list_objects(\n                bucket_name,\n                params=(\n                    {\"prefix\": blob_prefix, \"delimiter\": \"/\"} if blob_prefix else {\"delimiter\": \"/\"}\n                ),\n            )\n            items = response.get(\"items\", [])\n\n            for item in items:\n                blob_name = item[\"name\"]\n                if fnmatch(blob_name, f\"{blob_prefix}{pattern}\"):\n                    yield f\"{self.prefix[0]}://{bucket_name}/{blob_name}\"\n\n    async def walk(  # type: ignore[override]DOCS\n        self,\n        path: str,\n    ) -&gt; AsyncGenerator[tuple[str, list[str], list[str]], None]:\n        \"\"\"Walk directory tree.\n\n        Args:\n            path: Base GCS path\n\n        Yields:\n            Tuples of (dirpath, dirnames, filenames)\n        \"\"\"\n\n        bucket_name, blob_prefix = self.__class__._parse_path(path)\n        storage = await self._get_client()\n\n        # List all blobs under prefix\n        prefix = blob_prefix if blob_prefix else \"\"\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        response = await storage.list_objects(\n            bucket_name, params={\"prefix\": prefix} if prefix else {}\n        )\n        items = response.get(\"items\", [])\n\n        # Organize into directory structure\n        dirs: dict[str, tuple[set[str], set[str]]] = {}  # dirpath -&gt; (subdirs, files)\n\n        for item in items:\n            blob_name = item[\"name\"]\n            # Get relative path from prefix\n            rel_path = blob_name[len(prefix) :] if prefix else blob_name\n\n            # Split into directory and filename\n            parts = rel_path.split(\"/\")\n            if len(parts) == 1:\n                # File in root\n                if path not in dirs:\n                    dirs[path] = (set(), set())\n                if parts[0]:  # Skip empty strings\n                    dirs[path][1].add(parts[0])\n            else:\n                # File in subdirectory\n                # First, ensure root directory exists and add the first subdir to it\n                if path not in dirs:  # pragma: no cover\n                    dirs[path] = (set(), set())\n                if parts[0]:  # Add first-level subdirectory to root\n                    dirs[path][0].add(parts[0])\n\n                # Process all intermediate directories\n                for i in range(len(parts) - 1):\n                    dir_path = (\n                        f\"{path}/\" + \"/\".join(parts[: i + 1]) if path else \"/\".join(parts[: i + 1])\n                    )\n                    if dir_path not in dirs:\n                        dirs[dir_path] = (set(), set())\n\n                    # Add subdirectory if not last part\n                    if i &lt; len(parts) - 2:\n                        dirs[dir_path][0].add(parts[i + 1])\n\n                # Add file to its parent directory\n                parent_dir = f\"{path}/\" + \"/\".join(parts[:-1]) if path else \"/\".join(parts[:-1])\n                if parent_dir not in dirs:  # pragma: no cover\n                    dirs[parent_dir] = (set(), set())\n                if parts[-1]:  # Skip empty strings\n                    dirs[parent_dir][1].add(parts[-1])\n\n        # Yield each directory tuple\n        for d, (subdirs, files) in sorted(dirs.items()):\n            yield (d, sorted(subdirs), sorted(filter(None, files)))\n\n    async def touch(  # type: ignore[no-untyped-def, override]DOCS\n        self,\n        path: str,\n        mode=None,\n        exist_ok: bool = True,\n    ) -&gt; None:\n        \"\"\"Create empty file.\n\n        Args:\n            path: GCS path\n            mode: Mode setting (not supported for GCS, will raise ValueError if provided)\n            exist_ok: If False, raise error if file exists\n        \"\"\"\n        if mode is not None:\n            raise ValueError(\"Mode setting is not supported for Google Cloud Storage.\")\n\n        if not exist_ok and await self.exists(path):\n            raise FileExistsError(f\"File already exists: {path}\")\n\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        storage = await self._get_client()\n        await storage.upload(bucket_name, blob_name, b\"\")\n\n    async def rename(self, source: str, target: str) -&gt; None:DOCS\n        \"\"\"Rename/move file.\n\n        Args:\n            source: Source GCS path\n            target: Target GCS path\n        \"\"\"\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        # Copy to new location\n        src_bucket_name, src_blob_name = self.__class__._parse_path(source)\n        tgt_bucket_name, tgt_blob_name = self.__class__._parse_path(target)\n\n        storage = await self._get_client()\n\n        # Copy blob (read then write)\n        data = await storage.download(src_bucket_name, src_blob_name)\n        await storage.upload(tgt_bucket_name, tgt_blob_name, data)\n\n        # Delete source\n        await storage.delete(src_bucket_name, src_blob_name)\n\n    async def rmdir(self, path: str) -&gt; None:DOCS\n        \"\"\"Remove directory marker.\n\n        Args:\n            path: GCS path\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure path ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        # Check if it is empty\n        if await self.is_dir(path) and await self.list_dir(path):\n            raise OSError(f\"Directory not empty: {path}\")\n\n        storage = await self._get_client()\n\n        try:\n            await storage.delete(bucket_name, blob_name)\n        except Exception:\n            raise FileNotFoundError(f\"Directory not found: {path}\")\n\n    async def rmtree(DOCS\n        self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None\n    ) -&gt; None:\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            path: GCS path\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        if not await self.exists(path):\n            if ignore_errors:\n                return\n            else:\n                raise FileNotFoundError(f\"Path not found: {path}\")\n\n        if not await self.is_dir(path):\n            if ignore_errors:\n                return\n            else:\n                raise NotADirectoryError(f\"Path is not a directory: {path}\")\n\n        bucket_name, prefix = self.__class__._parse_path(path)\n\n        # Ensure prefix ends with / for directory listing\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        try:\n            storage = await self._get_client()\n\n            # List all blobs with this prefix\n            blobs = await storage.list_objects(bucket_name, params={\"prefix\": prefix})\n            blob_names = [item[\"name\"] for item in blobs.get(\"items\", [])]\n\n            # Delete all blobs\n            for blob_name in blob_names:\n                await storage.delete(bucket_name, blob_name)\n        except Exception:  # pragma: no cover\n            if ignore_errors:\n                return\n            if onerror is not None:\n                onerror(storage.delete, path, sys.exc_info())\n            else:\n                raise\n\n    async def copy(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy file to target.\n\n        Args:\n            source: Source GCS path\n            target: Target GCS path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and await self.is_symlink(source):\n            source = await self.readlink(source)\n\n        if await self.is_dir(source):\n            raise IsADirectoryError(f\"Source is a directory: {source}\")\n\n        src_bucket_name, src_blob_name = self.__class__._parse_path(source)\n        tgt_bucket_name, tgt_blob_name = self.__class__._parse_path(target)\n\n        storage = await self._get_client()\n\n        # Read from source\n        data = await storage.download(src_bucket_name, src_blob_name)\n\n        # Write to target\n        await storage.upload(tgt_bucket_name, tgt_blob_name, data)\n\n    async def copytree(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy directory tree to target recursively.\n\n        Args:\n            source: Source GCS path\n            target: Target GCS path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and await self.is_symlink(source):\n            source = await self.readlink(source)\n\n        if not await self.is_dir(source):\n            raise NotADirectoryError(f\"Source is not a directory: {source}\")\n\n        src_bucket_name, src_prefix = self.__class__._parse_path(source)\n        tgt_bucket_name, tgt_prefix = self.__class__._parse_path(target)\n\n        # Ensure prefixes end with / for directory operations\n        if src_prefix and not src_prefix.endswith(\"/\"):\n            src_prefix += \"/\"\n        if tgt_prefix and not tgt_prefix.endswith(\"/\"):\n            tgt_prefix += \"/\"\n\n        storage = await self._get_client()\n\n        # List all blobs with source prefix\n        blobs = await storage.list_objects(src_bucket_name, params={\"prefix\": src_prefix})\n\n        for item in blobs.get(\"items\", []):\n            src_blob_name = item[\"name\"]\n            # Calculate relative path and target blob name\n            rel_path = src_blob_name[len(src_prefix) :]\n            tgt_blob_name = tgt_prefix + rel_path\n\n            # Copy blob (read and write)\n            data = await storage.download(src_bucket_name, src_blob_name)\n            await storage.upload(tgt_bucket_name, tgt_blob_name, data)\n\n\nclass GSAsyncFileHandle(AsyncFileHandle):DOCS\n    \"\"\"Async file handle for GCS with chunked streaming support.\n\n    Uses range requests for reading to avoid loading entire blobs.\n    \"\"\"\n\n    async def _create_stream(self):  # type: ignore[no-untyped-def]\n        \"\"\"Create a GSAsyncReadStream for this file handle.\"\"\"\n        return await self._client.download_stream(  # type: ignore[union-attr]\n            self._bucket,\n            self._blob,\n        )\n\n    @classmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:\n        \"\"\"Check if exception indicates blob does not exist.\"\"\"\n        return True\n\n    async def _upload(self, data: Union[str, bytes]) -&gt; None:\n        \"\"\"Upload data to GCS blob using append semantics.\n\n        This method appends data using GCS compose.\n        For 'w' mode on first write, it overwrites. Subsequently it appends.\n        For 'a' mode, it always appends.\n\n        Args:\n            data: Data to upload\n                (will be appended to existing content after first write)\n        \"\"\"\n        if isinstance(data, str):\n            data = data.encode(self._encoding)\n\n        storage: Storage = self._client  # type: ignore[assignment]\n\n        # For 'w' mode on first write, overwrite existing content\n        if self._first_write and not self._is_append:\n            self._first_write = False\n            # Simple overwrite\n            await storage.upload(self._bucket, self._blob, data)\n            return\n\n        self._first_write = False\n\n        # For subsequent writes or append mode, use compose to append\n        # Check if the original blob exists\n        try:\n            await storage.download_metadata(self._bucket, self._blob)\n            blob_exists = True\n        except Exception:\n            blob_exists = False\n\n        if not blob_exists:\n            # If blob doesn't exist, just upload the new data\n            await storage.upload(self._bucket, self._blob, data)\n        else:\n            # Upload new data to a temporary blob\n            # Use upload count to ensure unique temp blob names across multiple flushes\n            temp_blob = f\"{self._blob}.tmp.{os.getpid()}.{self._upload_count}\"\n            await storage.upload(\n                self._bucket,\n                temp_blob,\n                data,\n            )\n\n            try:\n                # Use compose API to concatenate original + new data\n                await storage.compose(\n                    bucket=self._bucket,\n                    object_name=self._blob,\n                    source_object_names=[self._blob, temp_blob],\n                )\n            except Exception as e:  # pragma: no cover\n                raise IOError(f\"Failed to append data to GCS blob: {self._blob}\") from e\n            finally:\n                # Clean up the temporary blob\n                await storage.delete(self._bucket, temp_blob)\n</code></pre>"},{"location":"api/source/panpath.gs_client/","title":"panpath.gs_client","text":""},{"location":"api/source/panpath.gs_client/","title":"SOURCE CODE panpath.gs_client DOCS","text":"<pre><code>\"\"\"Google Cloud Storage client implementation.\"\"\"\n\nimport warnings\nimport os\nimport sys\nfrom typing import TYPE_CHECKING, Any, Optional, Union, Iterator\n\nfrom panpath.clients import SyncClient, SyncFileHandle\nfrom panpath.exceptions import MissingDependencyError, NoStatError\n\nif TYPE_CHECKING:\n    from google.cloud import storage  # type: ignore[import-untyped, unused-ignore]\n    from google.api_core.exceptions import NotFound\n\ntry:\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", FutureWarning)\n        from google.cloud import storage\n    from google.api_core.exceptions import NotFound\n\n    HAS_GCS = True\nexcept ImportError:\n    HAS_GCS = False\n    NotFound = Exception  # type: ignore\n\n\nclass GSClient(SyncClient):DOCS\n    \"\"\"Synchronous Google Cloud Storage client implementation.\"\"\"\n\n    prefix = (\"gs\",)\n    symlink_target_metaname = \"gcsfuse_symlink_target\"\n\n    def __init__(self, **kwargs: Any):\n        \"\"\"Initialize GCS client.\n\n        Args:\n            **kwargs: Additional arguments passed to storage.Client()\n        \"\"\"\n        if not HAS_GCS:\n            raise MissingDependencyError(\n                backend=\"Google Cloud Storage\",\n                package=\"google-cloud-storage\",\n                extra=\"gs\",\n            )\n        self._client = storage.Client(**kwargs)\n\n    def exists(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if GCS blob exists.\"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            # Check if bucket exists\n            try:\n                bucket = self._client.bucket(bucket_name)\n                return bucket.exists()  # type: ignore[no-any-return]\n            except Exception:  # pragma: no cover\n                return False\n\n        bucket = self._client.bucket(bucket_name)\n        blob = bucket.get_blob(blob_name)\n        if blob is None:\n            blob = bucket.get_blob(f\"{blob_name}/\")\n\n        return blob is not None and blob.exists()\n\n    def read_bytes(self, path: str) -&gt; bytes:DOCS\n        \"\"\"Read GCS blob as bytes.\"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        bucket = self._client.bucket(bucket_name)\n        blob = bucket.blob(blob_name)\n        try:\n            return blob.download_as_bytes()  # type: ignore[no-any-return]\n        except NotFound:\n            raise FileNotFoundError(f\"GCS blob not found: {path}\")\n\n    def write_bytes(self, path: str, data: bytes) -&gt; None:DOCS\n        \"\"\"Write bytes to GCS blob.\"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        bucket = self._client.bucket(bucket_name)\n        blob = bucket.blob(blob_name)\n        blob.upload_from_string(data)\n\n    def delete(self, path: str) -&gt; None:DOCS\n        \"\"\"Delete GCS blob.\"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        bucket = self._client.bucket(bucket_name)\n        blob = bucket.blob(blob_name)\n        try:\n            blob.delete()\n        except NotFound:\n            raise FileNotFoundError(f\"GCS blob not found: {path}\")\n\n    def list_dir(self, path: str) -&gt; list[str]:  # type: ignore[override]DOCS\n        \"\"\"List GCS blobs with prefix.\"\"\"\n        bucket_name, prefix = self.__class__._parse_path(path)\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        bucket = self._client.bucket(bucket_name)\n        blobs = bucket.list_blobs(prefix=prefix, delimiter=\"/\")\n\n        results = []\n        # List files first - this populates the prefixes attribute\n        for blob in blobs:\n            if blob.name != prefix:  # Skip the prefix itself\n                results.append(f\"{self.prefix[0]}://{bucket_name}/{blob.name}\")\n\n        # List \"subdirectories\" - access prefixes after iterating over blobs\n        for prefix_item in blobs.prefixes:\n            results.append(f\"{self.prefix[0]}://{bucket_name}/{prefix_item.rstrip('/')}\")\n\n        return results\n\n    def is_dir(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if GCS path is a directory (has blobs with prefix).\"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name and self.exists(bucket_name):\n            return True  # Bucket root is a directory\n\n        prefix = blob_name if blob_name.endswith(\"/\") else blob_name + \"/\"\n        bucket = self._client.bucket(bucket_name)\n        blobs = bucket.list_blobs(prefix=prefix, max_results=1)\n        # Try to get first item\n        try:\n            for _ in blobs:\n                return True\n        except NotFound:\n            return False\n        return False\n\n    def is_file(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if GCS path is a file.\"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        if not blob_name:\n            return False\n\n        bucket = self._client.bucket(bucket_name)\n        blob = bucket.blob(blob_name)\n        return blob.exists()  # type: ignore[no-any-return]\n\n    def stat(self, path: str) -&gt; Any:DOCS\n        \"\"\"Get GCS blob metadata.\"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        bucket = self._client.get_bucket(bucket_name)\n        blob = bucket.get_blob(blob_name)\n        if blob is None:\n            blob = bucket.get_blob(f\"{blob_name}/\")\n\n        if blob is None:\n            raise NoStatError(f\"No stats available for {path}\")\n\n        return os.stat_result(\n            (  # type: ignore[arg-type]\n                None,  # mode\n                None,  # ino\n                f\"{self.prefix[0]}://\",  # dev,\n                None,  # nlink,\n                None,  # uid,\n                None,  # gid,\n                blob.size,  # size,\n                blob.updated,  # atime,\n                blob.updated,  # mtime,\n                blob.time_created,  # ctime,\n            )\n        )\n\n    def open(DOCS\n        self,\n        path: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Open GCS blob for reading/writing with streaming support.\n\n        Args:\n            path: GCS path (gs://bucket/blob)\n            mode: File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')\n            encoding: Text encoding (for text modes)\n            **kwargs: Additional arguments (chunk_size, upload_warning_threshold,\n                upload_interval supported)\n\n        Returns:\n            GSSyncFileHandle with streaming support\n        \"\"\"\n        # Validate mode\n        if mode not in (\"r\", \"w\", \"rb\", \"wb\", \"a\", \"ab\"):\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        bucket, blob_name = self.__class__._parse_path(path)\n        return GSSyncFileHandle(  # type: ignore[no-untyped-call]\n            client=self._client,\n            bucket=bucket,\n            blob=blob_name,\n            prefix=self.prefix[0],\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )\n\n    def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Create a directory marker (empty blob with trailing slash).\n\n        Args:\n            path: GCS path (gs://bucket/path)\n            parents: If True, create parent directories as needed (ignored for GCS)\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure path ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        blob = self._client.bucket(bucket_name).blob(blob_name)\n\n        # Check if it already exists\n        if blob.exists():\n            if not exist_ok:\n                raise FileExistsError(f\"Directory already exists: {path}\")\n            return\n\n        # check parents\n        if blob_name:  # not bucket root\n            parent_path = \"/\".join(blob_name.rstrip(\"/\").split(\"/\")[:-1])\n            if parent_path:\n                parent_exists = self.exists(f\"{self.prefix[0]}://{bucket_name}/{parent_path}/\")\n                if not parent_exists:\n                    if not parents:\n                        raise FileNotFoundError(f\"Parent directory does not exist: {path}\")\n                    # Create parent directories recursively\n                    self.mkdir(\n                        f\"{self.prefix[0]}://{bucket_name}/{parent_path}/\",\n                        parents=True,\n                        exist_ok=True,\n                    )\n\n        # Create empty directory marker\n        blob.upload_from_string(\"\")\n\n    def get_metadata(self, path: str) -&gt; dict[str, str]:DOCS\n        \"\"\"Get blob metadata.\n\n        Args:\n            path: GCS path\n\n        Returns:\n            Dictionary of metadata key-value pairs\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        blob = self._client.bucket(bucket_name).blob(blob_name)\n        blob.reload()\n        return blob.metadata or {}\n\n    def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:DOCS\n        \"\"\"Set blob metadata.\n\n        Args:\n            path: GCS path\n            metadata: Dictionary of metadata key-value pairs\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        blob = self._client.bucket(bucket_name).blob(blob_name)\n        blob.metadata = metadata\n        blob.patch()\n\n    def symlink_to(self, path: str, target: str) -&gt; None:DOCS\n        \"\"\"Create symlink by storing target in metadata.\n\n        Args:\n            path: GCS path for the symlink\n            target: Target path the symlink should point to\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        blob = self._client.bucket(bucket_name).blob(blob_name)\n\n        # Create empty blob with symlink metadata\n        blob.metadata = {self.__class__.symlink_target_metaname: target}\n        blob.upload_from_string(\"\")\n\n    def is_symlink(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if blob is a symlink (has symlink_target metadata).\n\n        Args:\n            path: GCS path\n\n        Returns:\n            True if symlink metadata exists\n        \"\"\"\n        try:\n            metadata = self.get_metadata(path)\n            return self.__class__.symlink_target_metaname in metadata\n        except Exception:\n            return False\n\n    def readlink(self, path: str) -&gt; str:DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Args:\n            path: GCS path\n\n        Returns:\n            Symlink target path\n        \"\"\"\n        metadata = self.get_metadata(path)\n        target = metadata.get(self.__class__.symlink_target_metaname)\n        if not target:\n            raise ValueError(f\"Not a symlink: {path}\")\n\n        if any(target.startswith(f\"{prefix}://\") for prefix in self.__class__.prefix):\n            return target\n\n        # relative path\n        path = path.rstrip(\"/\").rsplit(\"/\", 1)[0]\n        return f\"{path}/{target}\"\n\n    def glob(self, path: str, pattern: str) -&gt; Iterator[str]:DOCS\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            path: Base GCS path\n            pattern: Glob pattern (e.g., \"*.txt\", \"**/*.py\")\n\n        Returns:\n            List of matching paths (as PanPath objects or strings)\n        \"\"\"\n        from fnmatch import fnmatch\n\n        bucket_name, blob_prefix = self.__class__._parse_path(path)\n        bucket = self._client.bucket(bucket_name)\n\n        # Handle recursive patterns\n        if \"**\" in pattern:\n            # Recursive search - list all blobs under prefix\n            prefix = blob_prefix if blob_prefix else None\n            blobs = bucket.list_blobs(prefix=prefix)\n\n            # Extract the pattern part after **\n            pattern_parts = pattern.split(\"**/\")\n            if len(pattern_parts) &gt; 1:\n                file_pattern = pattern_parts[-1]\n            else:\n                file_pattern = \"*\"\n\n            for blob in blobs:\n                if fnmatch(blob.name, f\"*{file_pattern}\"):\n                    path_str = f\"{self.prefix[0]}://{bucket_name}/{blob.name}\"\n                    yield path_str\n        else:\n            # Non-recursive - list blobs with delimiter\n            prefix = (\n                f\"{blob_prefix}/\" if blob_prefix and not blob_prefix.endswith(\"/\") else blob_prefix\n            )\n            blobs = bucket.list_blobs(prefix=prefix, delimiter=\"/\")\n\n            for blob in blobs:\n                if fnmatch(blob.name, f\"{prefix}{pattern}\"):\n                    path_str = f\"{self.prefix[0]}://{bucket_name}/{blob.name}\"\n                    yield path_str\n\n    def walk(DOCS\n        self,\n        path: str,\n    ) -&gt; Iterator[tuple[str, list[str], list[str]]]:\n        \"\"\"Walk directory tree.\n\n        Args:\n            path: Base GCS path\n\n        Returns:\n            List of (dirpath, dirnames, filenames) tuples\n        \"\"\"\n        bucket_name, blob_prefix = self.__class__._parse_path(path)\n        bucket = self._client.bucket(bucket_name)\n\n        # List all blobs under prefix\n        prefix = blob_prefix if blob_prefix else \"\"\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        blobs = list(bucket.list_blobs(prefix=prefix))\n\n        # Organize into directory structure\n        dirs: dict[str, tuple[set[str], set[str]]] = {}  # dirpath -&gt; (subdirs, files)\n\n        for blob in blobs:\n            # Get relative path from prefix\n            rel_path = blob.name[len(prefix) :] if prefix else blob.name\n\n            # Split into directory and filename\n            parts = rel_path.split(\"/\")\n            if len(parts) == 1:\n                # File in root\n                if path not in dirs:\n                    dirs[path] = (set(), set())\n                dirs[path][1].add(parts[0])\n            else:\n                # File in subdirectory\n                for i in range(len(parts) - 1):\n                    dir_path = (\n                        f\"{path}/\" + \"/\".join(parts[: i + 1]) if path else \"/\".join(parts[: i + 1])\n                    )\n                    if dir_path not in dirs:\n                        dirs[dir_path] = (set(), set())\n\n                    # Add subdirectory if not last part\n                    if i &lt; len(parts) - 2:  # pragma: no cover\n                        dirs[dir_path][0].add(parts[i + 1])\n\n                    sub_parent = (\n                        f\"{path}/\" + \"/\".join(parts[: i]) if path else \"/\".join(parts[: i])\n                    ).rstrip(\"/\")\n                    if sub_parent not in dirs:  # pragma: no cover\n                        dirs[sub_parent] = (set(), set())\n                    dirs[sub_parent][0].add(parts[i])\n\n                # Add file to its parent directory\n                parent_dir = f\"{path}/\" + \"/\".join(parts[:-1]) if path else \"/\".join(parts[:-1])\n                if parent_dir not in dirs:  # pragma: no cover\n                    dirs[parent_dir] = (set(), set())\n                dirs[parent_dir][1].add(parts[-1])\n\n        for d, (subdirs, files) in dirs.items():\n            yield d, sorted(subdirs), sorted(filter(None, files))\n\n    def touch(self, path: str, exist_ok: bool = True) -&gt; None:DOCS\n        \"\"\"Create empty file.\n\n        Args:\n            path: GCS path\n            exist_ok: If False, raise error if file exists\n        \"\"\"\n        if not exist_ok and self.exists(path):\n            raise FileExistsError(f\"File already exists: {path}\")\n\n        bucket_name, blob_name = self.__class__._parse_path(path)\n        blob = self._client.bucket(bucket_name).blob(blob_name)\n        blob.upload_from_string(\"\")\n\n    def rename(self, source: str, target: str) -&gt; None:DOCS\n        \"\"\"Rename/move file.\n\n        Args:\n            source: Source GCS path\n            target: Target GCS path\n        \"\"\"\n        # Copy to new location\n        src_bucket_name, src_blob_name = self.__class__._parse_path(source)\n        tgt_bucket_name, tgt_blob_name = self.__class__._parse_path(target)\n\n        src_bucket = self._client.bucket(src_bucket_name)\n        tgt_bucket = self._client.bucket(tgt_bucket_name)\n\n        src_blob = src_bucket.blob(src_blob_name)\n\n        # Copy blob\n        src_bucket.copy_blob(src_blob, tgt_bucket, tgt_blob_name)\n\n        # Delete source\n        src_blob.delete()\n\n    def rmdir(self, path: str) -&gt; None:DOCS\n        \"\"\"Remove directory marker.\n\n        Args:\n            path: GCS path\n        \"\"\"\n        bucket_name, blob_name = self.__class__._parse_path(path)\n\n        # Ensure path ends with / for directory marker\n        if blob_name and not blob_name.endswith(\"/\"):\n            blob_name += \"/\"\n\n        blob = self._client.bucket(bucket_name).blob(blob_name)\n\n        # Check if it is empty\n        if self.is_dir(path) and self.list_dir(path):\n            raise OSError(f\"Directory not empty: {path}\")\n\n        try:\n            blob.delete()\n        except NotFound:\n            raise FileNotFoundError(f\"Directory not found: {path}\")\n\n    def rmtree(self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None) -&gt; None:DOCS\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            path: GCS path\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        if not self.exists(path):\n            if ignore_errors:\n                return\n            else:\n                raise FileNotFoundError(f\"Path not found: {path}\")\n\n        if not self.is_dir(path):\n            if ignore_errors:\n                return\n            else:\n                raise NotADirectoryError(f\"Not a directory: {path}\")\n\n        bucket_name, prefix = self.__class__._parse_path(path)\n\n        # Ensure prefix ends with / for directory listing\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        try:\n            bucket = self._client.bucket(bucket_name)\n            blobs = list(bucket.list_blobs(prefix=prefix))\n\n            # Delete all blobs with this prefix\n            for blob in blobs:\n                blob.delete()\n        except Exception:  # pragma: no cover\n            if ignore_errors:\n                return\n            if onerror is not None:\n                onerror(blob.delete, path, sys.exc_info())\n            else:\n                raise\n\n    def copy(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy file to target.\n\n        Args:\n            source: Source GCS path\n            target: Target GCS path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and self.is_symlink(source):\n            source = self.readlink(source)\n\n        if self.is_dir(source):\n            raise IsADirectoryError(f\"Source is a directory: {source}\")\n\n        src_bucket_name, src_blob_name = self.__class__._parse_path(source)\n        tgt_bucket_name, tgt_blob_name = self.__class__._parse_path(target)\n\n        src_bucket = self._client.bucket(src_bucket_name)\n        src_blob = src_bucket.blob(src_blob_name)\n        tgt_bucket = self._client.bucket(tgt_bucket_name)\n\n        # Use GCS's native copy operation\n        src_bucket.copy_blob(src_blob, tgt_bucket, tgt_blob_name)\n\n    def copytree(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy directory tree to target recursively.\n\n        Args:\n            source: Source GCS path\n            target: Target GCS path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and self.is_symlink(source):\n            source = self.readlink(source)\n\n        src_bucket_name, src_prefix = self.__class__._parse_path(source)\n        tgt_bucket_name, tgt_prefix = self.__class__._parse_path(target)\n\n        # Ensure prefixes end with / for directory operations\n        if src_prefix and not src_prefix.endswith(\"/\"):\n            src_prefix += \"/\"\n        if tgt_prefix and not tgt_prefix.endswith(\"/\"):\n            tgt_prefix += \"/\"\n\n        src_bucket = self._client.bucket(src_bucket_name)\n        tgt_bucket = self._client.bucket(tgt_bucket_name)\n\n        # List all blobs with source prefix\n        for src_blob in src_bucket.list_blobs(prefix=src_prefix):\n            # Calculate relative path and target blob name\n            rel_path = src_blob.name[len(src_prefix) :]\n            tgt_blob_name = tgt_prefix + rel_path\n\n            # Copy blob\n            src_bucket.copy_blob(src_blob, tgt_bucket, tgt_blob_name)\n\n\nclass GSSyncFileHandle(SyncFileHandle):DOCS\n    \"\"\"Sync file handle for GCS with chunked streaming support.\n\n    Uses google-cloud-storage's streaming API for efficient reading of large files.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):  # type: ignore[no-untyped-def]\n        super().__init__(*args, **kwargs)\n        self._blob: storage.Blob = self._client.bucket(self._bucket).blob(self._blob)\n        if self._is_read and not self._blob.exists():\n            raise FileNotFoundError(f\"GCS blob not found: {self._bucket}/{self._blob.name}\")\n\n    @classmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:  # pragma: no cover\n        \"\"\"Check if exception is GCS NotFound and convert to FileNotFoundError.\"\"\"\n        # FileNotFoundError already raised in __init__\n        return isinstance(exception, NotFound)\n\n    def reset_stream(self) -&gt; None:DOCS\n        \"\"\"Reset streaming reader/writer.\"\"\"\n        if self._stream:\n            self._stream.close()\n            self._stream = None\n        super().reset_stream()\n\n    def __del__(self) -&gt; None:DOCS\n        \"\"\"Destructor to ensure stream is closed.\"\"\"\n        try:\n            if self._stream:\n                self._stream.close()\n            if self._blob.client:\n                self._blob.client.close()\n        except Exception:  # pragma: no cover\n            pass\n\n    def _create_stream(self) -&gt; None:\n        \"\"\"Create streaming reader/writer.\"\"\"\n        return self._blob.open(\"rb\")  # type: ignore[no-any-return]\n\n    def _upload(self, data: Union[bytes, str]) -&gt; None:\n        \"\"\"Upload data to GCS blob using append semantics.\n\n        This method appends data using GCS compose API.\n        For 'w' mode on first write, it overwrites. Subsequently it appends.\n        For 'a' mode, it always appends.\n\n        Args:\n            data: Data to upload\n                (will be appended to existing content after first write)\n        \"\"\"\n        if isinstance(data, str):\n            data = data.encode(self._encoding)\n\n        # For 'w' mode on first write, overwrite existing content\n        if self._first_write and not self._is_append:\n            self._first_write = False\n            # Simple overwrite\n            self._blob.upload_from_string(data)\n            return\n\n        self._first_write = False\n\n        # For subsequent writes or append mode, use compose to append\n        # Check if the original blob exists\n        blob_exists = self._blob.exists()\n\n        if not blob_exists:\n            # If blob doesn't exist, just upload the new data\n            self._blob.upload_from_string(data)\n        else:\n            bucket = self._blob.bucket\n            # Use upload count to ensure unique temp blob names across multiple flushes\n            temp_blob_name = f\"{self._blob.name}.tmp.{os.getpid()}.{self._upload_count}\"\n            temp_blob = bucket.blob(temp_blob_name)\n\n            # Upload new data to temp blob\n            temp_blob.upload_from_string(data)\n\n            try:\n                # Compose: original + temp = original\n                self._blob.compose([self._blob, temp_blob])\n            except Exception as e:  # pragma: no cover\n                raise IOError(f\"Failed to append data to GCS blob: {self._blob}\") from e\n            finally:\n                # Clean up temp blob\n                temp_blob.delete()\n</code></pre>"},{"location":"api/source/panpath.gs_path/","title":"panpath.gs_path","text":""},{"location":"api/source/panpath.gs_path/","title":"SOURCE CODE panpath.gs_path DOCS","text":"<pre><code>\"\"\"Google Cloud Storage path implementation.\"\"\"\n\nfrom typing import TYPE_CHECKING, Optional\n\nfrom panpath.cloud import CloudPath\nfrom panpath.gs_client import GSClient\n\nif TYPE_CHECKING:\n    from panpath.clients import Client, AsyncClient\n\n\nclass GSPath(CloudPath):DOCS\n    \"\"\"Google Cloud Storage path implementation (sync and async methods).\"\"\"\n\n    _client: Optional[GSClient] = None\n    _default_client: Optional[GSClient] = None\n\n    @classmethod\n    def _create_default_client(cls) -&gt; \"Client\":  # type: ignore[override]\n        \"\"\"Create default GCS client.\"\"\"\n        return GSClient()\n\n    @classmethod\n    def _create_default_async_client(cls) -&gt; \"AsyncClient\":\n        \"\"\"Create default async GCS client.\"\"\"\n        from panpath.gs_async_client import AsyncGSClient\n\n        return AsyncGSClient()\n</code></pre>"},{"location":"api/source/panpath.local_path/","title":"panpath.local_path","text":""},{"location":"api/source/panpath.local_path/","title":"SOURCE CODE panpath.local_path DOCS","text":"<pre><code>\"\"\"Local filesystem path implementation.\"\"\"\n\nimport os\nimport shutil\nimport sys\nfrom pathlib import Path, PosixPath, WindowsPath\nfrom typing import Any, AsyncGenerator, List, Optional, Tuple, Union\nfrom panpath.base import PanPath\nfrom panpath.cloud import CloudPath\nfrom panpath.exceptions import MissingDependencyError\n\n# Determine the concrete Path class for the current platform\n_ConcretePath = WindowsPath if os.name == \"nt\" else PosixPath\n\ntry:\n    import aiofiles  # type: ignore[import-untyped]\n    import aiofiles.os  # type: ignore[import-untyped]\n\n    HAS_AIOFILES = True\nexcept ImportError:\n    HAS_AIOFILES = False\n\n\nclass LocalPath(_ConcretePath, PanPath):  # type: ignore[valid-type, misc]DOCS\n    \"\"\"Local filesystem path (drop-in replacement for pathlib.Path).\n\n    Inherits from the platform-specific concrete path class (PosixPath/WindowsPath)\n    and PanPath for full compatibility. The concrete class must come first in MRO\n    to ensure proper _flavour attribute inheritance in Python 3.10.\n    Includes both sync methods (from Path) and async methods with a_ prefix.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Initialize LocalPath.\n\n        Skip initialization if already initialized (to avoid double-init when created via PanPath\n        factory).\n        \"\"\"\n        if hasattr(self, \"_raw_paths\"):\n            # Already initialized in __new__, skip\n            return\n        # In Python 3.10, pathlib.Path.__init__() doesn't accept arguments\n        # In Python 3.12+, pathlib.Path.__init__() needs the arguments\n        if sys.version_info &gt;= (3, 12):\n            super().__init__(*args, **kwargs)\n        else:  # pragma: no cover\n            super().__init__()\n\n    async def a_touch(self, mode: int = 0o666, exist_ok: bool = True) -&gt; None:DOCS\n        \"\"\"Create the file if it does not exist or update the modification time (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        if await self.a_exists() and not exist_ok:\n            raise FileExistsError(f\"File {self} already exists.\")\n\n        async with aiofiles.open(str(self), mode=\"a\"):\n            pass\n        os.chmod(str(self), mode)\n\n    async def a_rename(self, target: Union[str, \"Path\"]) -&gt; \"PanPath\":DOCS\n        \"\"\"Rename the file or directory to target.\n\n        Args:\n            target: New path\n\n        Returns:\n            New path instance\n        \"\"\"\n        target_str = str(target)\n        if CloudPath._is_cross_storage_op(str(self), target_str):\n            if await self.a_is_dir():\n                await CloudPath._a_copytree_cross_storage(str(self), target_str)\n                await self.a_rmtree()\n            else:\n                await CloudPath._a_copy_cross_storage(self, target_str)\n                await self.a_unlink()\n        else:\n            if not HAS_AIOFILES:\n                raise MissingDependencyError(\n                    backend=\"async local paths\",\n                    package=\"aiofiles\",\n                    extra=\"all-async\",\n                )\n            await aiofiles.os.rename(str(self), target_str)\n        return PanPath(target_str)\n\n    async def a_replace(self, target: Union[str, \"Path\"]) -&gt; \"PanPath\":DOCS\n        \"\"\"Rename the file or directory to target, overwriting if target exists.\n\n        Args:\n            target: New path\n\n        Returns:\n            New path instance\n        \"\"\"\n        return await self.a_rename(target)\n\n    async def a_resolve(self) -&gt; \"PanPath\":DOCS\n        \"\"\"Resolve to absolute path (no-op for cloud paths).\n\n        Returns:\n            Self (cloud paths are already absolute)\n        \"\"\"\n        return await self.a_readlink() if await self.a_is_symlink() else self\n\n    async def a_copy(self, target: Union[str, \"Path\"], follow_symlinks: bool = True) -&gt; \"PanPath\":DOCS\n        \"\"\"Copy file to target.\n\n        Can copy between cloud and local paths.\n\n        Args:\n            target: Destination path (can be cloud or local)\n\n        Returns:\n            Target path instance\n        \"\"\"\n\n        target_str = str(target)\n        # Check if cross-storage operation\n        if CloudPath._is_cross_storage_op(str(self), target_str):\n            await CloudPath._a_copy_cross_storage(self, target_str, follow_symlinks=follow_symlinks)\n        else:\n            if not HAS_AIOFILES:\n                raise MissingDependencyError(\n                    backend=\"async local paths\",\n                    package=\"aiofiles\",\n                    extra=\"all-async\",\n                )\n            async with aiofiles.open(str(self), mode=\"rb\") as sf:\n                async with aiofiles.open(target_str, mode=\"wb\") as df:\n                    while True:\n                        chunk = await sf.read(1024 * 1024)\n                        if not chunk:  # pragma: no cover\n                            break\n                        await df.write(chunk)\n\n        return PanPath(target_str)\n\n    async def a_copytree(DOCS\n        self,\n        target: Union[str, \"Path\"],\n        follow_symlinks: bool = True,\n    ) -&gt; \"PanPath\":\n        \"\"\"Recursively copy the directory and all its contents to the target path.\n\n        Args:\n            target: Destination PanPath to copy to.\n            follow_symlinks: If True, copies the contents of symlinks.\n\n        Returns:\n            The copied PanPath instance.\n        \"\"\"\n        target_str = str(target)\n\n        if CloudPath._is_cross_storage_op(str(self), target_str):\n            await CloudPath._a_copytree_cross_storage(\n                self,\n                target_str,\n                follow_symlinks=follow_symlinks,\n            )\n        else:\n            target = PanPath(target)\n            await target.a_mkdir(parents=True, exist_ok=True)\n\n            async for entry in self.a_iterdir():\n                src_path = entry\n                dest_path = target / entry.name\n\n                if await src_path.a_is_dir():\n                    await src_path.a_copytree(dest_path, follow_symlinks=follow_symlinks)\n                else:\n                    await src_path.a_copy(dest_path, follow_symlinks=follow_symlinks)\n\n        return PanPath(target)\n\n    async def a_walk(  # type: ignore[override]DOCS\n        self,\n    ) -&gt; AsyncGenerator[Tuple[\"LocalPath\", List[str], List[str]], None]:\n        \"\"\"Asynchronously walk the directory tree.\n\n        Returns:\n            A list of tuples (dirpath, dirnames, filenames)\n        \"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n        dirnames = []\n        filenames = []\n        for entry in await aiofiles.os.listdir(str(self)):\n            path = self / entry\n            if await path.a_is_dir():\n                dirnames.append(entry)\n                async for sub in path.a_walk():\n                    yield sub\n            else:\n                filenames.append(entry)\n        yield (self, dirnames, filenames)\n\n    async def a_readlink(self) -&gt; \"LocalPath\":DOCS\n        \"\"\"Asynchronously read the target of a symbolic link.\n\n        Returns:\n            The path to which the symbolic link points.\n        \"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        return PanPath(await aiofiles.os.readlink(str(self)))  # type: ignore[return-value]\n\n    async def a_symlink_to(DOCS\n        self,\n        target: Union[str, \"Path\"],\n        target_is_directory: bool = False,\n    ) -&gt; None:\n        \"\"\"Asynchronously create a symbolic link pointing to target.\n\n        Args:\n            target: The target path the symbolic link points to.\n            target_is_directory: Whether the target is a directory.\n        \"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        await aiofiles.os.symlink(str(target), str(self), target_is_directory=target_is_directory)\n\n    async def a_glob(  # type: ignore[override]DOCS\n        self,\n        pattern: str,\n    ) -&gt; AsyncGenerator[\"LocalPath\", None]:\n        \"\"\"Asynchronously yield paths matching the glob pattern.\n\n        Args:\n            pattern: Glob pattern (relative)\n\n        Yields:\n            Matching LocalPath instances\n        \"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        from fnmatch import fnmatch\n\n        if not pattern:\n            raise ValueError(\"Unacceptable pattern: {!r}\".format(pattern))\n\n        # aiofiles does not support globbing natively\n        # let's implement it with walk\n        if \"**\" in pattern:\n            pattern_parts = pattern.split(\"**/\")\n            if len(pattern_parts) &gt; 1:\n                file_pattern = pattern_parts[1]\n            else:  # pragma: no cover\n                file_pattern = \"*\"\n            async for dirpath, _, filenames in self.a_walk():\n                for filename in filenames:\n                    if fnmatch(filename, file_pattern):\n                        yield dirpath / filename\n        else:\n            async for entry in self.a_iterdir():\n                if fnmatch(entry.name, pattern):\n                    yield entry\n\n    async def a_rglob(  # type: ignore[override]DOCS\n        self,\n        pattern: str,\n    ) -&gt; AsyncGenerator[\"LocalPath\", None]:\n        \"\"\"Recursively yield all existing files matching the given pattern.\n\n        Args:\n            pattern: Glob pattern (relative)\n\n        Yields:\n            Matching LocalPath instances\n        \"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        if not pattern:\n            raise ValueError(\"Unacceptable pattern: {!r}\".format(pattern))\n\n        # use a_glob to implement rglob\n        async for path in self.a_glob(f\"**/{pattern}\"):\n            yield path\n\n    # Async I/O operations (prefixed with a_)\n    async def a_exists(self) -&gt; bool:DOCS\n        \"\"\"Check if path exists (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n        return await aiofiles.os.path.exists(str(self))  # type: ignore[no-any-return]\n\n    async def a_is_file(self) -&gt; bool:DOCS\n        \"\"\"Check if path is a file (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        return await aiofiles.os.path.isfile(str(self))  # type: ignore[no-any-return]\n\n    async def a_is_dir(self) -&gt; bool:DOCS\n        \"\"\"Check if path is a directory (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        return await aiofiles.os.path.isdir(str(self))  # type: ignore[no-any-return]\n\n    async def a_read_bytes(self) -&gt; bytes:DOCS\n        \"\"\"Read file as bytes (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        async with aiofiles.open(str(self), mode=\"rb\") as f:\n            return await f.read()  # type: ignore[no-any-return]\n\n    async def a_read_text(self, encoding: str = \"utf-8\") -&gt; str:DOCS\n        \"\"\"Read file as text (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        async with aiofiles.open(str(self), mode=\"r\", encoding=encoding) as f:\n            return await f.read()  # type: ignore[no-any-return]\n\n    async def a_write_bytes(self, data: bytes) -&gt; int:DOCS\n        \"\"\"Write bytes to file (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        async with aiofiles.open(str(self), mode=\"wb\") as f:\n            return await f.write(data)  # type: ignore[no-any-return]\n\n    async def a_write_text(self, data: str, encoding: str = \"utf-8\") -&gt; int:DOCS\n        \"\"\"Write text to file (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        async with aiofiles.open(str(self), mode=\"w\", encoding=encoding) as f:\n            return await f.write(data)  # type: ignore[no-any-return]\n\n    async def a_is_symlink(self) -&gt; bool:DOCS\n        \"\"\"Check if path is a symlink (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        return await aiofiles.os.path.islink(str(self))  # type: ignore[no-any-return]\n\n    async def a_unlink(self, missing_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Delete file (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        try:\n            await aiofiles.os.remove(str(self))\n        except FileNotFoundError:\n            if not missing_ok:\n                raise\n\n    async def a_mkdir(DOCS\n        self,\n        mode: int = 0o777,\n        parents: bool = False,\n        exist_ok: bool = False,\n    ) -&gt; None:\n        \"\"\"Create directory (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        if parents:\n            await aiofiles.os.makedirs(str(self), mode=mode, exist_ok=exist_ok)\n        else:\n            try:\n                await aiofiles.os.mkdir(str(self), mode=mode)\n            except FileExistsError:\n                if not exist_ok:\n                    raise\n\n    async def a_rmdir(self) -&gt; None:DOCS\n        \"\"\"Remove empty directory (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        await aiofiles.os.rmdir(str(self))\n\n    async def a_rmtree(self) -&gt; None:  # type: ignore[override]DOCS\n        \"\"\"Recursively remove directory and its contents (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        for entry in await aiofiles.os.listdir(str(self)):\n            path = self / entry\n            if await path.a_is_dir():\n                await path.a_rmtree()\n            else:\n                await aiofiles.os.remove(str(path))\n        await aiofiles.os.rmdir(str(self))\n\n    async def a_iterdir(  # type: ignore[override]DOCS\n        self,\n    ) -&gt; AsyncGenerator[\"LocalPath\", None]:\n        \"\"\"List directory contents (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        for item in await aiofiles.os.listdir(str(self)):\n            yield self / item\n\n    async def a_stat(self, follow_symlinks: bool = True) -&gt; os.stat_result:DOCS\n        \"\"\"Get file stats (async).\"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        return await aiofiles.os.stat(  # type: ignore[no-any-return]\n            str(self),\n            follow_symlinks=follow_symlinks,\n        )\n\n    def a_open(  # type: ignore[override]DOCS\n        self,\n        mode: str = \"r\",\n        buffering: int = -1,\n        encoding: Optional[str] = None,\n        errors: Optional[str] = None,\n        newline: Optional[str] = None,\n    ) -&gt; Any:\n        \"\"\"Open file and return async file handle.\n\n        Returns:\n            Async file handle from aiofiles\n        \"\"\"\n        if not HAS_AIOFILES:\n            raise MissingDependencyError(\n                backend=\"async local paths\",\n                package=\"aiofiles\",\n                extra=\"all-async\",\n            )\n\n        return aiofiles.open(\n            str(self),\n            mode=mode,\n            buffering=buffering,\n            encoding=encoding,\n            errors=errors,\n            newline=newline,\n        )\n\n    def rename(self, target: Union[str, \"Path\"]) -&gt; \"PanPath\":DOCS\n        \"\"\"Rename the file or directory to target.\n\n        Args:\n            target: New path\n\n        Returns:\n            New path instance\n        \"\"\"\n        target_str = str(target)\n        if CloudPath._is_cross_storage_op(str(self), target_str):\n            if self.is_dir():\n                CloudPath._copytree_cross_storage(self, target_str)\n                self.rmtree()\n            else:\n                CloudPath._copy_cross_storage(self, target_str)\n                self.unlink()\n        else:\n            os.rename(str(self), target_str)\n\n        return PanPath(target_str)\n\n    def copy(self, target: Union[str, \"Path\"], follow_symlinks: bool = True) -&gt; \"PanPath\":DOCS\n        \"\"\"Copy file to target.\n\n        Can copy between cloud and local paths.\n\n        Args:\n            target: Destination path (can be cloud or local)\n            follow_symlinks: If True, follow symbolic links\n\n        Returns:\n            Target path instance\n        \"\"\"\n        target_str = str(target)\n        if CloudPath._is_cross_storage_op(str(self), target_str):\n            CloudPath._copy_cross_storage(self, target_str, follow_symlinks=follow_symlinks)\n        else:\n            shutil.copy2(str(self), target_str, follow_symlinks=follow_symlinks)\n\n        return PanPath(target)\n\n    def copytree(DOCS\n        self,\n        target: Union[str, \"Path\"],\n        follow_symlinks: bool = True,\n    ) -&gt; \"PanPath\":\n        \"\"\"Recursively copy the directory and all its contents to the target path.\n\n        Args:\n            target: Destination PanPath to copy to.\n            follow_symlinks: If True, copies the contents of symlinks.\n\n        Returns:\n            The copied PanPath instance.\n        \"\"\"\n        target_str = str(target)\n        if CloudPath._is_cross_storage_op(str(self), target_str):\n            CloudPath._copytree_cross_storage(self, target_str, follow_symlinks=follow_symlinks)\n        else:\n            target = PanPath(target)\n\n            target.mkdir(parents=True, exist_ok=True)\n\n            for entry in self.iterdir():\n                src_path = entry\n                dest_path = target / entry.name\n\n                if src_path.is_dir():\n                    src_path.copytree(dest_path, follow_symlinks=follow_symlinks)\n                else:\n                    src_path.copy(dest_path, follow_symlinks=follow_symlinks)\n\n        return PanPath(target)\n\n    def rmdir(self) -&gt; None:DOCS\n        \"\"\"Remove empty directory.\"\"\"\n        os.rmdir(str(self))\n\n    def rmtree(self) -&gt; None:DOCS\n        \"\"\"Recursively remove directory and its contents.\"\"\"\n        shutil.rmtree(str(self))\n\n    # backports, walk is introduced in Python 3.12\n    def walk(  # type: ignore[override]DOCS\n        self,\n        *args,\n        **kwargs,\n    ) -&gt; List[Tuple[\"LocalPath\", List[str], List[str]]]:\n        \"\"\"Walk the directory tree.\n\n        Returns:\n            A list of tuples (dirpath, dirnames, filenames)\n        \"\"\"\n        if sys.version_info &gt;= (3, 12):\n            return super().walk(*args, **kwargs)  # type: ignore[no-untyped-call]\n\n        if args or kwargs:  # pragma: no cover\n            raise NotImplementedError(\n                \"walk() does not accept arguments in this backport.\"\n            )\n        else:  # pragma: no cover\n            results: List[Tuple[\"LocalPath\", List[str], List[str]]] = []\n            dirnames: List[str] = []\n            filenames: List[str] = []\n            for entry in os.listdir(str(self)):\n                path = self / entry\n                if path.is_dir():\n                    dirnames.append(entry)\n                    sub_results = path.walk()\n                    results.extend(sub_results)\n                else:\n                    filenames.append(entry)\n            results.insert(0, (self, dirnames, filenames))\n            return results\n</code></pre>"},{"location":"api/source/panpath/","title":"panpath","text":""},{"location":"api/source/panpath/","title":"SOURCE CODE panpath DOCS","text":"<pre><code>\"\"\"PanPath - Universal sync/async local/cloud path library.\n\nExamples:\n    &gt;&gt;&gt; from panpath import PanPath\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Local path (sync methods)\n    &gt;&gt;&gt; path = PanPath(\"/path/to/file.txt\")\n    &gt;&gt;&gt; content = path.read_text()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Local path (async methods with a_ prefix)\n    &gt;&gt;&gt; content = await path.a_read_text()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # S3 path (sync methods)\n    &gt;&gt;&gt; s3_path = PanPath(\"s3://bucket/key.txt\")\n    &gt;&gt;&gt; content = s3_path.read_text()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # S3 path (async methods with a_ prefix)\n    &gt;&gt;&gt; content = await s3_path.a_read_text()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Check if object is a PanPath instance\n    &gt;&gt;&gt; isinstance(path, PanPath)  # True for any path created by this package\n\"\"\"\n\nfrom panpath.base import PanPath\nfrom panpath.cloud import CloudPath\nfrom panpath.local_path import LocalPath\n\n# Import path classes and register them\nfrom panpath.registry import register_path_class\n\n# Register S3\ntry:\n    from panpath.s3_path import S3Path\n\n    register_path_class(\"s3\", S3Path)\nexcept ImportError:\n    # S3 dependencies not installed\n    raise\n\n# Register Google Cloud Storage\ntry:\n    from panpath.gs_path import GSPath\n\n    register_path_class(\"gs\", GSPath)\nexcept ImportError:\n    # GCS dependencies not installed\n    pass\n\n# Register Azure Blob Storage\ntry:\n    from panpath.azure_path import AzurePath\n\n    register_path_class(\"az\", AzurePath)\n    register_path_class(\"azure\", AzurePath)  # Support both schemes\nexcept ImportError:\n    # Azure dependencies not installed\n    pass\n\n__version__ = \"0.4.7\"\n\n__all__ = [\n    \"PanPath\",\n    \"CloudPath\",\n    \"LocalPath\",\n    # Export cloud paths if available\n]\n\n# Add cloud path classes to __all__ if they're available\ntry:\n    __all__.extend([\"S3Path\"])\nexcept NameError:\n    pass\n\ntry:\n    __all__.extend([\"GSPath\"])\nexcept NameError:\n    pass\n\ntry:\n    __all__.extend([\"AzurePath\"])\nexcept NameError:\n    pass\n</code></pre>"},{"location":"api/source/panpath.registry/","title":"panpath.registry","text":""},{"location":"api/source/panpath.registry/","title":"SOURCE CODE panpath.registry DOCS","text":"<pre><code>\"\"\"Registry for path class implementations.\"\"\"\n\nfrom typing import TYPE_CHECKING, Any, Dict, Type\n\nif TYPE_CHECKING:\n    from panpath.cloud import CloudPath\n\n\n# Registry mapping URI schemes to cloud path classes\n_REGISTRY: Dict[str, Type[\"CloudPath\"]] = {}\n\n\ndef register_path_class(DOCS\n    scheme: str,\n    path_class: Type[\"CloudPath\"],\n) -&gt; None:\n    \"\"\"Register a path class implementation for a URI scheme.\n\n    Args:\n        scheme: URI scheme (e.g., 's3', 'gs', 'az')\n        path_class: Cloud path class (with both sync and async methods)\n    \"\"\"\n    _REGISTRY[scheme] = path_class\n\n\ndef get_path_class(scheme: str) -&gt; Type[Any]:DOCS\n    \"\"\"Get the path class for a URI scheme.\n\n    Args:\n        scheme: URI scheme (e.g., 's3', 'gs', 'az')\n\n    Returns:\n        Path class for the scheme\n\n    Raises:\n        KeyError: If scheme is not registered\n    \"\"\"\n    return _REGISTRY[scheme]\n\n\ndef get_registered_schemes() -&gt; list[str]:DOCS\n    \"\"\"Get all registered URI schemes.\"\"\"\n    return list(_REGISTRY.keys())\n\n\ndef clear_registry() -&gt; None:DOCS\n    \"\"\"Clear the registry (mainly for testing).\"\"\"\n    _REGISTRY.clear()\n\n\ndef swap_implementation(DOCS\n    scheme: str,\n    path_class: Type[\"CloudPath\"],\n) -&gt; Type[\"CloudPath\"]:\n    \"\"\"Swap implementation for a scheme (for testing with local mocks).\n\n    Args:\n        scheme: URI scheme to swap\n        path_class: New path class\n\n    Returns:\n        Old path class (or None if not previously registered)\n    \"\"\"\n    old_class = _REGISTRY.get(scheme)\n    _REGISTRY[scheme] = path_class\n    return old_class  # type: ignore[return-value]\n\n\ndef restore_registry(snapshot: Dict[str, Type[\"CloudPath\"]]) -&gt; None:DOCS\n    \"\"\"Restore the registry from a snapshot (for testing).\n\n    Args:\n        snapshot: Registry snapshot to restore\n    \"\"\"\n    _REGISTRY.clear()\n    _REGISTRY.update(snapshot)\n</code></pre>"},{"location":"api/source/panpath.s3_async_client/","title":"panpath.s3_async_client","text":""},{"location":"api/source/panpath.s3_async_client/","title":"SOURCE CODE panpath.s3_async_client DOCS","text":"<pre><code>\"\"\"Async S3 client implementation.\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport os\nimport re\nimport weakref\nfrom typing import TYPE_CHECKING, Any, AsyncGenerator, Optional, Set, Union\n\nfrom panpath.clients import AsyncClient, AsyncFileHandle\nfrom panpath.exceptions import MissingDependencyError, NoStatError\n\nif TYPE_CHECKING:\n    import aioboto3  # type: ignore[import-not-found]\n    from aiobotocore.client import AioBaseClient  # type: ignore[import-untyped, unused-ignore]\n    from botocore.exceptions import ClientError  # type: ignore[import-untyped, unused-ignore]\n\ntry:\n    import aioboto3\n    from aiobotocore.client import AioBaseClient\n    from botocore.exceptions import ClientError\n\n    HAS_AIOBOTO3 = True\nexcept ImportError:\n    HAS_AIOBOTO3 = False\n    ClientError = Exception\n\n\n# Track all active client instances for cleanup\n_active_clients: Set[weakref.ref] = set()  # type: ignore[type-arg]\n\n\nasync def _async_cleanup_all_clients() -&gt; None:\n    \"\"\"Async cleanup of all active client instances.\"\"\"\n    # Create a copy of the set to avoid modification during iteration\n    client_to_clean = list(_active_clients)\n\n    for client_ref in client_to_clean:\n        client: AioBaseClient = client_ref()\n        if client is None:  # pragma: no cover\n            continue\n\n        try:\n            await client.close()\n        except Exception:  # pragma: no cover\n            # Ignore errors during cleanup\n            pass\n\n    _active_clients.clear()\n\n\ndef _register_loop_cleanup(loop: asyncio.AbstractEventLoop) -&gt; None:\n    \"\"\"Register cleanup to run before loop closes.\"\"\"\n    # Get the original shutdown_asyncgens method\n    original_shutdown = loop.shutdown_asyncgens\n\n    async def shutdown_with_cleanup():  # type: ignore[no-untyped-def]\n        \"\"\"Shutdown that includes client cleanup.\"\"\"\n        # Clean up clients first\n        await _async_cleanup_all_clients()\n        # Then run original shutdown\n        await original_shutdown()\n\n    # Replace with our version\n    loop.shutdown_asyncgens = shutdown_with_cleanup  # type: ignore[method-assign]\n\n\nclass AsyncS3Client(AsyncClient):DOCS\n    \"\"\"Asynchronous S3 client implementation using aioboto3.\"\"\"\n\n    prefix = (\"s3\",)\n\n    def __init__(self, **kwargs: Any):\n        \"\"\"Initialize async S3 client.\n\n        Args:\n            **kwargs: Additional arguments passed to aioboto3.Session\n        \"\"\"\n        if not HAS_AIOBOTO3:\n            raise MissingDependencyError(\n                backend=\"async S3\",\n                package=\"aioboto3\",\n                extra=\"async-s3\",\n            )\n\n        self._client: Optional[AioBaseClient] = None\n        self._kwargs = kwargs\n        self._client_ref: Optional[weakref.ref] = None  # type: ignore[type-arg]\n\n    async def _get_client(self) -&gt; AioBaseClient:\n        \"\"\"Get or create shared client.\"\"\"\n        # For aioboto3, the client is lightweight and doesn't need recreation\n        # Track it for cleanup purposes\n        needs_recreation = False\n        if self._client is None:\n            needs_recreation = True\n        else:\n            try:\n                if not self._client._endpoint.http_session._sessions:\n                    needs_recreation = True\n                    if self._client_ref is not None:\n                        _active_clients.discard(self._client_ref)\n                        self._client_ref = None\n                    self._client = None\n            except Exception:  # pragma: no cover\n                needs_recreation = True\n                self._client = None\n\n        if needs_recreation:\n            self._client = await aioboto3.Session(**self._kwargs).client(\"s3\").__aenter__()\n            self._client_ref = weakref.ref(self._client, self._on_client_deleted)\n            _active_clients.add(self._client_ref)\n\n        # Register cleanup with the current event loop\n        try:\n            loop = asyncio.get_running_loop()\n            # Check if we've already patched this loop\n            if not hasattr(loop, \"_panpath_s3_cleanup_registered\"):\n                _register_loop_cleanup(loop)\n                loop._panpath_s3_cleanup_registered = True  # type: ignore\n        except RuntimeError:  # pragma: no cover\n            # No running loop, cleanup will be handled by explicit close\n            pass\n\n        return self._client\n\n    def _on_client_deleted(self, ref: \"weakref.ref[Any]\") -&gt; None:  # pragma: no cover\n        \"\"\"Called when client is garbage collected.\"\"\"\n        _active_clients.discard(ref)\n\n    async def close(self) -&gt; None:DOCS\n        \"\"\"Close the client and cleanup resources.\"\"\"\n        if self._client is not None:\n            if self._client_ref is not None:\n                _active_clients.discard(self._client_ref)\n\n            await self._client.close()\n            self._client = None\n\n    async def exists(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if S3 object exists.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n        if not key:\n            try:\n                await client.head_bucket(Bucket=bucket)\n                return True\n            except ClientError:\n                return False\n\n        try:\n            await client.head_object(Bucket=bucket, Key=key)\n            return True\n        except ClientError as e:\n            error_code = e.response.get(\"Error\", {}).get(\"Code\")\n            # Common error codes for \"not found\"\n            if error_code in (\"404\", \"NoSuchKey\", \"NoSuchBucket\", \"AccessDenied\", \"Forbidden\"):\n                # Check if it's a directory (with trailing slash)\n                if key.endswith(\"/\"):\n                    return False\n                try:\n                    await client.head_object(Bucket=bucket, Key=key + \"/\")\n                    return True\n                except ClientError:\n                    return False\n            # For other errors, re-raise\n            if error_code not in (\"403\",):  # pragma: no cover\n                raise\n            return False\n\n    async def read_bytes(self, path: str) -&gt; bytes:DOCS\n        \"\"\"Read S3 object as bytes.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n        try:\n            response = await client.get_object(Bucket=bucket, Key=key)\n            async with response[\"Body\"] as stream:\n                return await stream.read()  # type: ignore[no-any-return]\n        except ClientError as e:\n            error_code = e.response.get(\"Error\", {}).get(\"Code\")\n            if error_code in (\"NoSuchKey\", \"NoSuchBucket\", \"404\"):\n                raise FileNotFoundError(f\"S3 object not found: {path}\")\n            raise\n\n    async def write_bytes(  # type: ignore[override]DOCS\n        self,\n        path: str,\n        data: bytes,\n    ) -&gt; None:\n        \"\"\"Write bytes to S3 object.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n        await client.put_object(Bucket=bucket, Key=key, Body=data)\n\n    async def delete(self, path: str) -&gt; None:DOCS\n        \"\"\"Delete S3 object.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n\n        if await self.is_dir(path):\n            raise IsADirectoryError(f\"Path is a directory: {path}\")\n\n        if not await self.exists(path):\n            raise FileNotFoundError(f\"S3 object not found: {path}\")\n\n        try:\n            await client.delete_object(Bucket=bucket, Key=key)\n        except ClientError:  # pragma: no cover\n            raise\n\n    async def list_dir(self, path: str) -&gt; list[str]:DOCS\n        \"\"\"List S3 objects with prefix.\"\"\"\n        bucket, prefix = self.__class__._parse_path(path)\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        results = []\n        client = await self._get_client()\n        paginator = client.get_paginator(\"list_objects_v2\")\n        async for page in paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter=\"/\"):\n            # List \"subdirectories\"\n            for common_prefix in page.get(\"CommonPrefixes\", []):\n                results.append(f\"{self.prefix[0]}://{bucket}/{common_prefix['Prefix'].rstrip('/')}\")\n            # List files\n            for obj in page.get(\"Contents\", []):\n                key = obj[\"Key\"]\n                if key != prefix:\n                    results.append(f\"{self.prefix[0]}://{bucket}/{key}\")\n        return results\n\n    async def is_dir(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if S3 path is a directory.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        if not key:\n            return True\n\n        prefix = key if key.endswith(\"/\") else key + \"/\"\n        client = await self._get_client()\n        response = await client.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=1)\n        return \"Contents\" in response or \"CommonPrefixes\" in response\n\n    async def is_file(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if S3 path is a file.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        if not key:\n            return False\n\n        client = await self._get_client()\n        try:\n            await client.head_object(Bucket=bucket, Key=key)\n            return True\n        except ClientError:\n            return False\n\n    async def stat(self, path: str) -&gt; os.stat_result:DOCS\n        \"\"\"Get S3 object metadata.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n        try:\n            response = await client.head_object(Bucket=bucket, Key=key)\n        except ClientError as e:  # pragma: no cover\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                raise FileNotFoundError(f\"S3 object not found: {path}\")\n            raise\n        except Exception:  # pragma: no cover\n            raise NoStatError(f\"Cannot retrieve stat for: {path}\")\n        else:\n            return os.stat_result(\n                (  # type: ignore[arg-type]\n                    None,  # mode\n                    None,  # ino\n                    f\"{self.prefix[0]}://\",  # dev\n                    None,  # nlink\n                    None,  # uid\n                    None,  # gid\n                    response.get(\"ContentLength\", 0),  # size\n                    None,  # atime\n                    (\n                        response.get(\"LastModified\").timestamp()\n                        if response.get(\"LastModified\")\n                        else None\n                    ),  # mtime\n                    None,  # ctime\n                )\n            )\n\n    def open(DOCS\n        self,\n        path: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; \"S3AsyncFileHandle\":\n        \"\"\"Open S3 object and return async file handle with streaming support.\n\n        Args:\n            path: S3 path (s3://bucket/key)\n            mode: File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')\n            encoding: Text encoding (for text modes)\n            **kwargs: Additional arguments (chunk_size, upload_warning_threshold,\n                upload_interval supported)\n\n        Returns:\n            S3AsyncFileHandle with streaming support\n        \"\"\"\n        # Validate mode\n        if mode not in (\"r\", \"w\", \"rb\", \"wb\", \"a\", \"ab\"):\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        bucket, key = self.__class__._parse_path(path)\n        return S3AsyncFileHandle(\n            client_factory=self._get_client,\n            bucket=bucket,\n            blob=key,\n            prefix=self.prefix[0],\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )\n\n    async def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Create a directory marker (empty object with trailing slash).\n\n        Args:\n            path: S3 path (s3://bucket/path)\n            parents: If True, create parent directories as needed\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        # Ensure key ends with / for directory marker\n        if key and not key.endswith(\"/\"):\n            key += \"/\"\n\n        # Clean up any double slashes in the key\n        # while '//' in key:\n        #     key = key.replace('//', '/')\n        key = re.sub(r\"/+\", \"/\", key)\n\n        # Check parent directories if parents=False\n        if not parents and key:\n            parent_key = \"/\".join(key.rstrip(\"/\").split(\"/\")[:-1])\n            if parent_key:\n                parent_key += \"/\"\n                parent_path = f\"{self.prefix[0]}://{bucket}/{parent_key}\"\n                if not await self.exists(parent_path):\n                    raise FileNotFoundError(f\"Parent directory does not exist: {parent_path}\")\n\n        # Check if it already exists\n        client = await self._get_client()\n        try:\n            await client.head_object(Bucket=bucket, Key=key)\n            if not exist_ok:\n                raise FileExistsError(f\"Directory already exists: {path}\")\n            return\n        except ClientError as e:\n            error_code = e.response.get(\"Error\", {}).get(\"Code\")\n            # Treat 404 and 403 as \"doesn't exist\" for mkdir\n            if error_code not in (\"404\", \"403\", \"NoSuchKey\", \"Forbidden\"):  # pragma: no cover\n                raise\n\n        # Create empty directory marker\n        await client.put_object(Bucket=bucket, Key=key, Body=b\"\")\n\n    async def get_metadata(self, path: str) -&gt; dict[str, Any]:DOCS\n        \"\"\"Get object metadata.\n\n        Args:\n            path: S3 path\n\n        Returns:\n            Dictionary containing response metadata including 'Metadata' key with user metadata\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n        try:\n            response = await client.head_object(Bucket=bucket, Key=key)\n            return response  # type: ignore[no-any-return]\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                raise FileNotFoundError(f\"S3 object not found: {path}\")\n            raise  # pragma: no cover\n\n    async def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:DOCS\n        \"\"\"Set object metadata.\n\n        Args:\n            path: S3 path\n            metadata: Dictionary of metadata key-value pairs\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n        # S3 requires copying object to itself to update metadata\n        await client.copy_object(\n            Bucket=bucket,\n            Key=key,\n            CopySource={\"Bucket\": bucket, \"Key\": key},\n            Metadata=metadata,\n            MetadataDirective=\"REPLACE\",\n        )\n\n    async def is_symlink(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if object is a symlink (has symlink-target metadata).\n\n        Args:\n            path: S3 path\n\n        Returns:\n            True if symlink metadata exists\n        \"\"\"\n        try:\n            metadata = await self.get_metadata(path)\n            return self.__class__.symlink_target_metaname in metadata.get(\"Metadata\", {})\n        except FileNotFoundError:\n            return False\n\n    async def readlink(self, path: str) -&gt; str:DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Args:\n            path: S3 path\n\n        Returns:\n            Symlink target path\n        \"\"\"\n        metadata = await self.get_metadata(path)\n        target = metadata.get(\"Metadata\", {}).get(self.__class__.symlink_target_metaname)\n        if not target:\n            raise ValueError(f\"Not a symlink: {path}\")\n        return target  # type: ignore[no-any-return]\n\n    async def symlink_to(self, path: str, target: str) -&gt; None:DOCS\n        \"\"\"Create symlink by storing target in metadata.\n\n        Args:\n            path: S3 path for the symlink\n            target: Target path the symlink should point to\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        client = await self._get_client()\n        # Create empty object with symlink metadata\n        await client.put_object(\n            Bucket=bucket,\n            Key=key,\n            Body=b\"\",\n            Metadata={self.__class__.symlink_target_metaname: target},\n        )\n\n    async def glob(  # type: ignore[override]DOCS\n        self,\n        path: str,\n        pattern: str,\n    ) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            path: Base S3 path\n            pattern: Glob pattern (e.g., \"*.txt\", \"**/*.py\")\n\n        Returns:\n            List of matching paths (as PanPath objects or strings)\n        \"\"\"\n        from fnmatch import fnmatch\n\n        bucket, prefix = self.__class__._parse_path(path)\n\n        client = await self._get_client()\n        # Handle recursive patterns\n        if \"**\" in pattern:\n            # Recursive search - list all objects under prefix\n            paginator = client.get_paginator(\"list_objects_v2\")\n            pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n\n            # Extract the pattern part after **\n            pattern_parts = pattern.split(\"**/\")\n            if len(pattern_parts) &gt; 1:\n                file_pattern = pattern_parts[-1]\n            else:\n                file_pattern = \"*\"\n\n            async for page in pages:\n                for obj in page.get(\"Contents\", []):\n                    key = obj[\"Key\"]\n                    if fnmatch(key, f\"*{file_pattern}\"):\n                        path_str = f\"{self.prefix[0]}://{bucket}/{key}\"\n                        yield path_str\n        else:\n            # Non-recursive - list objects with delimiter\n            prefix_with_slash = f\"{prefix}/\" if prefix and not prefix.endswith(\"/\") else prefix\n            response = await client.list_objects_v2(\n                Bucket=bucket, Prefix=prefix_with_slash, Delimiter=\"/\"\n            )\n\n            for obj in response.get(\"Contents\", []):\n                key = obj[\"Key\"]\n                if fnmatch(key, f\"{prefix_with_slash}{pattern}\"):\n                    path_str = f\"{self.prefix[0]}://{bucket}/{key}\"\n                    yield path_str\n\n    async def walk(  # type: ignore[override]DOCS\n        self,\n        path: str,\n    ) -&gt; AsyncGenerator[tuple[str, list[str], list[str]], None]:\n        \"\"\"Walk directory tree.\n\n        Args:\n            path: Base S3 path\n\n        Yields:\n            Tuples of (dirpath, dirnames, filenames)\n        \"\"\"\n        bucket, prefix = self.__class__._parse_path(path)\n\n        # List all objects under prefix\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        client = await self._get_client()\n        paginator = client.get_paginator(\"list_objects_v2\")\n        pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n\n        # Organize into directory structure\n        dirs: dict[str, tuple[set[str], set[str]]] = {}  # dirpath -&gt; (subdirs, files)\n\n        async for page in pages:\n            for obj in page.get(\"Contents\", []):\n                key = obj[\"Key\"]\n                # Get relative path from prefix\n                rel_path = key[len(prefix) :] if prefix else key\n\n                # Split into directory and filename\n                parts = rel_path.split(\"/\")\n                if len(parts) == 1:\n                    # File in root\n                    if path not in dirs:\n                        dirs[path] = (set(), set())\n                    if parts[0]:  # Skip empty strings\n                        dirs[path][1].add(parts[0])\n                else:\n                    # File in subdirectory\n                    # First, ensure root directory exists and add the first subdir to it\n                    if path not in dirs:  # pragma: no cover\n                        dirs[path] = (set(), set())\n                    if parts[0]:  # Add first-level subdirectory to root\n                        dirs[path][0].add(parts[0])\n\n                    for i in range(len(parts) - 1):\n                        dir_path = (\n                            f\"{path}/\" + \"/\".join(parts[: i + 1])\n                            if path\n                            else \"/\".join(parts[: i + 1])\n                        )\n                        if dir_path not in dirs:\n                            dirs[dir_path] = (set(), set())\n\n                        # Add subdirectory if not last part\n                        if i &lt; len(parts) - 2:\n                            dirs[dir_path][0].add(parts[i + 1])\n\n                    # Add file to its parent directory\n                    parent_dir = f\"{path}/\" + \"/\".join(parts[:-1]) if path else \"/\".join(parts[:-1])\n                    if parent_dir not in dirs:  # pragma: no cover\n                        dirs[parent_dir] = (set(), set())\n                    if parts[-1]:  # Skip empty strings\n                        dirs[parent_dir][1].add(parts[-1])\n\n        # Yield tuples\n        for d, (subdirs, files) in sorted(dirs.items()):\n            yield (d, sorted(subdirs), sorted(filter(None, files)))\n\n    async def touch(self, path: str, exist_ok: bool = True, mode: Optional[int] = None) -&gt; None:DOCS\n        \"\"\"Create empty file.\n\n        Args:\n            path: S3 path\n            exist_ok: If False, raise error if file exists\n            mode: Ignored for S3 (for compatibility)\n        \"\"\"\n        if mode is not None:\n            raise ValueError(\"Mode parameter is not supported for S3\")\n\n        if not exist_ok and await self.exists(path):\n            raise FileExistsError(f\"File already exists: {path}\")\n\n        bucket, key = self.__class__._parse_path(path)\n        client = await self._get_client()\n        await client.put_object(Bucket=bucket, Key=key, Body=b\"\")\n\n    async def rename(self, source: str, target: str) -&gt; None:DOCS\n        \"\"\"Rename/move file.\n\n        Args:\n            source: Source S3 path\n            target: Target S3 path\n        \"\"\"\n        # Check if source exists\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        # Copy to new location\n        src_bucket, src_key = self.__class__._parse_path(source)\n        tgt_bucket, tgt_key = self.__class__._parse_path(target)\n\n        client = await self._get_client()\n        # Copy object\n        await client.copy_object(\n            Bucket=tgt_bucket, Key=tgt_key, CopySource={\"Bucket\": src_bucket, \"Key\": src_key}\n        )\n\n        # Delete source\n        await client.delete_object(Bucket=src_bucket, Key=src_key)\n\n    async def rmdir(self, path: str) -&gt; None:DOCS\n        \"\"\"Remove directory marker.\n\n        Args:\n            path: S3 path\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        # Ensure key ends with / for directory marker\n        if key and not key.endswith(\"/\"):\n            key += \"/\"\n\n        client = await self._get_client()\n        # client.delete_object will not raise error if object doesn't exist\n        if not await self.exists(path):\n            raise FileNotFoundError(f\"Directory not found: {path}\")\n\n        # Check if it is empty\n        if await self.is_dir(path) and await self.list_dir(path):\n            raise OSError(f\"Directory not empty: {path}\")\n\n        await client.delete_object(Bucket=bucket, Key=key)\n\n    async def rmtree(DOCS\n        self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None\n    ) -&gt; None:\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            path: S3 path\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        bucket, prefix = self.__class__._parse_path(path)\n\n        # Ensure prefix ends with / for directory listing\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        try:\n            client = await self._get_client()\n            # List all objects with this prefix\n            objects_to_delete = []\n            paginator = client.get_paginator(\"list_objects_v2\")\n            async for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n                if \"Contents\" in page:\n                    objects_to_delete.extend([{\"Key\": obj[\"Key\"]} for obj in page[\"Contents\"]])\n\n            # Delete in batches (max 1000 per request)\n            if objects_to_delete:\n                for i in range(0, len(objects_to_delete), 1000):\n                    batch = objects_to_delete[i : i + 1000]\n                    await client.delete_objects(Bucket=bucket, Delete={\"Objects\": batch})\n        except Exception:  # pragma: no cover\n            if ignore_errors:\n                return\n            if onerror is not None:\n                import sys\n\n                onerror(client.delete_objects, path, sys.exc_info())\n            else:\n                raise\n\n    async def copy(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy file to target.\n\n        Args:\n            source: Source S3 path\n            target: Target S3 path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and await self.is_symlink(source):\n            source = await self.readlink(source)\n\n        # Check if source is a directory\n        if await self.is_dir(source):\n            raise IsADirectoryError(f\"Source is a directory: {source}\")\n\n        src_bucket, src_key = self.__class__._parse_path(source)\n        tgt_bucket, tgt_key = self.__class__._parse_path(target)\n\n        client = await self._get_client()\n        # Use S3's native copy operation\n        await client.copy_object(\n            Bucket=tgt_bucket, Key=tgt_key, CopySource={\"Bucket\": src_bucket, \"Key\": src_key}\n        )\n\n    async def copytree(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy directory tree to target recursively.\n\n        Args:\n            source: Source S3 path\n            target: Target S3 path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        # Check if source exists\n        if not await self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and await self.is_symlink(source):\n            source = await self.readlink(source)\n\n        # Check if source is a directory\n        if not await self.is_dir(source):\n            raise NotADirectoryError(f\"Source is not a directory: {source}\")\n\n        src_bucket, src_prefix = self.__class__._parse_path(source)\n        tgt_bucket, tgt_prefix = self.__class__._parse_path(target)\n\n        # Ensure prefixes end with / for directory operations\n        if src_prefix and not src_prefix.endswith(\"/\"):\n            src_prefix += \"/\"\n        if tgt_prefix and not tgt_prefix.endswith(\"/\"):\n            tgt_prefix += \"/\"\n\n        client = await self._get_client()\n        # List all objects with source prefix\n        paginator = client.get_paginator(\"list_objects_v2\")\n        async for page in paginator.paginate(Bucket=src_bucket, Prefix=src_prefix):\n            if \"Contents\" not in page:  # pragma: no cover\n                continue\n\n            for obj in page[\"Contents\"]:\n                src_key = obj[\"Key\"]\n                # Calculate relative path and target key\n                rel_path = src_key[len(src_prefix) :]\n                tgt_key = tgt_prefix + rel_path\n\n                # Copy object\n                await client.copy_object(\n                    Bucket=tgt_bucket,\n                    Key=tgt_key,\n                    CopySource={\"Bucket\": src_bucket, \"Key\": src_key},\n                )\n\n\nclass S3AsyncFileHandle(AsyncFileHandle):DOCS\n    \"\"\"Async file handle for S3 with streaming support.\n\n    Uses aioboto3's streaming API to avoid loading entire files into memory.\n    \"\"\"\n\n    async def _create_stream(self) -&gt; None:\n        \"\"\"Create the underlying stream for reading or writing.\"\"\"\n        client: AioBaseClient = await self._client_factory()\n        response = await client.get_object(Bucket=self._bucket, Key=self._blob)\n        return response[\"Body\"]  # type: ignore[no-any-return]\n\n    @classmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:\n        \"\"\"Check if exception indicates blob does not exist.\"\"\"\n        return isinstance(exception, ClientError) and exception.response.get(\"Error\", {}).get(\n            \"Code\"\n        ) in (\n            \"NoSuchKey\",\n            \"NoSuchBucket\",\n            \"404\",\n        )\n\n    async def _upload(self, data: Union[str, bytes]) -&gt; None:\n        \"\"\"Upload data to S3 using append semantics.\n\n        This method appends data using multipart upload.\n        For 'w' mode on first write, it overwrites. Subsequently it appends.\n        For 'a' mode, it always appends.\n\n        Args:\n            data: Data to upload (will be appended to existing content after first write)\n        \"\"\"\n        if isinstance(data, str):\n            data = data.encode(self._encoding)\n\n        client: AioBaseClient = self._client\n\n        # For 'w' mode on first write, overwrite existing content\n        if self._first_write and not self._is_append:\n            self._first_write = False\n            # Simple overwrite\n            await client.put_object(Bucket=self._bucket, Key=self._blob, Body=data)\n            return\n\n        self._first_write = False\n\n        # For subsequent writes or append mode, use read-modify-write\n        # Check if object exists\n        try:\n            await client.head_object(Bucket=self._bucket, Key=self._blob)\n            object_exists = True\n        except ClientError as e:\n            if e.response.get(\"Error\", {}).get(\"Code\") in (\"NoSuchKey\", \"404\"):\n                object_exists = False\n            else:  # pragma: no cover\n                raise\n\n        if not object_exists:\n            # Simple upload for new objects\n            await client.put_object(Bucket=self._bucket, Key=self._blob, Body=data)\n        else:\n            # For existing objects, download, concatenate, and re-upload\n            response = await client.get_object(Bucket=self._bucket, Key=self._blob)\n            existing_data = await response[\"Body\"].read()\n            combined_data = existing_data + data\n            await client.put_object(\n                Bucket=self._bucket, Key=self._blob, Body=combined_data\n            )\n</code></pre>"},{"location":"api/source/panpath.s3_client/","title":"panpath.s3_client","text":""},{"location":"api/source/panpath.s3_client/","title":"SOURCE CODE panpath.s3_client DOCS","text":"<pre><code>\"\"\"S3 client implementation.\"\"\"\n\nimport os\nimport re\nfrom typing import TYPE_CHECKING, Any, Iterator, Optional, Union\n\nfrom panpath.clients import SyncClient, SyncFileHandle\nfrom panpath.exceptions import MissingDependencyError\n\nif TYPE_CHECKING:\n    import boto3  # type: ignore[import-untyped]\n    from botocore.exceptions import ClientError  # type: ignore[import-untyped]\n\ntry:\n    import boto3\n    from botocore.exceptions import ClientError\n\n    HAS_BOTO3 = True\nexcept ImportError:\n    HAS_BOTO3 = False\n    ClientError = Exception\n\n\nclass S3Client(SyncClient):DOCS\n    \"\"\"Synchronous S3 client implementation using boto3.\"\"\"\n\n    prefix = (\"s3\",)\n\n    def __init__(self, **kwargs: Any):\n        \"\"\"Initialize S3 client.\n\n        Args:\n            **kwargs: Additional arguments passed to boto3.client()\n        \"\"\"\n        if not HAS_BOTO3:\n            raise MissingDependencyError(\n                backend=\"S3\",\n                package=\"boto3\",\n                extra=\"s3\",\n            )\n        self._client = boto3.client(\"s3\", **kwargs)\n        self._resource = boto3.resource(\"s3\", **kwargs)\n\n    def exists(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if S3 object exists.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        if not key:\n            # Check if bucket exists\n            try:\n                self._client.head_bucket(Bucket=bucket)\n                return True\n            except ClientError:\n                return False\n\n        try:\n            self._client.head_object(Bucket=bucket, Key=key)\n            return True\n        except ClientError as e:\n            error_code = e.response.get(\"Error\", {}).get(\"Code\")\n            # Common error codes for \"not found\"\n            if error_code in (\"404\", \"NoSuchKey\", \"NoSuchBucket\", \"AccessDenied\", \"Forbidden\"):\n                # Check if it's a directory (with trailing slash)\n                if key.endswith(\"/\"):\n                    return False\n                try:\n                    self._client.head_object(Bucket=bucket, Key=key + \"/\")\n                    return True\n                except ClientError:\n                    return False\n            # For other errors, re-raise\n            if error_code not in (\"403\",):  # pragma: no cover\n                raise\n            return False\n\n    def read_bytes(self, path: str) -&gt; bytes:DOCS\n        \"\"\"Read S3 object as bytes.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        try:\n            response = self._client.get_object(Bucket=bucket, Key=key)\n            return response[\"Body\"].read()  # type: ignore[no-any-return]\n        except ClientError as e:\n            error_code = e.response.get(\"Error\", {}).get(\"Code\")\n            if error_code in (\"NoSuchKey\", \"NoSuchBucket\", \"404\"):\n                raise FileNotFoundError(f\"S3 object not found: {path}\")\n            raise\n\n    def write_bytes(self, path: str, data: bytes) -&gt; None:DOCS\n        \"\"\"Write bytes to S3 object.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        self._client.put_object(Bucket=bucket, Key=key, Body=data)\n\n    def delete(self, path: str) -&gt; None:DOCS\n        \"\"\"Delete S3 object.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        if self.is_dir(path):\n            raise IsADirectoryError(f\"Path is a directory: {path}\")\n\n        if not self.exists(path):\n            raise FileNotFoundError(f\"S3 object not found: {path}\")\n\n        self._client.delete_object(Bucket=bucket, Key=key)\n\n    def list_dir(self, path: str) -&gt; list[str]:  # type: ignore[override]DOCS\n        \"\"\"List S3 objects with prefix.\"\"\"\n        bucket, prefix = self.__class__._parse_path(path)\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        results = []\n        paginator = self._client.get_paginator(\"list_objects_v2\")\n        for page in paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter=\"/\"):\n            # List \"subdirectories\"\n            for common_prefix in page.get(\"CommonPrefixes\", []):\n                results.append(f\"{self.prefix[0]}://{bucket}/{common_prefix['Prefix'].rstrip('/')}\")\n            # List files\n            for obj in page.get(\"Contents\", []):\n                key = obj[\"Key\"]\n                if key != prefix:  # Skip the prefix itself\n                    results.append(f\"{self.prefix[0]}://{bucket}/{key}\")\n        return results\n\n    def is_dir(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if S3 path is a directory (has objects with prefix).\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        if not key:\n            return True  # Bucket root is a directory\n\n        prefix = key if key.endswith(\"/\") else key + \"/\"\n        response = self._client.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=1)\n        return \"Contents\" in response or \"CommonPrefixes\" in response\n\n    def is_file(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if S3 path is a file.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        if not key:\n            return False\n\n        try:\n            self._client.head_object(Bucket=bucket, Key=key)\n            return True\n        except ClientError:\n            return False\n\n    def stat(self, path: str) -&gt; os.stat_result:DOCS\n        \"\"\"Get S3 object metadata.\"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        try:\n            response = self._client.head_object(Bucket=bucket, Key=key)\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                raise FileNotFoundError(f\"S3 object not found: {path}\")\n            raise  # pragma: no cover\n        except Exception:  # pragma: no cover\n            from panpath.exceptions import NoStatError\n\n            raise NoStatError(f\"Cannot retrieve stat for: {path}\")\n        else:\n            return os.stat_result(\n                (  # type: ignore[arg-type]\n                    None,  # mode\n                    None,  # ino\n                    f\"{self.prefix[0]}://\",  # dev\n                    None,  # nlink\n                    None,  # uid\n                    None,  # gid\n                    response.get(\"ContentLength\", 0),  # size\n                    None,  # atime\n                    (\n                        response.get(\"LastModified\").timestamp()\n                        if response.get(\"LastModified\")\n                        else None\n                    ),  # mtime\n                    None,  # ctime\n                )\n            )\n\n    def open(DOCS\n        self,\n        path: str,\n        mode: str = \"r\",\n        encoding: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Open S3 object for reading/writing with streaming support.\n\n        Args:\n            path: S3 path (s3://bucket/key)\n            mode: File mode ('r', 'w', 'rb', 'wb', 'a', 'ab')\n            encoding: Text encoding (for text modes)\n            **kwargs: Additional arguments (chunk_size, upload_warning_threshold,\n                upload_interval supported)\n\n        Returns:\n            S3SyncFileHandle with streaming support\n        \"\"\"\n        # Validate mode\n        if mode not in (\"r\", \"w\", \"rb\", \"wb\", \"a\", \"ab\"):\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        bucket, key = self.__class__._parse_path(path)\n        return S3SyncFileHandle(\n            client=self._client,\n            bucket=bucket,\n            blob=key,\n            prefix=self.prefix[0],\n            mode=mode,\n            encoding=encoding,\n            **kwargs,\n        )\n\n    def mkdir(self, path: str, parents: bool = False, exist_ok: bool = False) -&gt; None:DOCS\n        \"\"\"Create a directory marker (empty object with trailing slash).\n\n        Args:\n            path: S3 path (s3://bucket/path)\n            parents: If True, create parent directories as needed\n            exist_ok: If True, don't raise error if directory already exists\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        # Ensure key ends with / for directory marker\n        if key and not key.endswith(\"/\"):\n            key += \"/\"\n\n        # Clean up any double slashes in the key\n        key = re.sub(r\"/+\", \"/\", key)\n\n        # Check parent directories if parents=False\n        if not parents and key:\n            parent_key = \"/\".join(key.rstrip(\"/\").split(\"/\")[:-1])\n            if parent_key:\n                parent_key += \"/\"\n                parent_path = f\"{self.prefix[0]}://{bucket}/{parent_key}\"\n                if not self.exists(parent_path):\n                    raise FileNotFoundError(f\"Parent directory does not exist: {parent_path}\")\n\n        # Check if it already exists\n        try:\n            self._client.head_object(Bucket=bucket, Key=key)\n            if not exist_ok:\n                raise FileExistsError(f\"Directory already exists: {path}\")\n            return\n        except ClientError as e:\n            error_code = e.response.get(\"Error\", {}).get(\"Code\")\n            # Treat 404 and 403 as \"doesn't exist\" for mkdir\n            if error_code not in (\"404\", \"403\", \"NoSuchKey\", \"Forbidden\"):  # pragma: no cover\n                raise\n\n        # Create empty directory marker\n        self._client.put_object(Bucket=bucket, Key=key, Body=b\"\")\n\n    def get_metadata(self, path: str) -&gt; dict[str, str]:DOCS\n        \"\"\"Get object metadata.\n\n        Args:\n            path: S3 path\n\n        Returns:\n            Dictionary containing response metadata including 'Metadata' key with user metadata\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n        try:\n            response = self._client.head_object(Bucket=bucket, Key=key)\n            return response  # type: ignore[no-any-return]\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                raise FileNotFoundError(f\"S3 object not found: {path}\")\n            raise  # pragma: no cover\n\n    def set_metadata(self, path: str, metadata: dict[str, str]) -&gt; None:DOCS\n        \"\"\"Set object metadata.\n\n        Args:\n            path: S3 path\n            metadata: Dictionary of metadata key-value pairs\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        # S3 requires copying object to itself to update metadata\n        self._client.copy_object(\n            Bucket=bucket,\n            Key=key,\n            CopySource={\"Bucket\": bucket, \"Key\": key},\n            Metadata=metadata,\n            MetadataDirective=\"REPLACE\",\n        )\n\n    def is_symlink(self, path: str) -&gt; bool:DOCS\n        \"\"\"Check if object is a symlink (has symlink-target metadata).\n\n        Args:\n            path: S3 path\n\n        Returns:\n            True if symlink metadata exists\n        \"\"\"\n        try:\n            metadata = self.get_metadata(path)\n            return self.__class__.symlink_target_metaname in metadata.get(\"Metadata\", {})\n        except FileNotFoundError:\n            return False\n\n    def readlink(self, path: str) -&gt; str:DOCS\n        \"\"\"Read symlink target from metadata.\n\n        Args:\n            path: S3 path\n\n        Returns:\n            Symlink target path\n        \"\"\"\n        metadata = self.get_metadata(path)\n        target = metadata.get(\"Metadata\", {}).get(  # type: ignore[union-attr, call-overload]\n            self.__class__.symlink_target_metaname\n        )\n        if not target:\n            raise ValueError(f\"Not a symlink: {path}\")\n        return target  # type: ignore[no-any-return]\n\n    def symlink_to(self, path: str, target: str) -&gt; None:DOCS\n        \"\"\"Create symlink by storing target in metadata.\n\n        Args:\n            path: S3 path for the symlink\n            target: Target path the symlink should point to\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        # Create empty object with symlink metadata\n        self._client.put_object(\n            Bucket=bucket,\n            Key=key,\n            Body=b\"\",\n            Metadata={self.__class__.symlink_target_metaname: target},\n        )\n\n    def glob(self, path: str, pattern: str) -&gt; Iterator[str]:DOCS\n        \"\"\"Glob for files matching pattern.\n\n        Args:\n            path: Base S3 path\n            pattern: Glob pattern (e.g., \"*.txt\", \"**/*.py\")\n\n        Returns:\n            List of matching paths (as PanPath objects or strings)\n        \"\"\"\n        from fnmatch import fnmatch\n\n        bucket, prefix = self.__class__._parse_path(path)\n\n        # Handle recursive patterns\n        if \"**\" in pattern:\n            # Recursive search - list all objects under prefix\n            paginator = self._client.get_paginator(\"list_objects_v2\")\n            pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n\n            # Extract the pattern part after **\n            pattern_parts = pattern.split(\"**/\")\n            if len(pattern_parts) &gt; 1:\n                file_pattern = pattern_parts[-1]\n            else:\n                file_pattern = \"*\"\n\n            for page in pages:\n                for obj in page.get(\"Contents\", []):\n                    key = obj[\"Key\"]\n                    if fnmatch(key, f\"*{file_pattern}\"):\n                        path_str = f\"{self.prefix[0]}://{bucket}/{key}\"\n                        yield path_str\n        else:\n            # Non-recursive - list objects with delimiter\n            prefix_with_slash = f\"{prefix}/\" if prefix and not prefix.endswith(\"/\") else prefix\n            response = self._client.list_objects_v2(\n                Bucket=bucket, Prefix=prefix_with_slash, Delimiter=\"/\"\n            )\n\n            for obj in response.get(\"Contents\", []):\n                key = obj[\"Key\"]\n                if fnmatch(key, f\"{prefix_with_slash}{pattern}\"):\n                    path_str = f\"{self.prefix[0]}://{bucket}/{key}\"\n                    yield path_str\n\n    def walk(DOCS\n        self, path: str\n    ) -&gt; Iterator[tuple[str, list[str], list[str]]]:\n        \"\"\"Walk directory tree.\n\n        Args:\n            path: Base S3 path\n\n        Returns:\n            List of (dirpath, dirnames, filenames) tuples\n        \"\"\"\n        bucket, prefix = self.__class__._parse_path(path)\n\n        # List all objects under prefix\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        paginator = self._client.get_paginator(\"list_objects_v2\")\n        pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n\n        # Organize into directory structure\n        dirs: dict[str, tuple[set[str], set[str]]] = {}  # dirpath -&gt; (subdirs, files)\n\n        for page in pages:\n            for obj in page.get(\"Contents\", []):\n                key = obj[\"Key\"]\n                # Get relative path from prefix\n                rel_path = key[len(prefix) :] if prefix else key\n\n                # Split into directory and filename\n                parts = rel_path.split(\"/\")\n                if len(parts) == 1:\n                    # File in root\n                    if path not in dirs:\n                        dirs[path] = (set(), set())\n                    if parts[0]:  # Skip empty strings\n                        dirs[path][1].add(parts[0])\n                else:\n                    # File in subdirectory\n                    # First, ensure root directory exists and add the first subdir to it\n                    if path not in dirs:  # pragma: no cover\n                        dirs[path] = (set(), set())\n                    if parts[0]:  # Add first-level subdirectory to root\n                        dirs[path][0].add(parts[0])\n\n                    for i in range(len(parts) - 1):\n                        dir_path = (\n                            f\"{path}/\" + \"/\".join(parts[: i + 1])\n                            if path\n                            else \"/\".join(parts[: i + 1])\n                        )\n                        if dir_path not in dirs:\n                            dirs[dir_path] = (set(), set())\n\n                        # Add subdirectory if not last part\n                        if i &lt; len(parts) - 2:\n                            dirs[dir_path][0].add(parts[i + 1])\n\n                    # Add file to its parent directory\n                    parent_dir = f\"{path}/\" + \"/\".join(parts[:-1]) if path else \"/\".join(parts[:-1])\n                    if parent_dir not in dirs:  # pragma: no cover\n                        dirs[parent_dir] = (set(), set())\n                    if parts[-1]:  # Skip empty strings\n                        dirs[parent_dir][1].add(parts[-1])\n\n        for d, (subdirs, files) in dirs.items():\n            yield d, sorted(subdirs), sorted(filter(None, files))\n\n    def touch(self, path: str, exist_ok: bool = True) -&gt; None:DOCS\n        \"\"\"Create empty file.\n\n        Args:\n            path: S3 path\n            exist_ok: If False, raise error if file exists\n        \"\"\"\n        if not exist_ok and self.exists(path):\n            raise FileExistsError(f\"File already exists: {path}\")\n\n        bucket, key = self.__class__._parse_path(path)\n        self._client.put_object(Bucket=bucket, Key=key, Body=b\"\")\n\n    def rename(self, source: str, target: str) -&gt; None:DOCS\n        \"\"\"Rename/move file.\n\n        Args:\n            source: Source S3 path\n            target: Target S3 path\n        \"\"\"\n        # Copy to new location\n        src_bucket, src_key = self.__class__._parse_path(source)\n        tgt_bucket, tgt_key = self.__class__._parse_path(target)\n\n        # Copy object\n        self._client.copy_object(\n            Bucket=tgt_bucket, Key=tgt_key, CopySource={\"Bucket\": src_bucket, \"Key\": src_key}\n        )\n\n        # Delete source\n        self._client.delete_object(Bucket=src_bucket, Key=src_key)\n\n    def rmdir(self, path: str) -&gt; None:DOCS\n        \"\"\"Remove directory marker.\n\n        Args:\n            path: S3 path\n        \"\"\"\n        bucket, key = self.__class__._parse_path(path)\n\n        # Ensure key ends with / for directory marker\n        if key and not key.endswith(\"/\"):\n            key += \"/\"\n\n        # client.delete_object will not raise error if object doesn't exist\n        if not self.exists(path):\n            raise FileNotFoundError(f\"Directory not found: {path}\")\n\n        # Check if it is empty\n        if self.is_dir(path) and list(self.list_dir(path)):\n            raise OSError(f\"Directory not empty: {path}\")\n\n        self._client.delete_object(Bucket=bucket, Key=key)\n\n    def rmtree(self, path: str, ignore_errors: bool = False, onerror: Optional[Any] = None) -&gt; None:DOCS\n        \"\"\"Remove directory and all its contents recursively.\n\n        Args:\n            path: S3 path\n            ignore_errors: If True, errors are ignored\n            onerror: Callable that accepts (function, path, excinfo)\n        \"\"\"\n        bucket, prefix = self.__class__._parse_path(path)\n\n        # Ensure prefix ends with / for directory listing\n        if prefix and not prefix.endswith(\"/\"):\n            prefix += \"/\"\n\n        try:\n            # List all objects with this prefix\n            objects_to_delete = []\n            paginator = self._client.get_paginator(\"list_objects_v2\")\n            for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n                if \"Contents\" in page:\n                    objects_to_delete.extend([{\"Key\": obj[\"Key\"]} for obj in page[\"Contents\"]])\n\n            # Delete in batches (max 1000 per request)\n            if objects_to_delete:\n                for i in range(0, len(objects_to_delete), 1000):\n                    batch = objects_to_delete[i : i + 1000]\n                    self._client.delete_objects(Bucket=bucket, Delete={\"Objects\": batch})\n        except Exception:  # pragma: no cover\n            if ignore_errors:\n                return\n            if onerror is not None:\n                import sys\n\n                onerror(self._client.delete_objects, path, sys.exc_info())\n            else:\n                raise\n\n    def copy(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy file to target.\n\n        Args:\n            source: Source S3 path\n            target: Target S3 path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        if not self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and self.is_symlink(source):\n            source = self.readlink(source)\n\n        # Check if source is a directory\n        if self.is_dir(source):\n            raise IsADirectoryError(f\"Source is a directory: {source}\")\n\n        src_bucket, src_key = self.__class__._parse_path(source)\n        tgt_bucket, tgt_key = self.__class__._parse_path(target)\n\n        # Use S3's native copy operation\n        self._client.copy_object(\n            Bucket=tgt_bucket, Key=tgt_key, CopySource={\"Bucket\": src_bucket, \"Key\": src_key}\n        )\n\n    def copytree(self, source: str, target: str, follow_symlinks: bool = True) -&gt; None:DOCS\n        \"\"\"Copy directory tree to target recursively.\n\n        Args:\n            source: Source S3 path\n            target: Target S3 path\n            follow_symlinks: If False, symlinks are copied as symlinks (not dereferenced)\n        \"\"\"\n        # Check if source exists\n        if not self.exists(source):\n            raise FileNotFoundError(f\"Source not found: {source}\")\n\n        if follow_symlinks and self.is_symlink(source):\n            source = self.readlink(source)\n\n        # Check if source is a directory\n        if not self.is_dir(source):\n            raise NotADirectoryError(f\"Source is not a directory: {source}\")\n\n        src_bucket, src_prefix = self.__class__._parse_path(source)\n        tgt_bucket, tgt_prefix = self.__class__._parse_path(target)\n\n        # Ensure prefixes end with / for directory operations\n        if src_prefix and not src_prefix.endswith(\"/\"):\n            src_prefix += \"/\"\n        if tgt_prefix and not tgt_prefix.endswith(\"/\"):\n            tgt_prefix += \"/\"\n\n        # List all objects with source prefix\n        paginator = self._client.get_paginator(\"list_objects_v2\")\n        for page in paginator.paginate(Bucket=src_bucket, Prefix=src_prefix):\n            if \"Contents\" not in page:  # pragma: no cover\n                continue\n\n            for obj in page[\"Contents\"]:\n                src_key = obj[\"Key\"]\n                # Calculate relative path and target key\n                rel_path = src_key[len(src_prefix) :]\n                tgt_key = tgt_prefix + rel_path\n\n                # Copy object\n                self._client.copy_object(\n                    Bucket=tgt_bucket,\n                    Key=tgt_key,\n                    CopySource={\"Bucket\": src_bucket, \"Key\": src_key},\n                )\n\n\nclass S3SyncFileHandle(SyncFileHandle):DOCS\n    \"\"\"Sync file handle for S3 with chunked streaming support.\n\n    Uses boto3's streaming API for efficient reading of large files.\n    \"\"\"\n\n    def _create_stream(self):  # type: ignore[no-untyped-def]\n        \"\"\"Create the underlying stream.\"\"\"\n        return self._client.get_object(Bucket=self._bucket, Key=self._blob)[\"Body\"]\n\n    @classmethod\n    def _expception_as_filenotfound(cls, exception: Exception) -&gt; bool:\n        \"\"\"Check if exception corresponds to FileNotFoundError.\"\"\"\n        if isinstance(exception, ClientError):\n            error_code = exception.response.get(\"Error\", {}).get(\"Code\")\n            return error_code in (\"NoSuchKey\", \"NoSuchBucket\", \"404\")\n        return False  # pragma: no cover\n\n    def _upload(self, data: Union[str, bytes]) -&gt; None:\n        \"\"\"Upload data to S3 using append semantics.\n\n        This method appends data using multipart upload.\n        For 'w' mode on first write, it overwrites. Subsequently it appends.\n        For 'a' mode, it always appends.\n\n        Args:\n            data: Data to upload\n                (will be appended to existing content after first write)\n        \"\"\"\n        if isinstance(data, str):\n            data = data.encode(self._encoding)\n\n        # For 'w' mode on first write, overwrite existing content\n        if self._first_write and not self._is_append:\n            self._first_write = False\n            # Simple overwrite\n            self._client.put_object(Bucket=self._bucket, Key=self._blob, Body=data)\n            return\n\n        self._first_write = False\n\n        # For subsequent writes or append mode, use read-modify-write\n        # Check if object exists\n        try:\n            self._client.head_object(Bucket=self._bucket, Key=self._blob)\n            object_exists = True\n        except ClientError as e:\n            if e.response.get(\"Error\", {}).get(\"Code\") in (\"NoSuchKey\", \"404\"):\n                object_exists = False\n            else:  # pragma: no cover\n                raise\n\n        if not object_exists:\n            # Simple upload for new objects\n            self._client.put_object(Bucket=self._bucket, Key=self._blob, Body=data)\n        else:\n            # For existing objects, download, concatenate, and re-upload\n            response = self._client.get_object(Bucket=self._bucket, Key=self._blob)\n            existing_data = response[\"Body\"].read()\n            combined_data = existing_data + data\n            self._client.put_object(\n                Bucket=self._bucket, Key=self._blob, Body=combined_data\n            )\n</code></pre>"},{"location":"api/source/panpath.s3_path/","title":"panpath.s3_path","text":""},{"location":"api/source/panpath.s3_path/","title":"SOURCE CODE panpath.s3_path DOCS","text":"<pre><code>\"\"\"S3 path implementation.\"\"\"\n\nfrom typing import TYPE_CHECKING, Optional\n\nfrom panpath.cloud import CloudPath\nfrom panpath.s3_client import S3Client\nfrom panpath.s3_async_client import AsyncS3Client\n\nif TYPE_CHECKING:\n    from panpath.clients import Client, AsyncClient\n\n\nclass S3Path(CloudPath):DOCS\n    \"\"\"S3 path implementation (sync and async methods).\"\"\"\n\n    _client: Optional[S3Client] = None\n    _default_client: Optional[S3Client] = None\n\n    @classmethod\n    def _create_default_client(cls) -&gt; \"Client\":  # type: ignore[override]\n        \"\"\"Create default S3 client.\"\"\"\n        return S3Client()\n\n    @classmethod\n    def _create_default_async_client(cls) -&gt; \"AsyncClient\":\n        \"\"\"Create default async S3 client.\"\"\"\n        return AsyncS3Client()\n</code></pre>"},{"location":"getting-started/concepts/","title":"Basic Concepts","text":"<p>Understanding PanPath's architecture and design principles will help you use it effectively.</p>"},{"location":"getting-started/concepts/#core-principles","title":"Core Principles","text":""},{"location":"getting-started/concepts/#1-unified-interface","title":"1. Unified Interface","text":"<p>PanPath provides a single, consistent API that works across different storage backends:</p> <pre><code>from panpath import PanPath\n\n# All these use the same interface\nlocal = PanPath(\"/tmp/file.txt\")\ns3 = PanPath(\"s3://bucket/file.txt\")\ngcs = PanPath(\"gs://bucket/file.txt\")\nazure = PanPath(\"az://container/file.txt\")\n\n# Same operations work on all\nfor path in [local, s3, gcs, azure]:\n    path.write_text(\"Same API\")\n    content = path.read_text()\n    print(path.exists())\n</code></pre>"},{"location":"getting-started/concepts/#2-pathlib-compatibility","title":"2. Pathlib Compatibility","text":"<p>For local files, PanPath is a drop-in replacement for <code>pathlib.Path</code>:</p> <pre><code>from pathlib import Path\nfrom panpath import PanPath\n\n# These work identically for local paths\npathlib_path = Path(\"/tmp/file.txt\")\npan_path = PanPath(\"/tmp/file.txt\")\n\n# Same operations\npathlib_path.write_text(\"Hello\")\npan_path.write_text(\"Hello\")\n\n# Same properties\nassert pathlib_path.name == pan_path.name\nassert pathlib_path.suffix == pan_path.suffix\n</code></pre>"},{"location":"getting-started/concepts/#3-unified-sync-and-async","title":"3. Unified Sync and Async","text":"<p>Every path class provides both synchronous and asynchronous methods:</p> <pre><code>from panpath import PanPath\n\n# Create a path - same class for both sync and async\npath = PanPath(\"s3://bucket/file.txt\")\n\n# Synchronous methods (blocks until complete)\ncontent = path.read_text()  # Blocks\n\n# Asynchronous methods use a_ prefix (non-blocking)\ncontent = await path.a_read_text()  # Non-blocking\n\n# Both sync and async methods available on same instance\npath.write_text(\"sync write\")  # Sync\nawait path.a_write_text(\"async write\")  # Async\n</code></pre>"},{"location":"getting-started/concepts/#architecture","title":"Architecture","text":""},{"location":"getting-started/concepts/#path-resolution","title":"Path Resolution","text":"<p>PanPath uses URI schemes to route to the appropriate backend:</p> <pre><code>graph TD\n    A[PanPath] --&gt; B{Parse URI}\n    B --&gt;|No scheme or file://| C[LocalPath]\n    B --&gt;|s3://| D[S3Path]\n    B --&gt;|gs://| E[GSPath]\n    B --&gt;|az:// or azure://| F[AzurePath]\n\n    C --&gt; G[\"Sync methods: read_text(), write_text(), ...\"]\n    D --&gt; G\n    E --&gt; G\n    F --&gt; G\n\n    C --&gt; H[\"Async methods: a_read_text(), a_write_text(), ...\"]\n    D --&gt; H\n    E --&gt; H\n    F --&gt; H</code></pre>"},{"location":"getting-started/concepts/#client-management","title":"Client Management","text":"<p>Cloud clients are created lazily and reused:</p> <pre><code>from panpath import PanPath\n\n# First S3 path creates a client\npath1 = PanPath(\"s3://bucket1/file.txt\")\n\n# Second S3 path reuses the same client\npath2 = PanPath(\"s3://bucket2/file.txt\")\n\n# Different backend creates a different client\npath3 = PanPath(\"gs://bucket/file.txt\")\n</code></pre> <p>Performance</p> <p>Client reuse means you don't pay the initialization cost for each path instance.</p>"},{"location":"getting-started/concepts/#registry-system","title":"Registry System","text":"<p>Path classes are registered by URI scheme:</p> <pre><code>from panpath.registry import register_path_class, get_path_class\nfrom panpath.s3_path import S3Path\n\n# Registration (automatic for built-in backends)\nregister_path_class(\"s3\", S3Path)\n\n# Retrieval (used internally)\npath_class = get_path_class(\"s3\")  # Returns S3Path\n</code></pre>"},{"location":"getting-started/concepts/#path-classes","title":"Path Classes","text":""},{"location":"getting-started/concepts/#unified-path-classes","title":"Unified Path Classes","text":"<pre><code>from panpath import PanPath\nfrom panpath.s3_path import S3Path\n\n# Factory pattern - PanPath returns appropriate class\npath = PanPath(\"s3://bucket/file.txt\")\nprint(type(path))  # &lt;class 'panpath.s3_path.S3Path'&gt;\n\n# All methods available on same instance\ncontent = path.read_text()  # Sync\ncontent = await path.a_read_text()  # Async\n\n# Type checking\nisinstance(path, PanPath)  # True (inherits from PanPath)\nisinstance(path, S3Path)   # True (actual type)\n</code></pre> <p>Async Methods</p> <p>All async methods are prefixed with <code>a_</code> for easy identification:</p> <ul> <li><code>read_text()</code> \u2192 <code>a_read_text()</code></li> <li><code>write_bytes()</code> \u2192 <code>a_write_bytes()</code></li> <li><code>exists()</code> \u2192 <code>a_exists()</code></li> <li><code>iterdir()</code> \u2192 <code>a_iterdir()</code></li> </ul>"},{"location":"getting-started/concepts/#storage-concepts","title":"Storage Concepts","text":""},{"location":"getting-started/concepts/#local-paths","title":"Local Paths","text":"<p>Local paths represent files and directories on the filesystem:</p> <pre><code>from panpath import PanPath\n\npath = PanPath(\"/tmp/file.txt\")\n# or\npath = PanPath(\"file:///tmp/file.txt\")\n\n# Supports all pathlib operations\npath.resolve()\npath.absolute()\npath.expanduser()\n</code></pre>"},{"location":"getting-started/concepts/#cloud-paths","title":"Cloud Paths","text":"<p>Cloud paths use URI schemes to represent cloud storage objects:</p> <pre><code>from panpath import PanPath\n\n# Format: scheme://bucket_or_container/key_or_path\ns3 = PanPath(\"s3://my-bucket/path/to/object.txt\")\ngcs = PanPath(\"gs://my-bucket/path/to/object.txt\")\nazure = PanPath(\"az://my-container/path/to/blob.txt\")\n</code></pre> <p>Key differences from local paths:</p> <ul> <li>No absolute/relative distinction: All cloud paths are absolute</li> <li>No symlinks: Cloud storage doesn't support symbolic links</li> <li>Different permissions model: Uses cloud IAM instead of filesystem permissions</li> <li>No hard links: Each object is independent</li> </ul>"},{"location":"getting-started/concepts/#buckets-and-containers","title":"Buckets and Containers","text":"<p>The first component after the scheme is the bucket (S3/GCS) or container (Azure):</p> <pre><code>from panpath import PanPath\n\ns3_path = PanPath(\"s3://my-bucket/folder/file.txt\")\nprint(s3_path.parts)  # ('s3://my-bucket', 'folder', 'file.txt')\n\n# Cloud-specific properties\nprint(s3_path.cloud_prefix)  # s3://my-bucket\nprint(s3_path.key)           # folder/file.txt\n</code></pre>"},{"location":"getting-started/concepts/#operations","title":"Operations","text":""},{"location":"getting-started/concepts/#synchronous-operations","title":"Synchronous Operations","text":"<p>Block until completion:</p> <pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://bucket/file.txt\")\n\n# These block the thread\ncontent = path.read_text()\npath.write_text(\"new content\")\nexists = path.exists()\nitems = list(path.iterdir())\n</code></pre> <p>Use when:</p> <ul> <li>Writing simple scripts</li> <li>Working in synchronous frameworks (Flask, Django)</li> <li>Operations are infrequent</li> <li>Code simplicity is more important than concurrency</li> </ul>"},{"location":"getting-started/concepts/#asynchronous-operations","title":"Asynchronous Operations","text":"<p>Return coroutines that can be awaited:</p> <pre><code>from panpath import PanPath\nimport asyncio\n\nasync def main():\n    path = PanPath(\"s3://bucket/file.txt\")\n\n    # These are non-blocking\n    content = await path.a_read_text()\n    await path.a_write_text(\"new content\")\n    exists = await path.a_exists()\n    items = await path.a_iterdir()\n\nasyncio.run(main())\n</code></pre> <p>Use when:</p> <ul> <li>Building async applications (FastAPI, aiohttp)</li> <li>Need high concurrency</li> <li>Performing many I/O operations</li> <li>Want better resource utilization</li> </ul>"},{"location":"getting-started/concepts/#parallel-async-operations","title":"Parallel Async Operations","text":"<p>Async mode enables concurrent operations:</p> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def download_all(urls):\n    # Create async paths\n    paths = [PanPath(url) for url in urls]\n\n    # Download all concurrently\n    contents = await asyncio.gather(*[p.a_read_text() for p in paths])\n\n    return contents\n\nurls = [\n    \"s3://bucket/file1.txt\",\n    \"s3://bucket/file2.txt\",\n    \"s3://bucket/file3.txt\",\n]\nasyncio.run(download_all(urls))\n</code></pre>"},{"location":"getting-started/concepts/#error-handling","title":"Error Handling","text":""},{"location":"getting-started/concepts/#common-exceptions","title":"Common Exceptions","text":"<pre><code>from panpath import PanPath\nfrom panpath.exceptions import (\n    PanPathException,\n    PathNotFoundError,\n    PermissionError,\n)\n\npath = PanPath(\"s3://bucket/nonexistent.txt\")\n\ntry:\n    content = path.read_text()\nexcept PathNotFoundError:\n    print(\"File not found\")\nexcept PermissionError:\n    print(\"Access denied\")\nexcept PanPathException as e:\n    print(f\"Other error: {e}\")\n</code></pre>"},{"location":"getting-started/concepts/#backend-specific-errors","title":"Backend-Specific Errors","text":"<p>Cloud backends may raise provider-specific errors:</p> <pre><code>from panpath import PanPath\nimport botocore.exceptions\n\npath = PanPath(\"s3://bucket/file.txt\")\n\ntry:\n    content = path.read_text()\nexcept botocore.exceptions.NoCredentialsError:\n    print(\"AWS credentials not configured\")\nexcept botocore.exceptions.ClientError as e:\n    print(f\"AWS error: {e}\")\n</code></pre>"},{"location":"getting-started/concepts/#best-practices","title":"Best Practices","text":""},{"location":"getting-started/concepts/#1-use-type-hints","title":"1. Use Type Hints","text":"<pre><code>from panpath import PanPath\nfrom pathlib import Path\n\ndef process_file(path: PanPath) -&gt; str:\n    \"\"\"Can be sync or async path.\"\"\"\n    return path.read_text()\n\nasync def process_async(path: PanPath) -&gt; str:\n    \"\"\"Must be async path.\"\"\"\n    return await path.a_read_text()\n\ndef process_local(path: Path | PanPath) -&gt; str:\n    \"\"\"Accept pathlib.Path or PanPath.\"\"\"\n    if isinstance(path, Path):\n        path = PanPath(str(path))\n    return path.a_read_text()\n</code></pre>"},{"location":"getting-started/concepts/#2-handle-optional-dependencies","title":"2. Handle Optional Dependencies","text":"<pre><code>from panpath import PanPath\n\ndef get_data(uri: str) -&gt; str:\n    try:\n        path = PanPath(uri)\n        return path.read_text()\n    except ImportError as e:\n        raise RuntimeError(\n            f\"Cloud backend not installed: {e}\\n\"\n            f\"Install with: pip install panpath[s3]\"\n        )\n</code></pre>"},{"location":"getting-started/concepts/#3-use-context-managers","title":"3. Use Context Managers","text":"<pre><code>from panpath import PanPath\n\n# Good: File is automatically closed\nwith PanPath(\"s3://bucket/file.txt\").open(\"r\") as f:\n    content = f.read()\n\n# Also good for async\nfrom panpath import PanPath\n\nasync def read_file():\n    async with PanPath(\"s3://bucket/file.txt\").a_open(\"r\") as f:\n        content = await f.a_read()\n</code></pre>"},{"location":"getting-started/concepts/#4-prefer-bulk-operations","title":"4. Prefer Bulk Operations","text":"<pre><code>from panpath import PanPath\n\n# Less efficient: Individual copies\nsrc_dir = PanPath(\"s3://bucket/data/\")\ndst_dir = PanPath(\"gs://other/data/\")\nfor item in src_dir.iterdir():\n    item.copy(dst_dir / item.name)\n\n# More efficient: Use copytree\nsrc_dir.copytree(dst_dir)\n</code></pre>"},{"location":"getting-started/concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Local Paths Guide - Learn about local filesystem operations</li> <li>Cloud Storage Guide - Cloud-specific features</li> <li>Async Operations Guide - Deep dive into async</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<p>PanPath requires Python 3.9 or higher.</p>"},{"location":"getting-started/installation/#core-installation","title":"Core Installation","text":"<p>Install the core library which includes support for local file operations:</p> <pre><code>pip install panpath\n</code></pre> <p>The core installation includes:</p> <ul> <li>\u2705 Local filesystem support (sync and async)</li> <li>\u2705 Path manipulation and operations</li> <li>\u2705 Type hints and type safety</li> <li>\u2705 Zero cloud dependencies</li> </ul>"},{"location":"getting-started/installation/#cloud-storage-support","title":"Cloud Storage Support","text":"<p>PanPath uses optional dependencies for cloud storage backends. Install only what you need:</p>"},{"location":"getting-started/installation/#amazon-s3","title":"Amazon S3","text":"SynchronousAsynchronous <pre><code>pip install panpath[s3]\n</code></pre> <p>Installs: <code>boto3&gt;=1.20.0</code></p> <pre><code>pip install panpath[async-s3]\n</code></pre> <p>Installs: <code>aioboto3&gt;=11.0.0</code>, <code>aiofiles&gt;=23.0.0</code></p>"},{"location":"getting-started/installation/#google-cloud-storage","title":"Google Cloud Storage","text":"SynchronousAsynchronous <pre><code>pip install panpath[gs]\n</code></pre> <p>Installs: <code>google-cloud-storage&gt;=2.0.0</code></p> <pre><code>pip install panpath[async-gs]\n</code></pre> <p>Installs: <code>gcloud-aio-storage&gt;=8.0.0</code>, <code>aiofiles&gt;=23.0.0</code></p>"},{"location":"getting-started/installation/#azure-blob-storage","title":"Azure Blob Storage","text":"SynchronousAsynchronous <pre><code>pip install panpath[azure]\n</code></pre> <p>Installs: <code>azure-storage-blob&gt;=12.0.0</code></p> <pre><code>pip install panpath[async-azure]\n</code></pre> <p>Installs: <code>azure-storage-blob[aio]&gt;=12.0.0</code>, <code>aiofiles&gt;=23.0.0</code></p>"},{"location":"getting-started/installation/#convenience-bundles","title":"Convenience Bundles","text":""},{"location":"getting-started/installation/#all-sync-backends","title":"All Sync Backends","text":"<p>Install all synchronous cloud storage backends:</p> <pre><code>pip install panpath[all-sync]\n</code></pre> <p>Includes: S3, Google Cloud Storage, and Azure Blob Storage (sync only)</p>"},{"location":"getting-started/installation/#all-async-backends","title":"All Async Backends","text":"<p>Install all asynchronous cloud storage backends:</p> <pre><code>pip install panpath[all-async]\n</code></pre> <p>Includes: S3, Google Cloud Storage, and Azure Blob Storage (async only)</p>"},{"location":"getting-started/installation/#everything","title":"Everything","text":"<p>Install all backends (both sync and async):</p> <pre><code>pip install panpath[all]\n</code></pre> <p>Includes: All sync and async backends for all cloud providers</p>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>To contribute to PanPath or run tests:</p> <pre><code># Clone the repository\ngit clone https://github.com/pwwang/panpath.git\ncd panpath\n\n# Install in development mode with all dependencies\npip install -e .[all,dev]\n</code></pre> <p>The <code>dev</code> extra includes:</p> <ul> <li><code>pytest&gt;=7.0.0</code> - Testing framework</li> <li><code>pytest-asyncio&gt;=0.21.0</code> - Async test support</li> <li><code>pytest-cov&gt;=4.0.0</code> - Coverage reporting</li> <li><code>mypy&gt;=1.0.0</code> - Type checking</li> <li><code>black&gt;=23.0.0</code> - Code formatting</li> <li><code>ruff&gt;=0.1.0</code> - Linting</li> <li><code>moto[s3]&gt;=4.0.0</code> - AWS mocking for tests</li> </ul>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify that PanPath is working:</p> <pre><code>from panpath import PanPath\n\n# Test local paths\nlocal = PanPath(\"/tmp/test.txt\")\nprint(f\"Local path created: {local}\")\n\n# Test cloud paths (if installed)\ntry:\n    s3 = PanPath(\"s3://bucket/key\")\n    print(f\"S3 path created: {s3}\")\nexcept ImportError as e:\n    print(f\"S3 not available: {e}\")\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#import-errors","title":"Import Errors","text":"<p>If you see <code>ImportError</code> when trying to use cloud paths:</p> <pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://bucket/key\")  # ImportError!\n</code></pre> <p>Solution: Install the appropriate cloud backend:</p> <pre><code>pip install panpath[s3]\n</code></pre>"},{"location":"getting-started/installation/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>If you encounter dependency conflicts:</p> <ol> <li> <p>Use a virtual environment:    <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install panpath[all]\n</code></pre></p> </li> <li> <p>Update pip:    <pre><code>pip install --upgrade pip\n</code></pre></p> </li> <li> <p>Check installed packages:    <pre><code>pip list | grep -E \"(boto3|google-cloud-storage|azure-storage-blob|aiofiles)\"\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#version-requirements","title":"Version Requirements","text":"<p>Ensure you're using a supported Python version:</p> <pre><code>python --version  # Should be 3.8 or higher\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Learn the basics with hands-on examples</li> <li>Basic Concepts - Understand PanPath's architecture</li> <li>User Guide - Dive into detailed feature documentation</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will get you up and running with PanPath in minutes.</p>"},{"location":"getting-started/quick-start/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/quick-start/#local-files","title":"Local Files","text":"<p>PanPath works just like <code>pathlib.Path</code> for local files:</p> <pre><code>from panpath import PanPath\n\n# Create a path\npath = PanPath(\"/tmp/example.txt\")\n\n# Write content\npath.write_text(\"Hello, PanPath!\")\n\n# Read content\ncontent = path.read_text()\nprint(content)  # Hello, PanPath!\n\n# Path operations\nparent = path.parent\nsibling = parent / \"another.txt\"\nprint(parent)   # /tmp\nprint(sibling)  # /tmp/another.txt\n</code></pre>"},{"location":"getting-started/quick-start/#cloud-storage","title":"Cloud Storage","text":"<p>The same API works for cloud storage:</p> Amazon S3Google Cloud StorageAzure Blob Storage <pre><code>from panpath import PanPath\n\n# Create S3 path\ns3_path = PanPath(\"s3://my-bucket/data/file.txt\")\n\n# Write to S3\ns3_path.write_text(\"Upload to S3\")\n\n# Read from S3\ncontent = s3_path.read_text()\n\n# List directory\ns3_dir = PanPath(\"s3://my-bucket/data/\")\nfor item in s3_dir.iterdir():\n    print(item)\n</code></pre> <pre><code>from panpath import PanPath\n\n# Create GCS path\ngs_path = PanPath(\"gs://my-bucket/data/file.txt\")\n\n# Write to GCS\ngs_path.write_text(\"Upload to GCS\")\n\n# Read from GCS\ncontent = gs_path.read_text()\n\n# Check if exists\nif gs_path.exists():\n    print(\"File exists!\")\n</code></pre> <pre><code>from panpath import PanPath\n\n# Create Azure path\nazure_path = PanPath(\"az://my-container/data/file.txt\")\n\n# Async operations\nawait azure_path.a_write_bytes(b\"Binary data\")\ndata = await azure_path.a_read_bytes()\nis_file = await azure_path.a_is_file()\n</code></pre>"},{"location":"getting-started/quick-start/#async-operations","title":"Async Operations","text":"<p>All path classes support asynchronous methods with the <code>a_</code> prefix:</p> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    # Any path supports both sync and async methods\n    path = PanPath(\"s3://bucket/file.txt\")\n\n    # Async methods use a_ prefix\n    await path.a_write_text(\"Async upload\")\n    content = await path.a_read_text()\n    print(content)\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/quick-start/#async-context-manager","title":"Async Context Manager","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    path = PanPath(\"gs://bucket/file.txt\")\n\n    # Use async context manager\n    async with path.a_open(\"w\") as f:\n        await f.write(\"Line 1\\n\")\n        await f.write(\"Line 2\\n\")\n\n    # Read back\n    async with path.a_open(\"r\") as f:\n        content = await f.read()\n        print(content)\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/quick-start/#common-operations","title":"Common Operations","text":""},{"location":"getting-started/quick-start/#reading-and-writing","title":"Reading and Writing","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://bucket/data.txt\")\n\n# Text files\npath.write_text(\"Hello World\")\ntext = path.read_text()\n\n# Binary files\npath.write_bytes(b\"\\x00\\x01\\x02\")\ndata = path.read_bytes()\n\n# Using open()\nwith path.open(\"w\") as f:\n    f.write(\"Line 1\\n\")\n    f.write(\"Line 2\\n\")\n\nwith path.open(\"r\") as f:\n    for line in f:\n        print(line.strip())\n</code></pre>"},{"location":"getting-started/quick-start/#path-manipulation","title":"Path Manipulation","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://bucket/data/file.txt\")\n\n# Get components\nprint(path.name)        # file.txt\nprint(path.stem)        # file\nprint(path.suffix)      # .txt\nprint(path.parent)      # s3://bucket/data\n\n# Join paths\nnew_path = path.parent / \"other.txt\"\nprint(new_path)  # s3://bucket/data/other.txt\n\n# Change components\nrenamed = path.with_name(\"newfile.txt\")\nprint(renamed)  # s3://bucket/data/newfile.txt\n\ndifferent_ext = path.with_suffix(\".csv\")\nprint(different_ext)  # s3://bucket/data/file.csv\n</code></pre>"},{"location":"getting-started/quick-start/#checking-path-properties","title":"Checking Path Properties","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"gs://bucket/file.txt\")\n\n# Check existence\nif path.exists():\n    print(\"File exists\")\n\n# Check type\nif path.is_file():\n    print(\"It's a file\")\nelif path.is_dir():\n    print(\"It's a directory\")\n\n# Get metadata\nstat = path.stat()\nprint(f\"Size: {stat.st_size} bytes\")\nprint(f\"Modified: {stat.st_mtime}\")\n</code></pre>"},{"location":"getting-started/quick-start/#directory-operations","title":"Directory Operations","text":"<pre><code>from panpath import PanPath\n\ndirectory = PanPath(\"s3://bucket/data/\")\n\n# List contents\nfor item in directory.iterdir():\n    print(item)\n\n# Find files matching pattern\nfor txt_file in directory.glob(\"*.txt\"):\n    print(txt_file)\n\n# Recursive search\nfor py_file in directory.rglob(\"*.py\"):\n    print(py_file)\n\n# Create directory\nnew_dir = PanPath(\"s3://bucket/newdir/\")\nnew_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"getting-started/quick-start/#bulk-operations","title":"Bulk Operations","text":"<p>Copy and move files efficiently:</p> <pre><code>from panpath import PanPath\n\n# Copy a file\nsrc = PanPath(\"s3://bucket/source.txt\")\nsrc.copy(\"s3://bucket/backup/source.txt\")\n\n# Copy a directory tree\nsrc_dir = PanPath(\"s3://bucket/data/\")\nsrc_dir.copytree(\"gs://other-bucket/data/\")\n\n# Remove a directory tree\ntemp_dir = PanPath(\"s3://bucket/temp/\")\ntemp_dir.rmtree()\n\n# Rename/move\nold_path = PanPath(\"s3://bucket/old.txt\")\nold_path.rename(\"s3://bucket/new.txt\")\n</code></pre>"},{"location":"getting-started/quick-start/#cross-storage-transfers","title":"Cross-Storage Transfers","text":"<p>Move data between different storage backends:</p> <pre><code>from panpath import PanPath\n\n# S3 to local\ns3_file = PanPath(\"s3://bucket/data.csv\")\ns3_file.copy(\"/tmp/data.csv\")\n\n# Local to GCS\nlocal_file = PanPath(\"/tmp/data.csv\")\nlocal_file.copy(\"gs://bucket/data.csv\")\n\n# S3 to Azure\ns3_file = PanPath(\"s3://bucket/file.txt\")\ns3_file.copy(\"az://container/file.txt\")\n\n# Copy entire directory from cloud to local\ncloud_dataset = PanPath(\"gs://data-lake/dataset/\")\ncloud_dataset.copytree(\"/local/dataset/\")\n</code></pre>"},{"location":"getting-started/quick-start/#configuration","title":"Configuration","text":""},{"location":"getting-started/quick-start/#environment-variables","title":"Environment Variables","text":"<p>Configure cloud credentials using environment variables:</p> AWS S3Google CloudAzure <pre><code>export AWS_ACCESS_KEY_ID=your_access_key\nexport AWS_SECRET_ACCESS_KEY=your_secret_key\nexport AWS_DEFAULT_REGION=us-east-1\n</code></pre> <pre><code>export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json\n</code></pre> <pre><code>export AZURE_STORAGE_CONNECTION_STRING=your_connection_string\n# or\nexport AZURE_STORAGE_ACCOUNT_NAME=your_account\nexport AZURE_STORAGE_ACCOUNT_KEY=your_key\n</code></pre>"},{"location":"getting-started/quick-start/#custom-client-configuration","title":"Custom Client Configuration","text":"<p>For advanced use cases, you can configure clients:</p> <pre><code>from panpath import PanPath\nfrom panpath.clients import get_s3_client\n\n# Get or create client with custom config\nclient = get_s3_client(\n    aws_access_key_id=\"your_key\",\n    aws_secret_access_key=\"your_secret\",\n    region_name=\"us-west-2\"\n)\n\n# Use the path normally\npath = PanPath(\"s3://bucket/file.txt\")\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<p>Now that you know the basics:</p> <ul> <li>Basic Concepts - Learn about PanPath's architecture</li> <li>User Guide - Explore all features in detail</li> <li>Cloud Providers - Provider-specific documentation</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/async-operations/","title":"Async Operations","text":"<p>Deep dive into asynchronous operations with PanPath.</p>"},{"location":"guide/async-operations/#why-async","title":"Why Async?","text":"<p>Async operations provide:</p> <ul> <li>Better Concurrency - Handle multiple I/O operations simultaneously</li> <li>Resource Efficiency - Non-blocking I/O uses less threads</li> <li>Performance - Faster for I/O-bound workloads</li> <li>Scalability - Handle more connections with fewer resources</li> </ul>"},{"location":"guide/async-operations/#choosing-sync-or-async","title":"Choosing Sync or Async","text":"<p>Use sync when: - Writing simple scripts - Operations are infrequent - Working with synchronous frameworks - Simplicity is more important than performance</p> <p>Use async when: - Building async applications (FastAPI, aiohttp) - Performing many I/O operations - Need high concurrency - Want better resource utilization</p>"},{"location":"guide/async-operations/#basic-async-usage","title":"Basic Async Usage","text":"<p>All path classes support async methods with the <code>a_</code> prefix:</p> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    path = PanPath(\"s3://bucket/file.txt\")\n\n    # Async operations use a_ prefix\n    await path.a_write_text(\"Content\")\n    content = await path.a_read_text()\n    exists = await path.a_exists()\n\nasyncio.run(main())\n</code></pre>"},{"location":"guide/async-operations/#parallel-operations","title":"Parallel Operations","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def download_all(uris: list[str]):\n    paths = [PanPath(uri) for uri in uris]\n\n    # Download concurrently using async methods\n    contents = await asyncio.gather(*[p.a_read_text() for p in paths])\n\n    return contents\n\nuris = [\n    \"s3://bucket/file1.txt\",\n    \"s3://bucket/file2.txt\",\n    \"s3://bucket/file3.txt\",\n]\n\nasyncio.run(download_all(uris))\n</code></pre>"},{"location":"guide/async-operations/#async-context-managers","title":"Async Context Managers","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def process_file():\n    path = PanPath(\"gs://bucket/data.txt\")\n\n    # Use a_open for async file operations\n    async with path.a_open(\"r\") as f:\n        async for line in f:\n            print(line.strip())\n\nasyncio.run(process_file())\n</code></pre>"},{"location":"guide/async-operations/#advanced-file-handle-operations","title":"Advanced File Handle Operations","text":"<p>For cloud storage providers (S3, GCS, Azure), async file handles support advanced positioning methods:</p>"},{"location":"guide/async-operations/#seek-and-tell","title":"Seek and Tell","text":"<p>The <code>seek()</code> and <code>tell()</code> methods allow you to control the file position during async operations:</p> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def read_partial_file():\n    path = PanPath(\"s3://bucket/large-file.txt\")\n\n    async with path.a_open(\"rb\") as f:\n        # Get current position\n        position = await f.tell()\n        print(f\"Current position: {position}\")  # 0\n\n        # Read first 100 bytes\n        chunk1 = await f.read(100)\n\n        # Check new position\n        position = await f.tell()\n        print(f\"Position after read: {position}\")  # 100\n\n        # Seek to a specific position\n        await f.seek(50)\n        position = await f.tell()\n        print(f\"Position after seek: {position}\")  # 50\n\n        # Read from new position\n        chunk2 = await f.read(50)\n\n        # Seek relative to current position\n        await f.seek(10, 1)  # Move 10 bytes forward from current\n\n        # Seek relative to end\n        await f.seek(-100, 2)  # Move to 100 bytes before end\n\nasyncio.run(read_partial_file())\n</code></pre> <p>Seek Modes</p> <p>The <code>seek()</code> method supports three modes:</p> <ul> <li><code>0</code> (default): Seek from beginning of file</li> <li><code>1</code>: Seek relative to current position</li> <li><code>2</code>: Seek relative to end of file</li> </ul>"},{"location":"guide/async-operations/#use-cases-for-seektell","title":"Use Cases for Seek/Tell","text":"<p>These methods are particularly useful for:</p> <ul> <li>Large file processing: Read specific chunks without loading the entire file</li> <li>Resume operations: Track position for resumable downloads/uploads</li> <li>Random access: Jump to specific offsets in structured files</li> <li>Partial reads: Read file headers or specific sections</li> </ul> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def read_file_header():\n    \"\"\"Read only the header of a large binary file.\"\"\"\n    path = PanPath(\"gs://bucket/binary-data.bin\")\n\n    async with path.a_open(\"rb\") as f:\n        # Read magic number (first 4 bytes)\n        magic = await f.read(4)\n\n        # Read version (next 2 bytes)\n        version = await f.read(2)\n\n        # Skip metadata section (1000 bytes)\n        await f.seek(1000, 1)\n\n        # Read data from offset 1006\n        data = await f.read(100)\n\n        return magic, version, data\n\nasyncio.run(read_file_header())\n</code></pre>"},{"location":"guide/async-operations/#available-async-methods","title":"Available Async Methods","text":"<p>All async methods use the <code>a_</code> prefix:</p> <ul> <li>I/O Operations: <code>a_read_text()</code>, <code>a_write_text()</code>, <code>a_read_bytes()</code>, <code>a_write_bytes()</code>, <code>a_open()</code></li> <li>Existence Checks: <code>a_exists()</code>, <code>a_is_file()</code>, <code>a_is_dir()</code></li> <li>Metadata: <code>a_stat()</code></li> <li>Directory Operations: <code>a_iterdir()</code>, <code>a_mkdir()</code>, <code>a_rmdir()</code></li> <li>File Operations: <code>a_unlink()</code></li> </ul>"},{"location":"guide/async-operations/#async-file-handle-methods","title":"Async File Handle Methods","text":"<p>When using <code>a_open()</code> with cloud storage (S3, GCS, Azure), the returned file handle supports:</p> <ul> <li><code>read(size=-1)</code>: Read up to <code>size</code> bytes (all if -1)</li> <li><code>readline()</code>: Read a single line</li> <li><code>readlines()</code>: Read all lines</li> <li><code>write(data)</code>: Write data to file</li> <li><code>seek(offset, whence=0)</code>: Move to a specific position in the file</li> <li><code>tell()</code>: Get the current position in the file</li> <li>Async iteration: Use <code>async for line in f:</code> to iterate over lines</li> </ul>"},{"location":"guide/async-operations/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Async examples</li> <li>Performance Guide - Optimization tips</li> <li>API Reference - PanPath API</li> </ul>"},{"location":"guide/bulk-operations/","title":"Bulk Operations","text":"<p>PanPath provides efficient bulk operations for working with directories and multiple files.</p>"},{"location":"guide/bulk-operations/#overview","title":"Overview","text":"<p>Bulk operations are optimized for performance and work seamlessly across different storage backends:</p> <ul> <li><code>rmtree()</code> - Remove directory and all contents</li> <li><code>copy(src, dst)</code> - Copy a single file</li> <li><code>copytree(src, dst)</code> - Copy entire directory tree</li> <li><code>rename(src, dst)</code> - Move/rename files (enhanced for cross-storage)</li> </ul> <p>All operations support:</p> <p>\u2705 Cross-storage transfers (S3 \u2194 GCS \u2194 Azure \u2194 Local) \u2705 Synchronous and asynchronous modes \u2705 Recursive directory operations \u2705 Progress tracking (where applicable)</p>"},{"location":"guide/bulk-operations/#removing-directory-trees","title":"Removing Directory Trees","text":""},{"location":"guide/bulk-operations/#basic-usage","title":"Basic Usage","text":"<p>Remove a directory and all its contents:</p> SyncAsync <pre><code>from panpath import PanPath\n\n# Remove S3 directory\ns3_dir = PanPath(\"s3://bucket/logs/\")\ns3_dir.rmtree()\n\n# Remove local directory\nlocal_dir = PanPath(\"/tmp/cache/\")\nlocal_dir.rmtree()\n\n# Remove GCS directory\ngs_dir = PanPath(\"gs://bucket/temp/\")\ngs_dir.rmtree()\n</code></pre> <pre><code>from panpath import PanPath\nimport asyncio\n\nasync def cleanup():\n    # Remove Azure directory\n    azure_dir = PanPath(\"az://container/temp/\")\n    await azure_dir.a_rmtree()\n\n    # Remove S3 directory\n    s3_dir = PanPath(\"s3://bucket/old-data/\")\n    await s3_dir.a_rmtree()\n\nasyncio.run(cleanup())\n</code></pre>"},{"location":"guide/bulk-operations/#safety-options","title":"Safety Options","text":"<pre><code>from panpath import PanPath\n\ndirectory = PanPath(\"s3://bucket/data/\")\n\n# Check before deleting\nif directory.exists() and directory.is_dir():\n    file_count = len(list(directory.rglob(\"*\")))\n    print(f\"About to delete {file_count} files\")\n\n    if input(\"Continue? (y/n): \").lower() == \"y\":\n        directory.rmtree()\n</code></pre>"},{"location":"guide/bulk-operations/#error-handling","title":"Error Handling","text":"<pre><code>from panpath import PanPath\nfrom panpath.exceptions import PathNotFoundError, PermissionError\n\ndirectory = PanPath(\"s3://bucket/data/\")\n\ntry:\n    directory.rmtree()\nexcept PathNotFoundError:\n    print(\"Directory doesn't exist\")\nexcept PermissionError:\n    print(\"Access denied\")\n</code></pre>"},{"location":"guide/bulk-operations/#copying-files","title":"Copying Files","text":""},{"location":"guide/bulk-operations/#single-file-copy","title":"Single File Copy","text":"<p>Copy a file to a new location:</p> Same StorageCross-StorageAsync <pre><code>from panpath import PanPath\n\n# S3 to S3 (server-side copy - fast!)\nsrc = PanPath(\"s3://bucket/data.csv\")\nsrc.copy(\"s3://bucket/backup/data.csv\")\n\n# GCS to GCS\nsrc = PanPath(\"gs://bucket/file.txt\")\nsrc.copy(\"gs://bucket/archive/file.txt\")\n</code></pre> <pre><code>from panpath import PanPath\n\n# S3 to GCS\ns3_file = PanPath(\"s3://bucket/data.json\")\ns3_file.copy(\"gs://other-bucket/data.json\")\n\n# Cloud to local\ncloud = PanPath(\"az://container/report.pdf\")\ncloud.copy(\"/tmp/report.pdf\")\n\n# Local to cloud\nlocal = PanPath(\"/data/upload.txt\")\nlocal.copy(\"s3://bucket/upload.txt\")\n</code></pre> <pre><code>from panpath import PanPath\nimport asyncio\n\nasync def copy_files():\n    # Async copy\n    src = PanPath(\"s3://bucket/file.txt\")\n    await src.a_copy(\"gs://other/file.txt\")\n\n    # Multiple concurrent copies\n    files = [\n        (\"s3://bucket/a.txt\", \"gs://backup/a.txt\"),\n        (\"s3://bucket/b.txt\", \"gs://backup/b.txt\"),\n        (\"s3://bucket/c.txt\", \"gs://backup/c.txt\"),\n    ]\n\n    await asyncio.gather(*[\n        PanPath(src).a_copy(dst)\n        for src, dst in files\n    ])\n\nasyncio.run(copy_files())\n</code></pre>"},{"location":"guide/bulk-operations/#copy-options","title":"Copy Options","text":"<pre><code>from panpath import PanPath\n\nsrc = PanPath(\"s3://bucket/file.txt\")\n\n# Basic copy\nsrc.copy(\"s3://bucket/backup/file.txt\")\n\n# Overwrite if exists\nsrc.copy(\"s3://bucket/backup/file.txt\", overwrite=True)\n\n# Copy to PanPath object\ndst = PanPath(\"gs://other/file.txt\")\nsrc.copy(dst)\n</code></pre>"},{"location":"guide/bulk-operations/#copying-directory-trees","title":"Copying Directory Trees","text":""},{"location":"guide/bulk-operations/#basic-usage_1","title":"Basic Usage","text":"<p>Copy an entire directory structure recursively:</p> DownloadUploadCloud-to-Cloud <pre><code>from panpath import PanPath\n\n# Download from S3 to local\ns3_dir = PanPath(\"s3://data-lake/dataset/\")\ns3_dir.copytree(\"/tmp/dataset/\")\n\n# Download from GCS\ngs_dir = PanPath(\"gs://bucket/models/\")\ngs_dir.copytree(\"/local/models/\")\n</code></pre> <pre><code>from panpath import PanPath\n\n# Upload from local to S3\nlocal_dir = PanPath(\"/home/user/project/\")\nlocal_dir.copytree(\"s3://backups/project/\")\n\n# Upload to Azure\nlocal_data = PanPath(\"/data/\")\nlocal_data.copytree(\"az://container/data/\")\n</code></pre> <pre><code>from panpath import PanPath\n\n# Mirror between cloud providers\ns3_dir = PanPath(\"s3://source/data/\")\ns3_dir.copytree(\"gs://target/data/\")\n\n# Azure to S3\nazure_dir = PanPath(\"az://container/files/\")\nazure_dir.copytree(\"s3://bucket/files/\")\n</code></pre>"},{"location":"guide/bulk-operations/#async-copytree","title":"Async Copytree","text":"<pre><code>from panpath import PanPath\nimport asyncio\n\nasync def backup_datasets():\n    # Async directory copy\n    src = PanPath(\"s3://production/data/\")\n    await src.a_copytree(\"s3://backup/data/\")\n\n    # Multiple concurrent copytree operations\n    tasks = [\n        PanPath(\"s3://bucket/logs/\").a_copytree(\"/backup/logs/\"),\n        PanPath(\"s3://bucket/data/\").a_copytree(\"/backup/data/\"),\n        PanPath(\"s3://bucket/config/\").a_copytree(\"/backup/config/\"),\n    ]\n    await asyncio.gather(*tasks)\n\nasyncio.run(backup_datasets())\n</code></pre>"},{"location":"guide/bulk-operations/#advanced-options","title":"Advanced Options","text":"<pre><code>from panpath import PanPath\n\nsrc_dir = PanPath(\"s3://bucket/data/\")\ndst_dir = PanPath(\"gs://other/data/\")\n\n# Basic copytree\nsrc_dir.copytree(dst_dir)\n\n# Skip existing files\nsrc_dir.copytree(dst_dir, exist_ok=True)\n\n# Custom filtering (if supported)\nsrc_dir.copytree(\n    dst_dir,\n    ignore_patterns=[\"*.tmp\", \"*.log\"]\n)\n</code></pre>"},{"location":"guide/bulk-operations/#moving-and-renaming","title":"Moving and Renaming","text":""},{"location":"guide/bulk-operations/#enhanced-cross-storage-rename","title":"Enhanced Cross-Storage Rename","text":"<p>The <code>rename()</code> method now supports cross-storage operations by copying to the destination and deleting the source:</p> Same StorageCross-StorageAsync <pre><code>from panpath import PanPath\n\n# S3 to S3 (efficient server-side rename)\nold = PanPath(\"s3://bucket/old-name.txt\")\nold.rename(\"s3://bucket/new-name.txt\")\n\n# Move to different folder\nfile = PanPath(\"s3://bucket/temp/file.txt\")\nfile.rename(\"s3://bucket/archive/file.txt\")\n</code></pre> <pre><code>from panpath import PanPath\n\n# S3 to GCS (copies then deletes)\ns3_file = PanPath(\"s3://old-bucket/file.txt\")\ns3_file.rename(\"gs://new-bucket/file.txt\")\n\n# Cloud to local\ncloud = PanPath(\"az://container/temp.log\")\ncloud.rename(\"/var/log/temp.log\")\n\n# Between any backends\nsrc = PanPath(\"gs://bucket/data.csv\")\nsrc.rename(\"s3://other/data.csv\")\n</code></pre> <pre><code>from panpath import PanPath\nimport asyncio\n\nasync def move_files():\n    # Async rename/move\n    old = PanPath(\"s3://bucket/old.txt\")\n    await old.a_rename(\"gs://other/new.txt\")\n\n    # Move multiple files concurrently\n    files = [\n        (\"s3://bucket/a.txt\", \"gs://backup/a.txt\"),\n        (\"s3://bucket/b.txt\", \"gs://backup/b.txt\"),\n    ]\n\n    await asyncio.gather(*[\n        PanPath(src).a_rename(dst)\n        for src, dst in files\n    ])\n\nasyncio.run(move_files())\n</code></pre>"},{"location":"guide/bulk-operations/#return-value","title":"Return Value","text":"<p><code>rename()</code> returns the new path:</p> <pre><code>from panpath import PanPath\n\nold_path = PanPath(\"s3://bucket/old.txt\")\nnew_path = old_path.rename(\"s3://bucket/new.txt\")\n\nprint(new_path)  # s3://bucket/new.txt\nprint(new_path.exists())  # True\nprint(old_path.exists())  # False\n</code></pre>"},{"location":"guide/bulk-operations/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guide/bulk-operations/#server-side-operations","title":"Server-Side Operations","text":"<p>When source and destination are on the same storage backend, operations use server-side APIs:</p> <pre><code>from panpath import PanPath\n\n# Fast: S3 server-side copy\ns3_src = PanPath(\"s3://bucket/large-file.bin\")\ns3_src.copy(\"s3://bucket/backup/large-file.bin\")  # No download/upload!\n\n# Fast: GCS server-side copy\ngs_src = PanPath(\"gs://bucket/data.tar.gz\")\ngs_src.copy(\"gs://bucket/archive/data.tar.gz\")  # No download/upload!\n</code></pre>"},{"location":"guide/bulk-operations/#cross-storage-transfer","title":"Cross-Storage Transfer","text":"<p>Cross-storage operations require download and upload:</p> <pre><code>from panpath import PanPath\n\n# Slower: Downloads from S3, uploads to GCS\ns3_file = PanPath(\"s3://bucket/large-file.bin\")\ns3_file.copy(\"gs://other/large-file.bin\")  # Downloads then uploads\n</code></pre>"},{"location":"guide/bulk-operations/#parallel-async-operations","title":"Parallel Async Operations","text":"<p>Use async for concurrent operations:</p> <pre><code>from panpath import PanPath\nimport asyncio\n\nasync def parallel_copy():\n    files = [f\"s3://bucket/file{i}.txt\" for i in range(100)]\n\n    # Copy all files concurrently\n    tasks = [\n        PanPath(src).a_copy(f\"gs://backup/file{i}.txt\")\n        for i, src in enumerate(files)\n    ]\n\n    await asyncio.gather(*tasks)\n    print(\"Copied 100 files concurrently!\")\n\nasyncio.run(parallel_copy())\n</code></pre>"},{"location":"guide/bulk-operations/#chunked-operations","title":"Chunked Operations","text":"<p>For very large directories, process in chunks:</p> <pre><code>from panpath import PanPath\nfrom itertools import islice\n\ndef chunked_copytree(src, dst, chunk_size=100):\n    \"\"\"Copy directory in chunks.\"\"\"\n    src_path = PanPath(src)\n    dst_path = PanPath(dst)\n\n    # Get all files\n    files = list(src_path.rglob(\"*\"))\n\n    # Process in chunks\n    for i in range(0, len(files), chunk_size):\n        chunk = files[i:i + chunk_size]\n        for file in chunk:\n            if file.is_file():\n                rel_path = file.relative_to(src_path)\n                file.copy(dst_path / rel_path)\n        print(f\"Processed {min(i + chunk_size, len(files))}/{len(files)} files\")\n\nchunked_copytree(\"s3://huge-bucket/data/\", \"/local/data/\")\n</code></pre>"},{"location":"guide/bulk-operations/#examples","title":"Examples","text":""},{"location":"guide/bulk-operations/#backup-script","title":"Backup Script","text":"<pre><code>from panpath import PanPath\nfrom datetime import datetime\n\ndef backup_to_cloud(local_dir: str, cloud_bucket: str):\n    \"\"\"Backup local directory to cloud with timestamp.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    src = PanPath(local_dir)\n    dst = PanPath(f\"{cloud_bucket}/backup_{timestamp}/\")\n\n    print(f\"Backing up {src} to {dst}...\")\n    src.copytree(dst)\n    print(\"Backup complete!\")\n\n# Usage\nbackup_to_cloud(\"/important/data/\", \"s3://backups/\")\n</code></pre>"},{"location":"guide/bulk-operations/#cleanup-old-files","title":"Cleanup Old Files","text":"<pre><code>from panpath import PanPath\nfrom datetime import datetime, timedelta\n\ndef cleanup_old_files(directory: str, days: int = 30):\n    \"\"\"Remove files older than specified days.\"\"\"\n    cutoff = datetime.now().timestamp() - (days * 86400)\n    dir_path = PanPath(directory)\n\n    for file in dir_path.rglob(\"*\"):\n        if file.is_file():\n            stat = file.stat()\n            if stat.st_mtime &lt; cutoff:\n                print(f\"Removing old file: {file}\")\n                file.unlink()\n\n# Usage\ncleanup_old_files(\"s3://bucket/logs/\", days=90)\n</code></pre>"},{"location":"guide/bulk-operations/#mirror-directories","title":"Mirror Directories","text":"<pre><code>from panpath import PanPath\n\ndef mirror_directories(src: str, dst: str, clean_dst: bool = False):\n    \"\"\"Mirror source directory to destination.\"\"\"\n    src_path = PanPath(src)\n    dst_path = PanPath(dst)\n\n    # Optionally clean destination\n    if clean_dst and dst_path.exists():\n        print(f\"Cleaning {dst_path}...\")\n        dst_path.rmtree()\n\n    # Copy directory tree\n    print(f\"Mirroring {src_path} to {dst_path}...\")\n    src_path.copytree(dst_path)\n    print(\"Mirror complete!\")\n\n# Usage\nmirror_directories(\"s3://production/data/\", \"s3://backup/data/\", clean_dst=True)\n</code></pre>"},{"location":"guide/bulk-operations/#async-batch-operations","title":"Async Batch Operations","text":"<pre><code>from panpath import PanPath\nimport asyncio\n\nasync def batch_process(files: list[str], operation: str):\n    \"\"\"Process multiple files concurrently.\"\"\"\n    paths = [PanPath(f) for f in files]\n\n    if operation == \"delete\":\n        await asyncio.gather(*[p.a_unlink() for p in paths])\n    elif operation == \"backup\":\n        await asyncio.gather(*[\n            p.a_copy(f\"s3://backup/{p.name}\")\n            for p in paths\n        ])\n\n    print(f\"Processed {len(files)} files\")\n\n# Usage\nfiles = [f\"s3://bucket/temp/file{i}.txt\" for i in range(1000)]\nasyncio.run(batch_process(files, \"delete\"))\n</code></pre>"},{"location":"guide/bulk-operations/#best-practices","title":"Best Practices","text":""},{"location":"guide/bulk-operations/#1-check-before-deleting","title":"1. Check Before Deleting","text":"<pre><code>from panpath import PanPath\n\ndef safe_rmtree(path: str):\n    \"\"\"Safely remove directory with confirmation.\"\"\"\n    dir_path = PanPath(path)\n\n    if not dir_path.exists():\n        print(f\"{path} doesn't exist\")\n        return\n\n    # Count files\n    files = list(dir_path.rglob(\"*\"))\n    file_count = len([f for f in files if f.is_file()])\n\n    # Confirm\n    print(f\"About to delete {file_count} files from {path}\")\n    if input(\"Continue? (yes/no): \") == \"yes\":\n        dir_path.rmtree()\n        print(\"Deleted!\")\n    else:\n        print(\"Cancelled\")\n</code></pre>"},{"location":"guide/bulk-operations/#2-use-async-for-large-batches","title":"2. Use Async for Large Batches","text":"<pre><code># Slow: Sequential\nfrom panpath import PanPath\nfor i in range(1000):\n    PanPath(f\"s3://bucket/file{i}.txt\").copy(f\"gs://other/file{i}.txt\")\n\n# Fast: Concurrent\nfrom panpath import PanPath\nimport asyncio\n\nasync def fast_copy():\n    await asyncio.gather(*[\n        PanPath(f\"s3://bucket/file{i}.txt\").a_copy(f\"gs://other/file{i}.txt\")\n        for i in range(1000)\n    ])\n\nasyncio.run(fast_copy())\n</code></pre>"},{"location":"guide/bulk-operations/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code>from panpath import PanPath\nfrom panpath.exceptions import PanPathException\n\ndef robust_copytree(src: str, dst: str):\n    \"\"\"Copy directory with error handling.\"\"\"\n    src_path = PanPath(src)\n    dst_path = PanPath(dst)\n\n    try:\n        src_path.copytree(dst_path)\n        print(\"Copy successful!\")\n    except PanPathException as e:\n        print(f\"Error during copy: {e}\")\n        # Cleanup partial copy\n        if dst_path.exists():\n            print(\"Cleaning up partial copy...\")\n            dst_path.rmtree()\n        raise\n</code></pre>"},{"location":"guide/bulk-operations/#next-steps","title":"Next Steps","text":"<ul> <li>Cross-Storage Transfers - More on cross-backend operations</li> <li>Async Operations - Deep dive into async patterns</li> <li>Performance Guide - Optimization tips</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/cloud-storage/","title":"Cloud Storage","text":"<p>Working with cloud storage providers using PanPath.</p>"},{"location":"guide/cloud-storage/#supported-providers","title":"Supported Providers","text":"<p>PanPath supports three major cloud storage providers:</p> <ul> <li>Amazon S3 - <code>s3://bucket/key</code></li> <li>Google Cloud Storage - <code>gs://bucket/path</code></li> <li>Azure Blob Storage - <code>az://container/blob</code> or <code>azure://container/blob</code></li> </ul>"},{"location":"guide/cloud-storage/#basic-usage","title":"Basic Usage","text":"<pre><code>from panpath import PanPath\n\n# S3\ns3 = PanPath(\"s3://my-bucket/data/file.txt\")\ns3.write_text(\"Content\")\n\n# Google Cloud Storage\ngs = PanPath(\"gs://my-bucket/data/file.txt\")\ngs.write_text(\"Content\")\n\n# Azure Blob Storage\nazure = PanPath(\"az://my-container/data/file.txt\")\nazure.write_text(\"Content\")\n</code></pre>"},{"location":"guide/cloud-storage/#cloud-specific-properties","title":"Cloud-Specific Properties","text":"<pre><code>path = PanPath(\"s3://my-bucket/folder/file.txt\")\n\n# Cloud prefix (bucket/container with scheme)\nprint(path.cloud_prefix)  # s3://my-bucket\n\n# Key (path within bucket)\nprint(path.key)  # folder/file.txt\n\n# Bucket/container name\nprint(path.bucket)  # my-bucket\n</code></pre>"},{"location":"guide/cloud-storage/#see-also","title":"See Also","text":"<ul> <li>Amazon S3 - S3-specific documentation</li> <li>Google Cloud Storage - GCS-specific documentation</li> <li>Azure Blob Storage - Azure-specific documentation</li> <li>Bulk Operations - Efficient cloud operations</li> </ul>"},{"location":"guide/cross-storage/","title":"Cross-Storage Transfers","text":"<p>Transfer files between different storage backends seamlessly.</p>"},{"location":"guide/cross-storage/#overview","title":"Overview","text":"<p>PanPath supports copying and moving files between: - Local \u2194 Cloud - Cloud \u2194 Cloud (different providers) - Cloud \u2194 Cloud (same provider)</p>"},{"location":"guide/cross-storage/#local-to-cloud","title":"Local to Cloud","text":"<pre><code>from panpath import PanPath\n\n# Upload to S3\nlocal = PanPath(\"/data/file.txt\")\nlocal.copy(\"s3://bucket/file.txt\")\n\n# Upload to GCS\nlocal.copy(\"gs://bucket/file.txt\")\n\n# Upload directory\nlocal_dir = PanPath(\"/data/\")\nlocal_dir.copytree(\"s3://bucket/data/\")\n</code></pre>"},{"location":"guide/cross-storage/#cloud-to-local","title":"Cloud to Local","text":"<pre><code>from panpath import PanPath\n\n# Download from S3\ns3 = PanPath(\"s3://bucket/file.txt\")\ns3.copy(\"/tmp/file.txt\")\n\n# Download directory\ns3_dir = PanPath(\"s3://bucket/data/\")\ns3_dir.copytree(\"/tmp/data/\")\n</code></pre>"},{"location":"guide/cross-storage/#cloud-to-cloud","title":"Cloud to Cloud","text":"<pre><code>from panpath import PanPath\n\n# S3 to GCS\ns3 = PanPath(\"s3://bucket/file.txt\")\ns3.copy(\"gs://other-bucket/file.txt\")\n\n# Azure to S3\nazure = PanPath(\"az://container/file.txt\")\nazure.copy(\"s3://bucket/file.txt\")\n</code></pre>"},{"location":"guide/cross-storage/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Same backend: Uses server-side copy (fast)</li> <li>Different backends: Downloads then uploads (slower)</li> <li>Use async: For better performance with multiple files</li> </ul>"},{"location":"guide/cross-storage/#see-also","title":"See Also","text":"<ul> <li>Bulk Operations - Efficient directory operations</li> <li>Quick Start - Basic examples</li> </ul>"},{"location":"guide/error-handling/","title":"Error Handling","text":"<p>Understanding and handling errors in PanPath.</p>"},{"location":"guide/error-handling/#common-exceptions","title":"Common Exceptions","text":"<pre><code>from panpath import PanPath\nfrom panpath.exceptions import (\n    PanPathException,\n    PathNotFoundError,\n    PermissionError,\n)\n\npath = PanPath(\"s3://bucket/nonexistent.txt\")\n\ntry:\n    content = path.read_text()\nexcept PathNotFoundError:\n    print(\"File not found\")\nexcept PermissionError:\n    print(\"Access denied\")\nexcept PanPathException as e:\n    print(f\"Other error: {e}\")\n</code></pre>"},{"location":"guide/error-handling/#provider-specific-errors","title":"Provider-Specific Errors","text":""},{"location":"guide/error-handling/#aws-s3","title":"AWS S3","text":"<pre><code>import botocore.exceptions\n\ntry:\n    path.read_text()\nexcept botocore.exceptions.NoCredentialsError:\n    print(\"AWS credentials not configured\")\nexcept botocore.exceptions.ClientError as e:\n    error_code = e.response['Error']['Code']\n    if error_code == '404':\n        print(\"Not found\")\n</code></pre>"},{"location":"guide/error-handling/#google-cloud-storage","title":"Google Cloud Storage","text":"<pre><code>from google.cloud import exceptions\n\ntry:\n    path.read_text()\nexcept exceptions.NotFound:\n    print(\"Not found\")\nexcept exceptions.Forbidden:\n    print(\"Access denied\")\n</code></pre>"},{"location":"guide/error-handling/#azure-blob-storage","title":"Azure Blob Storage","text":"<pre><code>from azure.core.exceptions import ResourceNotFoundError\n\ntry:\n    path.read_text()\nexcept ResourceNotFoundError:\n    print(\"Not found\")\n</code></pre>"},{"location":"guide/error-handling/#best-practices","title":"Best Practices","text":"<pre><code>from panpath import PanPath\n\ndef safe_read(uri: str) -&gt; str | None:\n    \"\"\"Safely read file, return None if not found.\"\"\"\n    try:\n        path = PanPath(uri)\n        return path.read_text()\n    except Exception as e:\n        print(f\"Error reading {uri}: {e}\")\n        return None\n</code></pre>"},{"location":"guide/local-paths/","title":"Local Paths","text":"<p>Working with local filesystem paths using PanPath.</p>"},{"location":"guide/local-paths/#overview","title":"Overview","text":"<p>PanPath provides a pathlib-compatible interface for local files, making it a drop-in replacement for <code>pathlib.Path</code>.</p>"},{"location":"guide/local-paths/#basic-usage","title":"Basic Usage","text":"<pre><code>from panpath import PanPath\n\n# Create a local path\npath = PanPath(\"/tmp/file.txt\")\n\n# Or use file:// URI\npath = PanPath(\"file:///tmp/file.txt\")\n\n# Works like pathlib.Path\npath.write_text(\"Hello, World!\")\ncontent = path.read_text()\nprint(content)  # Hello, World!\n</code></pre>"},{"location":"guide/local-paths/#compatibility-with-pathlib","title":"Compatibility with pathlib","text":"<pre><code>from pathlib import Path\nfrom panpath import PanPath\n\n# These work identically\npathlib_path = Path(\"/tmp/file.txt\")\npan_path = PanPath(\"/tmp/file.txt\")\n\n# Same operations\npathlib_path.write_text(\"content\")\npan_path.write_text(\"content\")\n\n# Same results\nassert pathlib_path.name == pan_path.name\nassert pathlib_path.suffix == pan_path.suffix\nassert pathlib_path.parent == PanPath(str(pathlib_path.parent))\n</code></pre>"},{"location":"guide/local-paths/#async-local-operations","title":"Async Local Operations","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    path = PanPath(\"/tmp/file.txt\")\n\n    # Async write\n    await path.a_write_text(\"Async content\")\n\n    # Async read\n    content = await path.a_read_text()\n    print(content)\n\n    # Async context manager\n    async with path.a_open(\"w\") as f:\n        await f.a_write(\"Line 1\\n\")\n        await f.a_write(\"Line 2\\n\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"guide/local-paths/#see-also","title":"See Also","text":"<ul> <li>Path Operations - Comprehensive path manipulation guide</li> <li>Async Operations - Async patterns and best practices</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/path-operations/","title":"Path Operations","text":"<p>Comprehensive guide to path manipulation and querying.</p>"},{"location":"guide/path-operations/#path-components","title":"Path Components","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://bucket/dir/file.tar.gz\")\n\nprint(path.name)        # file.tar.gz\nprint(path.stem)        # file.tar\nprint(path.suffix)      # .gz\nprint(path.suffixes)    # ['.tar', '.gz']\nprint(path.parent)      # s3://bucket/dir\nprint(path.parts)       # ('s3://bucket', 'dir', 'file.tar.gz')\n</code></pre>"},{"location":"guide/path-operations/#joining-paths","title":"Joining Paths","text":"<pre><code>from panpath import PanPath\n\nbase = PanPath(\"s3://bucket/data\")\n\n# Using / operator\npath1 = base / \"subdir\" / \"file.txt\"\n\n# Using joinpath\npath2 = base.joinpath(\"subdir\", \"file.txt\")\n\nprint(path1)  # s3://bucket/data/subdir/file.txt\nprint(path2)  # s3://bucket/data/subdir/file.txt\n</code></pre>"},{"location":"guide/path-operations/#modifying-paths","title":"Modifying Paths","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://bucket/data/file.txt\")\n\n# Change filename\nnew = path.with_name(\"newfile.txt\")\n# s3://bucket/data/newfile.txt\n\n# Change stem\nnew = path.with_stem(\"document\")\n# s3://bucket/data/document.txt\n\n# Change suffix\nnew = path.with_suffix(\".csv\")\n# s3://bucket/data/file.csv\n</code></pre>"},{"location":"guide/path-operations/#pattern-matching","title":"Pattern Matching","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://bucket/data/file.txt\")\n\n# Match patterns\nprint(path.match(\"*.txt\"))           # True\nprint(path.match(\"**/data/*.txt\"))   # True\nprint(path.match(\"*.csv\"))           # False\n</code></pre>"},{"location":"guide/path-operations/#see-also","title":"See Also","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Quick Start - Basic usage</li> </ul>"},{"location":"migration/from-cloudpathlib/","title":"Migration from cloudpathlib","text":"<p>This guide helps you migrate from cloudpathlib to PanPath.</p>"},{"location":"migration/from-cloudpathlib/#why-migrate","title":"Why Migrate?","text":"<p>PanPath offers several advantages over cloudpathlib:</p> <ul> <li>\u2705 Local path support - Same API for local and cloud storage</li> <li>\u2705 Explicit async/sync - Clear separation with better type safety</li> <li>\u2705 Better performance - Lazy client loading and optimized operations</li> <li>\u2705 Cross-storage operations - Copy/move between different providers</li> <li>\u2705 Simpler API - Unified <code>PanPath</code> instead of separate classes</li> </ul>"},{"location":"migration/from-cloudpathlib/#compatibility","title":"Compatibility","text":"<p>PanPath maintains compatibility with most cloudpathlib features. See Cloudpathlib Compatibility for detailed comparison.</p>"},{"location":"migration/from-cloudpathlib/#quick-migration-guide","title":"Quick Migration Guide","text":""},{"location":"migration/from-cloudpathlib/#installation","title":"Installation","text":"<p>cloudpathlib: <pre><code>pip install cloudpathlib[all]\n</code></pre></p> <p>PanPath: <pre><code>pip install panpath[all]\n</code></pre></p>"},{"location":"migration/from-cloudpathlib/#basic-path-creation","title":"Basic Path Creation","text":"cloudpathlibPanPath <pre><code>from cloudpathlib import CloudPath, S3Path, GSPath, AzurePath\n\n# Generic (auto-dispatch)\npath = CloudPath(\"s3://bucket/key\")\n\n# Specific backends\ns3 = S3Path(\"s3://bucket/key\")\ngs = GSPath(\"gs://bucket/path\")\naz = AzurePath(\"az://container/blob\")\n</code></pre> <pre><code>from panpath import PanPath\n\n# Generic (auto-dispatch)\npath = PanPath(\"s3://bucket/key\")\n\n# All backends use PanPath\ns3 = PanPath(\"s3://bucket/key\")\ngs = PanPath(\"gs://bucket/path\")\naz = PanPath(\"az://container/blob\")\n</code></pre>"},{"location":"migration/from-cloudpathlib/#reading-and-writing","title":"Reading and Writing","text":"<p>The API is identical:</p> cloudpathlibPanPath <pre><code>path = CloudPath(\"s3://bucket/file.txt\")\n\n# Read\ntext = path.read_text()\ndata = path.read_bytes()\n\n# Write\npath.write_text(\"content\")\npath.write_bytes(b\"data\")\n</code></pre> <pre><code>path = PanPath(\"s3://bucket/file.txt\")\n\n# Read (identical)\ntext = path.read_text()\ndata = path.read_bytes()\n\n# Write (identical)\npath.write_text(\"content\")\npath.write_bytes(b\"data\")\n</code></pre>"},{"location":"migration/from-cloudpathlib/#path-operations","title":"Path Operations","text":"<p>Most operations are identical:</p> cloudpathlibPanPath <pre><code>path = CloudPath(\"s3://bucket/dir/file.txt\")\n\n# Properties\nprint(path.name)        # file.txt\nprint(path.stem)        # file\nprint(path.suffix)      # .txt\nprint(path.parent)      # s3://bucket/dir\n\n# Joining\nnew = path.parent / \"other.txt\"\n\n# Modification\nrenamed = path.with_name(\"new.txt\")\n</code></pre> <pre><code>path = PanPath(\"s3://bucket/dir/file.txt\")\n\n# Properties (identical)\nprint(path.name)        # file.txt\nprint(path.stem)        # file\nprint(path.suffix)      # .txt\nprint(path.parent)      # s3://bucket/dir\n\n# Joining (identical)\nnew = path.parent / \"other.txt\"\n\n# Modification (identical)\nrenamed = path.with_name(\"new.txt\")\n</code></pre>"},{"location":"migration/from-cloudpathlib/#directory-operations","title":"Directory Operations","text":"cloudpathlibPanPath <pre><code>directory = CloudPath(\"s3://bucket/data/\")\n\n# Iterate\nfor item in directory.iterdir():\n    print(item)\n\n# Glob\ntxt_files = directory.glob(\"*.txt\")\npy_files = directory.rglob(\"*.py\")\n</code></pre> <pre><code>directory = PanPath(\"s3://bucket/data/\")\n\n# Iterate (identical)\nfor item in directory.iterdir():\n    print(item)\n\n# Glob (identical)\ntxt_files = directory.glob(\"*.txt\")\npy_files = directory.rglob(\"*.py\")\n</code></pre>"},{"location":"migration/from-cloudpathlib/#key-differences","title":"Key Differences","text":""},{"location":"migration/from-cloudpathlib/#1-async-support","title":"1. Async Support","text":"<p>cloudpathlib has async support mixed into the same classes.</p> <p>PanPath has explicit sync/async separation:</p> cloudpathlibPanPath <pre><code>from cloudpathlib import CloudPath\n\n# Sync (default)\npath = CloudPath(\"s3://bucket/file.txt\")\ncontent = path.read_text()\n\n# Async (not well-documented)\n# Limited async support\n</code></pre> <pre><code>from panpath import PanPath\n\n# Sync (explicit)\npath = PanPath(\"s3://bucket/file.txt\")\ncontent = path.read_text()\n\n# Async\ncontent = await async_path.a_read_text()\n</code></pre>"},{"location":"migration/from-cloudpathlib/#2-local-paths","title":"2. Local Paths","text":"<p>cloudpathlib doesn't support local paths.</p> <p>PanPath treats local paths the same as cloud paths:</p> cloudpathlibPanPath <pre><code>from cloudpathlib import CloudPath\nfrom pathlib import Path\n\n# Need different classes\ncloud_path = CloudPath(\"s3://bucket/file.txt\")\nlocal_path = Path(\"/tmp/file.txt\")\n\n# Different APIs\ncloud_content = cloud_path.read_text()\nlocal_content = local_path.read_text()\n</code></pre> <pre><code>from panpath import PanPath\n\n# Same class for everything\ncloud_path = PanPath(\"s3://bucket/file.txt\")\nlocal_path = PanPath(\"/tmp/file.txt\")\n\n# Same API\ncloud_content = cloud_path.read_text()\nlocal_content = local_path.read_text()\n</code></pre>"},{"location":"migration/from-cloudpathlib/#3-client-configuration","title":"3. Client Configuration","text":"<p>cloudpathlib uses client objects.</p> <p>PanPath uses lazy client creation with registry:</p> cloudpathlibPanPath <pre><code>from cloudpathlib import S3Client, S3Path\n\n# Create client\nclient = S3Client(\n    aws_access_key_id=\"key\",\n    aws_secret_access_key=\"secret\"\n)\n\n# Use with path\npath = S3Path(\"s3://bucket/file.txt\", client=client)\n</code></pre> <pre><code>from panpath import PanPath\nfrom panpath.clients import get_s3_client\n\n# Configure client (optional - uses env vars by default)\nclient = get_s3_client(\n    aws_access_key_id=\"key\",\n    aws_secret_access_key=\"secret\"\n)\n\n# Paths automatically use configured client\npath = PanPath(\"s3://bucket/file.txt\")\n</code></pre>"},{"location":"migration/from-cloudpathlib/#4-file-caching","title":"4. File Caching","text":"<p>cloudpathlib has built-in file caching.</p> <p>PanPath doesn't implement caching (yet):</p> cloudpathlibPanPath <pre><code>from cloudpathlib import S3Path\n\n# With caching\npath = S3Path(\"s3://bucket/file.txt\")\npath.fspath  # Downloads to cache\n</code></pre> <pre><code>from panpath import PanPath\n\n# No automatic caching\n# Manually download if needed\npath = PanPath(\"s3://bucket/file.txt\")\nlocal_copy = PanPath(\"/tmp/file.txt\")\npath.copy(local_copy)\n</code></pre>"},{"location":"migration/from-cloudpathlib/#migration-steps","title":"Migration Steps","text":""},{"location":"migration/from-cloudpathlib/#step-1-update-imports","title":"Step 1: Update Imports","text":"<p>Replace cloudpathlib imports:</p> <pre><code># Before\nfrom cloudpathlib import CloudPath, S3Path, GSPath\n\n# After\nfrom panpath import PanPath\n</code></pre>"},{"location":"migration/from-cloudpathlib/#step-2-update-path-creation","title":"Step 2: Update Path Creation","text":"<p>Replace specific path classes with <code>PanPath</code>:</p> <pre><code># Before\ns3 = S3Path(\"s3://bucket/key\")\ngs = GSPath(\"gs://bucket/path\")\n\n# After\ns3 = PanPath(\"s3://bucket/key\")\ngs = PanPath(\"gs://bucket/path\")\n</code></pre>"},{"location":"migration/from-cloudpathlib/#step-3-update-client-configuration","title":"Step 3: Update Client Configuration","text":"<p>If you use custom clients:</p> <pre><code># Before\nfrom cloudpathlib import S3Client, S3Path\n\nclient = S3Client(...)\npath = S3Path(\"s3://bucket/key\", client=client)\n\n# After\nfrom panpath import PanPath\nfrom panpath.clients import get_s3_client\n\nget_s3_client(...)  # Configure once\npath = PanPath(\"s3://bucket/key\")  # Uses configured client\n</code></pre>"},{"location":"migration/from-cloudpathlib/#step-4-update-async-code","title":"Step 4: Update Async Code","text":"<p>Make async operations explicit:</p> <pre><code># Before\nfrom cloudpathlib import CloudPath\n\npath = CloudPath(\"s3://bucket/file.txt\")\n# Might be async internally?\n\n# After\nfrom panpath import PanPath\n\nasync_path = PanPath(\"s3://bucket/file.txt\")\ncontent = await async_path.a_read_text()\n</code></pre>"},{"location":"migration/from-cloudpathlib/#step-5-remove-caching-code","title":"Step 5: Remove Caching Code","text":"<p>If you relied on automatic caching:</p> <pre><code># Before\nfrom cloudpathlib import S3Path\n\npath = S3Path(\"s3://bucket/file.txt\")\nlocal_path = path.fspath  # Cached local copy\n\n# After\nfrom panpath import PanPath\n\npath = PanPath(\"s3://bucket/file.txt\")\n# Download explicitly if needed\nlocal_path = \"/tmp/file.txt\"\npath.copy(local_path)\n</code></pre>"},{"location":"migration/from-cloudpathlib/#complete-example","title":"Complete Example","text":"<p>Here's a complete migration example:</p> cloudpathlibPanPath <pre><code>from cloudpathlib import CloudPath, S3Client\n\n# Configure client\nclient = S3Client(\n    aws_access_key_id=\"key\",\n    aws_secret_access_key=\"secret\"\n)\n\n# Process files\ndef process_files(bucket_uri: str):\n    directory = CloudPath(bucket_uri, client=client)\n\n    for txt_file in directory.glob(\"*.txt\"):\n        content = txt_file.read_text()\n\n        # Process content\n        processed = content.upper()\n\n        # Write to new location\n        output = txt_file.with_stem(f\"{txt_file.stem}_processed\")\n        output.write_text(processed)\n\nprocess_files(\"s3://my-bucket/data/\")\n</code></pre> <pre><code>from panpath import PanPath\nfrom panpath.clients import get_s3_client\n\n# Configure client (optional - uses env vars by default)\nget_s3_client(\n    aws_access_key_id=\"key\",\n    aws_secret_access_key=\"secret\"\n)\n\n# Process files\ndef process_files(bucket_uri: str):\n    directory = PanPath(bucket_uri)\n\n    for txt_file in directory.glob(\"*.txt\"):\n        content = txt_file.read_text()\n\n        # Process content\n        processed = content.upper()\n\n        # Write to new location\n        output = txt_file.with_stem(f\"{txt_file.stem}_processed\")\n        output.write_text(processed)\n\nprocess_files(\"s3://my-bucket/data/\")\n</code></pre>"},{"location":"migration/from-cloudpathlib/#testing","title":"Testing","text":""},{"location":"migration/from-cloudpathlib/#mocking","title":"Mocking","text":"<p>PanPath uses a different mocking strategy:</p> cloudpathlibPanPath <pre><code>import pytest\nfrom cloudpathlib import S3Path\nfrom cloudpathlib.local import LocalS3Path\n\ndef test_with_mock():\n    # Use local implementation\n    path = LocalS3Path(\"s3://bucket/file.txt\")\n    path.write_text(\"test\")\n    assert path.read_text() == \"test\"\n</code></pre> <pre><code>import pytest\nfrom panpath import PanPath\n\ndef test_with_mock():\n    # Use local paths for testing\n    path = PanPath(\"/tmp/test-bucket/file.txt\")\n    path.parent.mkdir(parents=True, exist_ok=True)\n    path.write_text(\"test\")\n    assert path.read_text() == \"test\"\n</code></pre>"},{"location":"migration/from-cloudpathlib/#compatibility-layer","title":"Compatibility Layer","text":"<p>If you need to maintain compatibility with both libraries:</p> <pre><code>def get_cloud_path(uri: str):\n    \"\"\"Get cloud path using available library.\"\"\"\n    try:\n        from panpath import PanPath\n        return PanPath(uri)\n    except ImportError:\n        from cloudpathlib import CloudPath\n        return CloudPath(uri)\n\n# Use it\npath = get_cloud_path(\"s3://bucket/file.txt\")\ncontent = path.read_text()\n</code></pre>"},{"location":"migration/from-cloudpathlib/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Learn PanPath basics</li> <li>User Guide - Detailed feature documentation</li> <li>API Reference - Complete API documentation</li> <li>Cloudpathlib Compatibility - Detailed compatibility info</li> </ul>"},{"location":"migration/from-pathlib/","title":"Migration from pathlib","text":"<p>This guide helps you migrate from Python's standard <code>pathlib</code> to PanPath.</p>"},{"location":"migration/from-pathlib/#why-migrate","title":"Why Migrate?","text":"<p>PanPath extends pathlib's interface to support cloud storage while maintaining full compatibility for local paths.</p>"},{"location":"migration/from-pathlib/#quick-migration","title":"Quick Migration","text":"<p>For local paths, PanPath is a drop-in replacement:</p> <pre><code># Before\nfrom pathlib import Path\n\npath = Path(\"/tmp/file.txt\")\ncontent = path.read_text()\n\n# After\nfrom panpath import PanPath\n\npath = PanPath(\"/tmp/file.txt\")\ncontent = path.read_text()\n</code></pre>"},{"location":"migration/from-pathlib/#extending-to-cloud","title":"Extending to Cloud","text":"<p>Once using PanPath, adding cloud support is trivial:</p> <pre><code>from panpath import PanPath\n\n# Same code works for cloud\npath = PanPath(\"s3://bucket/file.txt\")\ncontent = path.read_text()\n</code></pre>"},{"location":"migration/from-pathlib/#type-hints","title":"Type Hints","text":"<pre><code>from pathlib import Path\nfrom panpath import PanPath\n\n# Accept both\ndef process(path: Path | PanPath):\n    # Convert to PanPath if needed\n    if isinstance(path, Path):\n        path = PanPath(str(path))\n\n    # Now works with cloud too\n    return path.read_text()\n</code></pre>"},{"location":"migration/from-pathlib/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Learn PanPath basics</li> <li>API Reference - Complete API</li> </ul>"},{"location":"providers/azure/","title":"Azure Blob Storage","text":"<p>Comprehensive guide for using PanPath with Azure Blob Storage.</p>"},{"location":"providers/azure/#installation","title":"Installation","text":"<pre><code># Sync support\npip install panpath[azure]\n\n# Async support\npip install panpath[async-azure]\n\n# Both\npip install panpath[azure,async-azure]\n</code></pre>"},{"location":"providers/azure/#authentication","title":"Authentication","text":"<p>Configure authentication using one of these methods:</p> Connection StringAccount KeySAS Token <pre><code>export AZURE_STORAGE_CONNECTION_STRING=\"DefaultEndpointsProtocol=https;AccountName=...\"\n</code></pre> <pre><code>export AZURE_STORAGE_ACCOUNT_NAME=your_account\nexport AZURE_STORAGE_ACCOUNT_KEY=your_key\n</code></pre> <pre><code>export AZURE_STORAGE_ACCOUNT_NAME=your_account\nexport AZURE_STORAGE_SAS_TOKEN=your_sas_token\n</code></pre>"},{"location":"providers/azure/#basic-usage","title":"Basic Usage","text":""},{"location":"providers/azure/#uri-format","title":"URI Format","text":"<pre><code>from panpath import PanPath\n\n# Format: az://container-name/path or azure://container-name/path\npath = PanPath(\"az://my-container/file.txt\")\n# or\npath = PanPath(\"azure://my-container/file.txt\")\n\n# Container root\ncontainer = PanPath(\"az://my-container/\")\n\n# Nested paths\nnested = PanPath(\"az://my-container/folder/subfolder/file.txt\")\n</code></pre>"},{"location":"providers/azure/#reading-and-writing","title":"Reading and Writing","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"az://my-container/data.txt\")\n\n# Write text\npath.write_text(\"Hello, Azure!\")\n\n# Read text\ncontent = path.read_text()\nprint(content)  # Hello, Azure!\n\n# Binary operations\npath_bin = PanPath(\"az://my-container/data.bin\")\npath_bin.write_bytes(b\"\\x00\\x01\\x02\\x03\")\ndata = path_bin.read_bytes()\n</code></pre>"},{"location":"providers/azure/#async-operations","title":"Async Operations","text":""},{"location":"providers/azure/#basic-async-usage","title":"Basic Async Usage","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    path = PanPath(\"az://my-container/file.txt\")\n\n    # Async write and read\n    await path.a_write_text(\"Async content\")\n    content = await path.a_read_text()\n    print(content)\n\nasyncio.run(main())\n</code></pre>"},{"location":"providers/azure/#async-file-handles-with-position-control","title":"Async File Handles with Position Control","text":"<p>Async file handles support <code>seek()</code> and <code>tell()</code> for file position control:</p> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def read_partial():\n    path = PanPath(\"az://my-container/large-file.bin\")\n\n    async with path.a_open(\"rb\") as f:\n        # Get current position\n        pos = await f.tell()  # 0\n\n        # Read first 100 bytes\n        chunk = await f.read(100)\n\n        # Seek to specific position\n        await f.seek(50)\n\n        # Read from new position\n        chunk = await f.read(50)\n\nasyncio.run(read_partial())\n</code></pre>"},{"location":"providers/azure/#directory-operations","title":"Directory Operations","text":"<pre><code>from panpath import PanPath\n\ncontainer = PanPath(\"az://my-container/data/\")\n\n# List blobs\nfor item in container.iterdir():\n    print(item)\n\n# Glob patterns\nfor txt_file in container.glob(\"*.txt\"):\n    print(txt_file)\n\n# Recursive glob\nfor py_file in container.rglob(\"*.py\"):\n    print(py_file)\n</code></pre>"},{"location":"providers/azure/#advanced-features","title":"Advanced Features","text":""},{"location":"providers/azure/#server-side-copy","title":"Server-Side Copy","text":"<p>Azure supports efficient server-side copy:</p> <pre><code>from panpath import PanPath\n\nsrc = PanPath(\"az://my-container/source.txt\")\n\n# Fast server-side copy (no download/upload)\nsrc.copy(\"az://my-container/backup/source.txt\")\n\n# Works across containers\nsrc.copy(\"az://other-container/source.txt\")\n</code></pre>"},{"location":"providers/azure/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Basic usage</li> <li>Cloud Storage Guide - Cloud features</li> <li>Async Operations - Detailed async guide</li> </ul>"},{"location":"providers/gcs/","title":"Google Cloud Storage","text":"<p>Comprehensive guide for using PanPath with Google Cloud Storage.</p>"},{"location":"providers/gcs/#installation","title":"Installation","text":"<pre><code># Sync support\npip install panpath[gs]\n\n# Async support\npip install panpath[async-gs]\n\n# Both\npip install panpath[gs,async-gs]\n</code></pre>"},{"location":"providers/gcs/#authentication","title":"Authentication","text":"<p>Configure authentication using one of these methods:</p> Service Account Keygcloud CLIDefault Credentials <pre><code>export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json\n</code></pre> <pre><code>gcloud auth application-default login\n</code></pre> <pre><code># When running on GCP (GCE, GKE, Cloud Functions, etc.)\n# Credentials are automatically obtained\nfrom panpath import PanPath\n\npath = PanPath(\"gs://my-bucket/file.txt\")\n# Uses default service account automatically\n</code></pre>"},{"location":"providers/gcs/#basic-usage","title":"Basic Usage","text":""},{"location":"providers/gcs/#uri-format","title":"URI Format","text":"<pre><code>from panpath import PanPath\n\n# Format: gs://bucket-name/path\npath = PanPath(\"gs://my-bucket/file.txt\")\n\n# Bucket root\nbucket = PanPath(\"gs://my-bucket/\")\n\n# Nested paths\nnested = PanPath(\"gs://my-bucket/folder/subfolder/file.txt\")\n</code></pre>"},{"location":"providers/gcs/#reading-and-writing","title":"Reading and Writing","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"gs://my-bucket/data.txt\")\n\n# Write text\npath.write_text(\"Hello, GCS!\")\n\n# Read text\ncontent = path.read_text()\nprint(content)  # Hello, GCS!\n\n# Binary operations\npath_bin = PanPath(\"gs://my-bucket/data.bin\")\npath_bin.write_bytes(b\"\\x00\\x01\\x02\\x03\")\ndata = path_bin.read_bytes()\n</code></pre>"},{"location":"providers/gcs/#async-operations","title":"Async Operations","text":""},{"location":"providers/gcs/#basic-async-usage","title":"Basic Async Usage","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    path = PanPath(\"gs://my-bucket/file.txt\")\n\n    # Async write and read\n    await path.a_write_text(\"Async content\")\n    content = await path.a_read_text()\n    print(content)\n\nasyncio.run(main())\n</code></pre>"},{"location":"providers/gcs/#async-file-handles-with-position-control","title":"Async File Handles with Position Control","text":"<p>Async file handles support <code>seek()</code> and <code>tell()</code> for file position control:</p> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def read_partial():\n    path = PanPath(\"gs://my-bucket/large-file.bin\")\n\n    async with path.a_open(\"rb\") as f:\n        # Get current position\n        pos = await f.tell()  # 0\n\n        # Read first 100 bytes\n        chunk = await f.read(100)\n\n        # Seek to specific position\n        await f.seek(50)\n\n        # Read from new position\n        chunk = await f.read(50)\n\nasyncio.run(read_partial())\n</code></pre>"},{"location":"providers/gcs/#directory-operations","title":"Directory Operations","text":"<pre><code>from panpath import PanPath\n\nbucket = PanPath(\"gs://my-bucket/data/\")\n\n# List files\nfor item in bucket.iterdir():\n    print(item)\n\n# Glob patterns\nfor txt_file in bucket.glob(\"*.txt\"):\n    print(txt_file)\n\n# Recursive glob\nfor py_file in bucket.rglob(\"*.py\"):\n    print(py_file)\n</code></pre>"},{"location":"providers/gcs/#advanced-features","title":"Advanced Features","text":""},{"location":"providers/gcs/#server-side-copy","title":"Server-Side Copy","text":"<p>GCS supports efficient server-side copy:</p> <pre><code>from panpath import PanPath\n\nsrc = PanPath(\"gs://my-bucket/source.txt\")\n\n# Fast server-side copy (no download/upload)\nsrc.copy(\"gs://my-bucket/backup/source.txt\")\n\n# Works across buckets\nsrc.copy(\"gs://other-bucket/source.txt\")\n</code></pre>"},{"location":"providers/gcs/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Basic usage</li> <li>Cloud Storage Guide - Cloud features</li> <li>Async Operations - Detailed async guide</li> </ul>"},{"location":"providers/s3/","title":"Amazon S3","text":"<p>Comprehensive guide for using PanPath with Amazon S3.</p>"},{"location":"providers/s3/#prerequisites","title":"Prerequisites","text":""},{"location":"providers/s3/#installation","title":"Installation","text":"<pre><code># Sync support\npip install panpath[s3]\n\n# Async support\npip install panpath[async-s3]\n\n# Both\npip install panpath[s3,async-s3]\n</code></pre>"},{"location":"providers/s3/#aws-credentials","title":"AWS Credentials","text":"<p>Configure AWS credentials using one of these methods:</p> Environment VariablesAWS Config FileIAM Role <pre><code>export AWS_ACCESS_KEY_ID=your_access_key\nexport AWS_SECRET_ACCESS_KEY=your_secret_key\nexport AWS_DEFAULT_REGION=us-east-1\n</code></pre> <pre><code># ~/.aws/credentials\n[default]\naws_access_key_id = your_access_key\naws_secret_access_key = your_secret_key\n\n# ~/.aws/config\n[default]\nregion = us-east-1\n</code></pre> <pre><code># When running on EC2, ECS, or Lambda\n# Credentials are automatically obtained from IAM role\nfrom panpath import PanPath\n\npath = PanPath(\"s3://bucket/file.txt\")\n# Uses IAM role credentials automatically\n</code></pre>"},{"location":"providers/s3/#basic-usage","title":"Basic Usage","text":""},{"location":"providers/s3/#uri-format","title":"URI Format","text":"<pre><code>from panpath import PanPath\n\n# Format: s3://bucket-name/key/path\npath = PanPath(\"s3://my-bucket/data/file.txt\")\n\n# Bucket root\nbucket = PanPath(\"s3://my-bucket/\")\n\n# Nested paths\nnested = PanPath(\"s3://my-bucket/folder/subfolder/file.txt\")\n</code></pre>"},{"location":"providers/s3/#reading-and-writing","title":"Reading and Writing","text":"Text FilesBinary FilesUsing open() <pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://my-bucket/data.txt\")\n\n# Write text\npath.write_text(\"Hello, S3!\")\n\n# Read text\ncontent = path.read_text()\nprint(content)  # Hello, S3!\n\n# With encoding\npath.write_text(\"Hello\", encoding=\"utf-8\")\ncontent = path.read_text(encoding=\"utf-8\")\n</code></pre> <pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://my-bucket/data.bin\")\n\n# Write bytes\npath.write_bytes(b\"\\x00\\x01\\x02\\x03\")\n\n# Read bytes\ndata = path.read_bytes()\n</code></pre> <pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://my-bucket/log.txt\")\n\n# Write\nwith path.open(\"w\") as f:\n    f.write(\"Line 1\\n\")\n    f.write(\"Line 2\\n\")\n\n# Read\nwith path.open(\"r\") as f:\n    for line in f:\n        print(line.strip())\n</code></pre>"},{"location":"providers/s3/#path-operations","title":"Path Operations","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://my-bucket/data/file.txt\")\n\n# Path components\nprint(path.name)        # file.txt\nprint(path.stem)        # file\nprint(path.suffix)      # .txt\nprint(path.parent)      # s3://my-bucket/data\n\n# Join paths\nnew_path = path.parent / \"other.txt\"\nprint(new_path)  # s3://my-bucket/data/other.txt\n\n# Modify components\nrenamed = path.with_name(\"newfile.txt\")\nprint(renamed)  # s3://my-bucket/data/newfile.txt\n\ndifferent_ext = path.with_suffix(\".csv\")\nprint(different_ext)  # s3://my-bucket/data/file.csv\n</code></pre>"},{"location":"providers/s3/#directory-operations","title":"Directory Operations","text":""},{"location":"providers/s3/#listing-objects","title":"Listing Objects","text":"<pre><code>from panpath import PanPath\n\nbucket = PanPath(\"s3://my-bucket/data/\")\n\n# List all items\nfor item in bucket.iterdir():\n    print(item)\n\n# Find specific files\nfor txt_file in bucket.glob(\"*.txt\"):\n    print(txt_file)\n\n# Recursive search\nfor py_file in bucket.rglob(\"*.py\"):\n    print(py_file)\n</code></pre>"},{"location":"providers/s3/#walking-directory-tree","title":"Walking Directory Tree","text":"<pre><code>from panpath import PanPath\n\nbucket = PanPath(\"s3://my-bucket/\")\n\nfor dirpath, dirnames, filenames in bucket.walk():\n    print(f\"Directory: {dirpath}\")\n    print(f\"  Subdirectories: {dirnames}\")\n    print(f\"  Files: {filenames}\")\n</code></pre>"},{"location":"providers/s3/#creating-directories","title":"Creating Directories","text":"<pre><code>from panpath import PanPath\n\n# Create directory (creates marker object)\ndirectory = PanPath(\"s3://my-bucket/new-folder/\")\ndirectory.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"providers/s3/#async-operations","title":"Async Operations","text":""},{"location":"providers/s3/#basic-async-usage","title":"Basic Async Usage","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    path = PanPath(\"s3://my-bucket/file.txt\")\n\n    # Write\n    await path.a_write_text(\"Async content\")\n\n    # Read\n    content = await path.a_read_text()\n    print(content)\n\nasyncio.run(main())\n</code></pre>"},{"location":"providers/s3/#async-context-manager","title":"Async Context Manager","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def main():\n    path = PanPath(\"s3://my-bucket/log.txt\")\n\n    # Write\n    async with path.a_open(\"w\") as f:\n        await f.a_write(\"Line 1\\n\")\n        await f.a_write(\"Line 2\\n\")\n\n    # Read\n    async with path.a_open(\"r\") as f:\n        content = await f.a_read()\n        print(content)\n\nasyncio.run(main())\n</code></pre>"},{"location":"providers/s3/#file-position-control-seektell","title":"File Position Control (seek/tell)","text":"<p>Async file handles support <code>seek()</code> and <code>tell()</code> methods for controlling file position:</p> <pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def read_partial():\n    path = PanPath(\"s3://my-bucket/large-file.bin\")\n\n    async with path.a_open(\"rb\") as f:\n        # Get current position\n        pos = await f.tell()\n        print(f\"Position: {pos}\")  # 0\n\n        # Read first 100 bytes\n        chunk = await f.read(100)\n\n        # Check new position\n        pos = await f.tell()\n        print(f\"Position: {pos}\")  # 100\n\n        # Seek to specific position\n        await f.seek(50)  # Absolute position\n\n        # Read from new position\n        chunk = await f.read(50)\n\n        # Seek relative to current position\n        await f.seek(10, 1)  # 10 bytes forward\n\n        # Seek from end\n        await f.seek(-100, 2)  # 100 bytes before end\n\nasyncio.run(read_partial())\n</code></pre> <p>Use Cases for seek/tell</p> <ul> <li>Large file processing: Read specific chunks without downloading the entire file</li> <li>Resume operations: Track position for resumable downloads</li> <li>Random access: Jump to specific offsets in structured files</li> <li>Header parsing: Read file headers without loading the full content</li> </ul>"},{"location":"providers/s3/#parallel-operations","title":"Parallel Operations","text":"<pre><code>import asyncio\nfrom panpath import PanPath\n\nasync def download_all(uris: list[str]):\n    \"\"\"Download multiple files concurrently.\"\"\"\n    paths = [PanPath(uri) for uri in uris]\n    contents = await asyncio.gather(*[p.a_read_text() for p in paths])\n    return contents\n\nuris = [\n    \"s3://my-bucket/file1.txt\",\n    \"s3://my-bucket/file2.txt\",\n    \"s3://my-bucket/file3.txt\",\n]\n\nasyncio.run(download_all(uris))\n</code></pre>"},{"location":"providers/s3/#advanced-features","title":"Advanced Features","text":""},{"location":"providers/s3/#server-side-copy","title":"Server-Side Copy","text":"<p>S3 supports server-side copy for efficient copying within S3:</p> <pre><code>from panpath import PanPath\n\n# Fast: No download/upload\nsrc = PanPath(\"s3://my-bucket/source.txt\")\nsrc.copy(\"s3://my-bucket/backup/source.txt\")\n\n# Also works across buckets\nsrc.copy(\"s3://other-bucket/source.txt\")\n</code></pre>"},{"location":"providers/s3/#multipart-upload","title":"Multipart Upload","text":"<p>Large files are automatically handled with multipart upload:</p> <pre><code>from panpath import PanPath\n\n# Large file (&gt;5GB)\nlarge_file = PanPath(\"s3://my-bucket/large-file.bin\")\n\n# Automatically uses multipart upload\nwith open(\"/local/large-file.bin\", \"rb\") as f:\n    large_file.write_bytes(f.read())\n</code></pre>"},{"location":"providers/s3/#object-metadata","title":"Object Metadata","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://my-bucket/file.txt\")\n\n# Get metadata via stat()\nstat = path.stat()\nprint(f\"Size: {stat.st_size} bytes\")\nprint(f\"Modified: {stat.st_mtime}\")\n</code></pre>"},{"location":"providers/s3/#s3-specific-properties","title":"S3-Specific Properties","text":"<pre><code>from panpath import PanPath\n\npath = PanPath(\"s3://my-bucket/folder/file.txt\")\n\n# Cloud prefix (bucket)\nprint(path.cloud_prefix)  # s3://my-bucket\n\n# Key (path within bucket)\nprint(path.key)  # folder/file.txt\n\n# Bucket name\nprint(path.bucket)  # my-bucket\n</code></pre>"},{"location":"providers/s3/#performance-tips","title":"Performance Tips","text":""},{"location":"providers/s3/#1-use-async-for-multiple-operations","title":"1. Use Async for Multiple Operations","text":"<pre><code># Slow: Sequential\nfrom panpath import PanPath\n\nfor i in range(100):\n    path = PanPath(f\"s3://bucket/file{i}.txt\")\n    content = path.read_text()\n\n# Fast: Concurrent\nfrom panpath import PanPath\nimport asyncio\n\nasync def read_all():\n    paths = [PanPath(f\"s3://bucket/file{i}.txt\") for i in range(100)]\n    contents = await asyncio.gather(*[p.a_read_text() for p in paths])\n    return contents\n\nasyncio.run(read_all())\n</code></pre>"},{"location":"providers/s3/#2-use-server-side-copy","title":"2. Use Server-Side Copy","text":"<pre><code># Slow: Downloads then uploads\nsrc = PanPath(\"s3://bucket/large.bin\")\ncontent = src.read_bytes()\ndst = PanPath(\"s3://bucket/backup/large.bin\")\ndst.write_bytes(content)\n\n# Fast: Server-side copy\nsrc.copy(\"s3://bucket/backup/large.bin\")\n</code></pre>"},{"location":"providers/s3/#3-batch-operations","title":"3. Batch Operations","text":"<pre><code>from panpath import PanPath\n\n# Copy entire directory efficiently\nsrc_dir = PanPath(\"s3://bucket/data/\")\nsrc_dir.copytree(\"s3://bucket/backup/\")\n</code></pre>"},{"location":"providers/s3/#configuration","title":"Configuration","text":""},{"location":"providers/s3/#custom-client","title":"Custom Client","text":"<pre><code>from panpath import PanPath\nfrom panpath.clients import get_s3_client\n\n# Configure with custom settings\nclient = get_s3_client(\n    aws_access_key_id=\"your_key\",\n    aws_secret_access_key=\"your_secret\",\n    region_name=\"us-west-2\",\n    endpoint_url=\"https://custom-s3-endpoint.com\"  # For S3-compatible services\n)\n\n# Paths will use this configuration\npath = PanPath(\"s3://bucket/file.txt\")\n</code></pre>"},{"location":"providers/s3/#s3-compatible-services","title":"S3-Compatible Services","text":"<p>PanPath works with S3-compatible services (MinIO, DigitalOcean Spaces, etc.):</p> <pre><code>from panpath.clients import get_s3_client\n\n# Configure for MinIO\nget_s3_client(\n    endpoint_url=\"http://localhost:9000\",\n    aws_access_key_id=\"minioadmin\",\n    aws_secret_access_key=\"minioadmin\"\n)\n\n# Use normally\nfrom panpath import PanPath\npath = PanPath(\"s3://my-bucket/file.txt\")\n</code></pre>"},{"location":"providers/s3/#error-handling","title":"Error Handling","text":"<pre><code>from panpath import PanPath\nfrom panpath.exceptions import (\n    PathNotFoundError,\n    PermissionError,\n)\nimport botocore.exceptions\n\npath = PanPath(\"s3://bucket/file.txt\")\n\ntry:\n    content = path.read_text()\nexcept PathNotFoundError:\n    print(\"File not found\")\nexcept PermissionError:\n    print(\"Access denied\")\nexcept botocore.exceptions.NoCredentialsError:\n    print(\"AWS credentials not configured\")\nexcept botocore.exceptions.ClientError as e:\n    error_code = e.response['Error']['Code']\n    if error_code == '404':\n        print(\"File not found\")\n    elif error_code == '403':\n        print(\"Access denied\")\n</code></pre>"},{"location":"providers/s3/#examples","title":"Examples","text":""},{"location":"providers/s3/#process-csv-files","title":"Process CSV Files","text":"<pre><code>from panpath import PanPath\nimport csv\nfrom io import StringIO\n\ndef process_csv(s3_uri: str):\n    path = PanPath(s3_uri)\n\n    # Read CSV\n    content = path.read_text()\n    reader = csv.DictReader(StringIO(content))\n\n    # Process rows\n    for row in reader:\n        print(row)\n\nprocess_csv(\"s3://my-bucket/data.csv\")\n</code></pre>"},{"location":"providers/s3/#backup-to-s3","title":"Backup to S3","text":"<pre><code>from panpath import PanPath\nfrom datetime import datetime\n\ndef backup_to_s3(local_dir: str, s3_bucket: str):\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    src = PanPath(local_dir)\n    dst = PanPath(f\"s3://{s3_bucket}/backup_{timestamp}/\")\n\n    print(f\"Backing up {src} to {dst}...\")\n    src.copytree(dst)\n    print(\"Backup complete!\")\n\nbackup_to_s3(\"/important/data/\", \"my-backups\")\n</code></pre>"},{"location":"providers/s3/#download-dataset","title":"Download Dataset","text":"<pre><code>from panpath import PanPath\n\ndef download_dataset(s3_uri: str, local_dir: str):\n    src = PanPath(s3_uri)\n    dst = PanPath(local_dir)\n\n    print(f\"Downloading {src}...\")\n    src.copytree(dst)\n    print(f\"Downloaded to {dst}\")\n\ndownload_dataset(\"s3://datasets/imagenet/\", \"/data/imagenet/\")\n</code></pre>"},{"location":"providers/s3/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Basic usage</li> <li>Async Operations - Async patterns</li> <li>Bulk Operations - Efficient file operations</li> <li>API Reference - Complete S3 API</li> </ul>"}]}